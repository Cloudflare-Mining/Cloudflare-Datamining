<div class="mb2 gray5">5 min read</div><img class="mr2" src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5IuppnvSEHkX8QYGnKGB74/f7501a4d166e1f465b509f4420d15395/0.png" alt="">
<div class="post-content lh-copy gray1">
	<p>It’s an exciting time to build applications. With the recent AI-powered <a href="https://www.cloudflare.com/learning/ai/ai-vibe-coding"><u>"vibe coding"</u></a> boom, anyone can build a website or application by simply describing what they want in a few sentences. We’re already seeing organizations expose this functionality to both their users and internal employees, empowering anyone to build out what they need.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/40Jzjser2hE91b1y3p80pm/7bc1a7f0ee4cfaeb7a39bb413969b189/1.png" alt="" class="kg-image" width="1160" height="552" loading="lazy">
	</figure>
	<p>Today, we’re excited to open-source an AI vibe coding platform, VibeSDK, to enable anyone to run an entire vibe coding platform themselves, end-to-end, with just one click.</p>
	<p>Want to see it for yourself? Check out our <a href="https://build.cloudflare.dev"><u>demo platform</u></a> that you can use to create and deploy applications. Or better yet, click the button below to deploy your own AI-powered platform, and dive into the repo to learn about how it’s built.</p><a href="https://deploy.workers.cloudflare.com/?url=https%3A%2F%2Fgithub.com%2Fcloudflare%2Fvibesdk"><img src="https://deploy.workers.cloudflare.com/button" alt="Deploy to Cloudflare"></a>
	<p></p>
	<p>Deploying VibeSDK sets up everything you need to run your own AI-powered development platform:</p>
	<ul>
		<li>
			<p><b>Integration with LLM models</b> to generate code, build applications, debug errors, and iterate in real-time, powered by <a href="https://developers.cloudflare.com/agents"><u>Agents SDK</u></a>.&nbsp;</p>
		</li>
		<li>
			<p><b>Isolated development environments </b>that allow users to safely build and preview their applications in secure sandboxes.</p>
		</li>
		<li>
			<p><b>Infinite scale</b> that allows you to deploy thousands or even millions of applications that end users deploy, all served on Cloudflare’s global network</p>
		</li>
		<li>
			<p><b>Observability and caching</b> across multiple AI providers, giving you insight into costs and performance with built-in caching for popular responses.&nbsp;</p>
		</li>
		<li>
			<p><b>Project templates</b> that the LLM can use as a starting point to build common applications and speed up development.</p>
		</li>
		<li>
			<p><b>One-click project export</b> to the user’s Cloudflare account or GitHub repo, so users can take their code and continue development on their own.</p>
		</li>
	</ul>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3jsExecZKmgJHARsxDsMkM/60803b1ba2c68514a053f4d000bf8576/2.png" alt="" class="kg-image" width="1890" height="788" loading="lazy">
	</figure>
	<p><b>Building an AI vibe coding platform from start to finish</b></p>
	<p><b>Step 0: Get started immediately with VibeSDK</b></p>
	<p>We’re seeing companies build their own AI vibe coding platforms to enable both internal and external users. With a vibe coding platform, internal teams like marketing, product, and support can build their own landing pages, prototypes, or internal tools without having to rely on the engineering team. Similarly, SaaS companies can embed this capability into their product to allow users to build their own customizations.&nbsp;</p>
	<p>Every platform has unique requirements and specializations. By <a href="https://www.cloudflare.com/learning/ai/how-to-get-started-with-vibe-coding">building your own</a>, you can write custom logic to prompt LLMs for your specific needs, giving your users more relevant results. This also grants you complete control over the development environment and application hosting, giving you a secure platform that keeps your data private and within your control.&nbsp;</p>
	<p>We wanted to make it easy for anyone to build this themselves, which is why we built a complete platform that comes with project templates, previews, and project deployment. Developers can repurpose the whole platform, or simply take the components they need and customize them to fit their needs.</p>
	<p><b>Step 1: Finding a safe, isolated environment for running untrusted, AI generated code</b></p>
	<p>AI can now build entire applications, but there's a catch: you need somewhere safe to run this untrusted, AI-generated code. Imagine if an <a href="https://www.cloudflare.com/learning/ai/what-is-large-language-model"><u>LLM</u></a> writes an application that needs to install packages, run build commands, and start a development server — you can't just run this directly on your infrastructure where it might affect other users or systems.</p>
	<p>With <a href="https://developers.cloudflare.com/changelog/2025-06-24-announcing-sandboxes"><u>Cloudflare Sandboxes</u></a>, you don't have to worry about this. Every user gets their own isolated environment where the AI-generated code can do anything a normal development environment can do: install npm packages, run builds, start servers, but it's fully contained in a secure, container-based environment that can't affect anything outside its sandbox.&nbsp;</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1AVtsIotiISgrjspHaRLsg/6cd2e56d5edb7021d63c01183362aafe/3.png" alt="" class="kg-image" width="967" height="665" loading="lazy">
	</figure>
	<p>The platform assigns each user to their own sandbox based on their session, so that if a user comes back, they can continue to access the same container with their files intact:</p>
	<pre class="language-TypeScript"><code class="language-TypeScript">// Creating a sandbox client for a user session
const sandbox = getSandbox(env.Sandbox, sandboxId);

// Now AI can safely write and execute code in this isolated environment
await sandbox.writeFile('app.js', aiGeneratedCode);
await sandbox.exec('npm install express');
await sandbox.exec('node app.js');</code></pre>
	<p><b>Step 2: Generating the code</b></p>
	<p>Once the sandbox is created, you have a development environment that can bring the code to life. VibeSDK orchestrates the whole workflow from writing the code, installing the necessary packages, and starting the development server. If you ask it to build a to-do app, it will generate the React application, write the component files, run <code>bun install</code> to get the dependencies, and start the server, so you can see the end result.&nbsp;</p>
	<p>Once the user submits their request, the AI will generate all the necessary files, whether it's a React app, Node.js API, or full-stack application, and write them directly to the sandbox:</p>
	<pre class="language-TypeScript"><code class="language-TypeScript">async function generateAndWriteCode(instanceId: string) {
    // AI generates the application structure
    const aiGeneratedFiles = await callAIModel("Create a React todo app");
    
    // Write all generated files to the sandbox
    for (const file of aiGeneratedFiles) {
        await sandbox.writeFile(
            `${instanceId}/${file.path}`,
            file.content
        );
        // User sees: "✓ Created src/App.tsx"
        notifyUser(`✓ Created ${file.path}`);
    }
}</code></pre>
	<p>To speed this up even more, we’ve provided a set of templates, stored in an <a href="https://www.cloudflare.com/developer-platform/products/r2"><u>R2 bucket</u></a>, that the platform can use and quickly customize, instead of generating every file from scratch. This is just an initial set, but you can expand it and add more examples.&nbsp;</p>
	<p><b>Step 3: Getting a preview of your deployment</b></p>
	<p>Once everything is ready, the platform starts the development server and uses the Sandbox SDK to expose it to the internet with a public preview URL which allows users to instantly see their AI-generated application running live:</p>
	<pre class="language-TypeScript"><code class="language-TypeScript">// Start the development server in the sandbox
const processId = await sandbox.startProcess(
    `bun run dev`, 
    { cwd: instanceId }
);

// Create a public preview URL 
const preview = await sandbox.exposePort(3000, { 
    hostname: 'preview.example.com' 
});

// User instantly gets: "https://my-app-xyz.preview.example.com"
notifyUser(`✓ Preview ready at: ${preview.url}`);</code></pre>
	<p><b>Step 4: Test, log, fix, repeat</b></p>
	<p>But that’s not all! Throughout this process, the platform will capture console output, build logs, and error messages and feed them back to the LLM for automatic fixes. As the platform makes any updates or fixes, the user can see it all happening live —&nbsp;the file editing, installation progress, and error resolution.&nbsp;</p>
	<p>Deploying applications: From Sandbox to Region Earth</p>
	<p>Once the application is developed, it needs to be deployed. The platform packages everything in the sandbox and then uses a separate specialized "deployment sandbox" to deploy the application to <a href="https://www.cloudflare.com/developer-platform/products/workers"><u>Cloudflare Workers</u></a>. This deployment sandbox runs <code>wrangler deploy</code> inside the secure environment to publish the application to Cloudflare's global network.&nbsp;</p>
	<p>Since the platform may deploy up to thousands or millions of applications, Workers for Platforms is used to deploy the Workers at scale. Although all the Workers are deployed to the same Namespace, they are all isolated from one another by default, ensuring there’s no cross-tenant access. Once deployed, each application receives its own isolated Worker instance with a unique public URL like <code>my-app.vibe-build.example.com</code>.&nbsp;</p>
	<pre class="language-TypeScript"><code class="language-TypeScript">async function deployToWorkersForPlatforms(instanceId: string) {
    // 1. Package the app from development sandbox
    const devSandbox = getSandbox(env.Sandbox, instanceId);
    const packagedApp = await devSandbox.exec('zip -r app.zip .');
    
    // 2. Transfer to specialized deployment sandbox
    const deploymentSandbox = getSandbox(env.DeployerServiceObject, 'deployer');
    await deploymentSandbox.writeFile('app.zip', packagedApp);
    await deploymentSandbox.exec('unzip app.zip');
    
    // 3. Deploy using Workers for Platforms dispatch namespace
    const deployResult = await deploymentSandbox.exec(`
        bunx wrangler deploy \\\\
        --dispatch-namespace vibe-sdk-build-default-namespace
    `);
    
    // Each app gets its own isolated Worker and unique URL
    // e.g., https://my-app.example.com
    return `https://${instanceId}.example.com`;
}</code></pre>
	<p><b>Exportable Applications&nbsp;</b></p>
	<p>The platform also allows users to export their application to their own Cloudflare account and GitHub repo, so they can continue the development on their own.&nbsp;</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3itKLSmnTzk2NapoaDQG6e/a0aba26f83cb01db5bd7957a8dfe18f4/Screenshot_2025-09-23_at_9.22.28%C3%A2__AM.png" alt="" class="kg-image" width="1476" height="1084" loading="lazy">
	</figure>
	<p>Observability, caching, and multi-model support built in!&nbsp;</p>
	<p>It's no secret that LLM models have their specialties, which means that when building an AI-powered platform, you may end up using a few different models for different operations. By default, VibeSDK leverages Google’s Gemini models (gemini-2.5-pro, gemini-2.5-flash-lite, gemini-2.5-flash) for project planning, code generation, and debugging.&nbsp;</p>
	<p>VibeSDK is automatically set up with <a href="https://www.cloudflare.com/developer-platform/products/ai-gateway"><u>AI Gateway</u></a>, so that by default, the platform is able to:</p>
	<ul>
		<li>
			<p>Use a unified access point to <a href="https://blog.cloudflare.com/ai-gateway-aug-2025-refresh"><u>route requests across LLM providers</u></a>, allowing you to use models from a range of providers (OpenAI, Anthropic, Google, and others)</p>
		</li>
		<li>
			<p>Cache popular responses, so when someone asks to "build a to-do list app", the gateway can serve a cached response instead of going to the provider (saving inference costs)</p>
		</li>
		<li>
			<p>Get observability into the requests, tokens used, and response times across all providers in one place</p>
		</li>
		<li>
			<p>Track costs across models and integrations</p>
		</li>
	</ul>
	<p>Open sourced, so you can build your own Platform!&nbsp;</p>
	<p>We're open-sourcing VibeSDK for the same reason Cloudflare open-sourced the Workers runtime — we believe the best development happens in the open. That's why we wanted to make it as easy as possible for anyone to build their own AI coding platform, whether it's for internal company use, for your website builder, or for the next big vibe coding platform. We tied all the pieces together for you, so you can get started with the click of a button instead of spending months figuring out how to connect everything yourself. To learn more, check out our <a href="https://developers.cloudflare.com/reference-architecture/diagrams/ai/ai-vibe-coding-platform"><u>reference architecture</u></a> for vibe coding platforms.&nbsp;</p><a href="https://deploy.workers.cloudflare.com/?url=https%3A%2F%2Fgithub.com%2Fcloudflare%2Fvibesdk"><img src="https://deploy.workers.cloudflare.com/button" alt="Deploy to Cloudflare"></a>
	<p></p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2sjy1OUciwTKnKmhXJfbLQ/d0e01bee3867d639077f134fc6374948/5.png" alt="" class="kg-image" width="1999" height="531" loading="lazy">
	</figure>
	<div style="position: relative; padding-top: 56.25%;">
		<iframe src="https://customer-rhnwzxvb3mg4wz3v.cloudflarestream.com/11b508820035b5b5d1a93b087d6013ed/iframe?poster=https%3A%2F%2Fcustomer-rhnwzxvb3mg4wz3v.cloudflarestream.com%2F11b508820035b5b5d1a93b087d6013ed%2Fthumbnails%2Fthumbnail.jpg%3Ftime%3D0m5s%26height%3D600" loading="lazy" style="border: none; position: absolute; top: 0; left: 0; height: 100%; width: 100%;" allow="accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;" allowfullscreen="true"></iframe>
	</div>
	<p></p>
</div>