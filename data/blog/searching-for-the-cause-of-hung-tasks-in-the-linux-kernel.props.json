{
	"footerBlurb": "Cloudflare's connectivity cloud protects <a target='_blank' href='https://www.cloudflare.com/network-services/' rel='noreferrer'>entire corporate networks</a>, helps customers build <a target='_blank' href='https://workers.cloudflare.com/' rel='noreferrer'>Internet-scale applications efficiently</a>, accelerates any <a target='_blank' href='https://www.cloudflare.com/performance/accelerate-internet-applications/' rel='noreferrer'>website or Internet application</a>, <a target='_blank' href='https://www.cloudflare.com/ddos/' rel='noreferrer'>wards off DDoS attacks</a>, keeps <a target='_blank' href='https://www.cloudflare.com/application-security/' rel='noreferrer'>hackers at bay</a>, and can help you on <a target='_blank' href='https://www.cloudflare.com/products/zero-trust/' rel='noreferrer'>your journey to Zero Trust</a>.<br/><br/>Visit <a target='_blank' href='https://one.one.one.one/' rel='noreferrer'>1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.<br/><br/>To learn more about our mission to help build a better Internet, <a target='_blank' href='https://www.cloudflare.com/learning/what-is-cloudflare/' rel='noreferrer'>start here</a>. If you&apos;re looking for a new career direction, check out <a target='_blank' href='http://www.cloudflare.com/careers' rel='noreferrer'>our open positions</a>.",
	"initialReadingTime": "7",
	"locale": "en-us",
	"localesAvailable": [
		"zh-cn",
		"zh-tw"
	],
	"post": {
		"authors": [
			{
				"name": "Oxana Kharitonova",
				"slug": "oxana",
				"bio": null,
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3VMs5mLnM2JGDuB1x0sRSE/957ab30efef528d9fa8ccf73f1c20242/oxana.png",
				"location": "London",
				"website": null,
				"twitter": null,
				"facebook": null,
				"publiclyIndex": true
			},
			{
				"name": "Jesper Brouer",
				"slug": "jesper-brouer",
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/QAY4H7YQSvJvLIPB5Ff0p/6f6aa104cc897511714dddc9ea4ebe1a/Jesper_Brouer.jpg",
				"publiclyIndex": true
			}
		],
		"excerpt": "The Linux kernel can produce a hung task warning. Searching the Internet and the kernel docs, you can find a brief explanation that the process is stuck in the uninterruptible state.",
		"feature_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4iHBIzAkLrDyr0Gc4NAtK3/6c26fa93870ea112c62a791a30bcf705/image1.png",
		"featured": false,
		"html": "<p>Depending on your configuration, the Linux kernel can produce a hung task warning message in its log. Searching the Internet and the kernel documentation, you can find a brief explanation that the kernel process is stuck in the uninterruptable state and hasn’t been scheduled on the CPU for an unexpectedly long period of time. That explains the warning’s meaning, but doesn’t provide the reason it occurred. In this blog post we’re going to explore how the hung task warning works, why it happens, whether it is a bug in the Linux kernel or application itself, and whether it is worth monitoring at all.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"info-task-xxx-1495882-blocked-for-more-than-yyy-seconds\">INFO: task XXX:1495882 blocked for more than YYY seconds.</h3>\n      <a href=\"#info-task-xxx-1495882-blocked-for-more-than-yyy-seconds\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>The hung task message in the kernel log looks like this:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">INFO: task XXX:1495882 blocked for more than YYY seconds.\n     Tainted: G          O       6.6.39-cloudflare-2024.7.3 #1\n&quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.\ntask:XXX         state:D stack:0     pid:1495882 ppid:1      flags:0x00004002\n. . .</pre></code>\n            <p>Processes in Linux can be in different states. Some of them are running or ready to run on the CPU — they are in the <a href=\"https://elixir.bootlin.com/linux/v6.12.6/source/include/linux/sched.h#L99\"><code><u>TASK_RUNNING</u></code></a> state. Others are waiting for some signal or event to happen, e.g. network packets to arrive or terminal input from a user. They are in a <code>TASK_INTERRUPTIBLE</code> state and can spend an arbitrary length of time in this state until being woken up by a signal. The most important thing about these states is that they still can receive signals, and be terminated by a signal. In contrast, a process in the <code>TASK_UNINTERRUPTIBLE</code> state is waiting only for certain special classes of events to wake them up, and can’t be interrupted by a signal. The signals are not delivered until the process emerges from this state and only a system reboot can clear the process. It’s marked with the letter <code>D</code> in the log shown above.</p><p>What if this wake up event doesn’t happen or happens with a significant delay? (A “significant delay” may be on the order of seconds or minutes, depending on the system.) Then our dependent process is hung in this state. What if this dependent process holds some lock and prevents other processes from acquiring it? Or if we see many processes in the D state? Then it might tell us that some of the system resources are overwhelmed or are not working correctly. At the same time, this state is very valuable, especially if we want to preserve the process memory. It might be useful if part of the data is written to disk and another part is still in the process memory — we don’t want inconsistent data on a disk. Or maybe we want a snapshot of the process memory when the bug is hit. To preserve this behaviour, but make it more controlled, a new state was introduced in the kernel: <a href=\"https://lwn.net/Articles/288056/\"><code><u>TASK_KILLABLE</u></code></a> — it still protects a process, but allows termination with a fatal signal. </p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"how-linux-identifies-the-hung-process\">How Linux identifies the hung process</h3>\n      <a href=\"#how-linux-identifies-the-hung-process\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>The Linux kernel has a special thread called <code>khungtaskd</code>. It runs regularly depending on the settings, iterating over all processes in the <code>D</code> state. If a process is in this state for more than YYY seconds, we’ll see a message in the kernel log. There are settings for this daemon that can be changed according to your wishes:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">$ sudo sysctl -a --pattern hung\nkernel.hung_task_all_cpu_backtrace = 0\nkernel.hung_task_check_count = 4194304\nkernel.hung_task_check_interval_secs = 0\nkernel.hung_task_panic = 0\nkernel.hung_task_timeout_secs = 10\nkernel.hung_task_warnings = 200</pre></code>\n            <p>At Cloudflare, we changed the notification threshold <code>kernel.hung_task_timeout_secs</code> from the default 120 seconds to 10 seconds. You can adjust the value for your system depending on configuration and how critical this delay is for you. If the process spends more than <code>hung_task_timeout_secs</code> seconds in the D state, a log entry is written, and our internal monitoring system emits an alert based on this log. Another important setting here is <code>kernel.hung_task_warnings</code> — the total number of messages that will be sent to the log. We limit it to 200 messages and reset it every 15 minutes. It allows us not to be overwhelmed by the same issue, and at the same time doesn’t stop our monitoring for too long. You can make it unlimited by <a href=\"https://docs.kernel.org/admin-guide/sysctl/kernel.html#hung-task-warnings\"><u>setting the value to &quot;-1&quot;</u></a>.</p><p>To better understand the root causes of the hung tasks and how a system can be affected, we’re going to review more detailed examples. </p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"example-1-or-xfs\">Example #1 or XFS</h3>\n      <a href=\"#example-1-or-xfs\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Typically, there is a meaningful process or application name in the log, but sometimes you might see something like this:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">INFO: task kworker/13:0:834409 blocked for more than 11 seconds.\n \tTainted: G      \tO   \t6.6.39-cloudflare-2024.7.3 #1\n&quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.\ntask:kworker/13:0\tstate:D stack:0 \tpid:834409 ppid:2   flags:0x00004000\nWorkqueue: xfs-sync/dm-6 xfs_log_worker</pre></code>\n            <p>In this log, <code>kworker</code> is the kernel thread. It’s used as a deferring mechanism, meaning a piece of work will be scheduled to be executed in the future. Under <code>kworker</code>, the work is aggregated from different tasks, which makes it difficult to tell which application is experiencing a delay. Luckily, the <code>kworker</code> is accompanied by the <a href=\"https://docs.kernel.org/core-api/workqueue.html\"><code><u>Workqueue</u></code></a> line. <code>Workqueue</code> is a linked list, usually predefined in the kernel, where these pieces of work are added and performed by the <code>kworker</code> in the order they were added to the queue. The <code>Workqueue</code> name <code>xfs-sync</code> and <a href=\"https://elixir.bootlin.com/linux/v6.12.6/source/kernel/workqueue.c#L6096\"><u>the function which it points to</u></a>, <code>xfs_log_worker</code>, might give a good clue where to look. Here we can make an assumption that the <a href=\"https://en.wikipedia.org/wiki/XFS\"><u>XFS</u></a> is under pressure and check the relevant metrics. It helped us to discover that due to some configuration changes, we forgot <code>no_read_workqueue</code> / <code>no_write_workqueue</code> flags that were introduced some time ago to <a href=\"https://blog.cloudflare.com/speeding-up-linux-disk-encryption/\"><u>speed up Linux disk encryption</u></a>.</p><p><i>Summary</i>: In this case, nothing critical happened to the system, but the hung tasks warnings gave us an alert that our file system had slowed down.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"example-2-or-coredump\">Example #2 or Coredump</h3>\n      <a href=\"#example-2-or-coredump\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Let’s take a look at the next hung task log and its decoded stack trace:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">INFO: task test:964 blocked for more than 5 seconds.\n      Not tainted 6.6.72-cloudflare-2025.1.7 #1\n&quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.\ntask:test            state:D stack:0     pid:964   ppid:916    flags:0x00004000\nCall Trace:\n&lt;TASK&gt;\n__schedule (linux/kernel/sched/core.c:5378 linux/kernel/sched/core.c:6697) \nschedule (linux/arch/x86/include/asm/preempt.h:85 (discriminator 13) linux/kernel/sched/core.c:6772 (discriminator 13)) \n[do_exit (linux/kernel/exit.c:433 (discriminator 4) linux/kernel/exit.c:825 (discriminator 4)) \n? finish_task_switch.isra.0 (linux/arch/x86/include/asm/irqflags.h:42 linux/arch/x86/include/asm/irqflags.h:77 linux/kernel/sched/sched.h:1385 linux/kernel/sched/core.c:5132 linux/kernel/sched/core.c:5250) \ndo_group_exit (linux/kernel/exit.c:1005) \nget_signal (linux/kernel/signal.c:2869) \n? srso_return_thunk (linux/arch/x86/lib/retpoline.S:217) \n? hrtimer_try_to_cancel.part.0 (linux/kernel/time/hrtimer.c:1347) \narch_do_signal_or_restart (linux/arch/x86/kernel/signal.c:310) \n? srso_return_thunk (linux/arch/x86/lib/retpoline.S:217) \n? hrtimer_nanosleep (linux/kernel/time/hrtimer.c:2105) \nexit_to_user_mode_prepare (linux/kernel/entry/common.c:176 linux/kernel/entry/common.c:210) \nsyscall_exit_to_user_mode (linux/arch/x86/include/asm/entry-common.h:91 linux/kernel/entry/common.c:141 linux/kernel/entry/common.c:304) \n? srso_return_thunk (linux/arch/x86/lib/retpoline.S:217) \ndo_syscall_64 (linux/arch/x86/entry/common.c:88) \nentry_SYSCALL_64_after_hwframe (linux/arch/x86/entry/entry_64.S:121) \n&lt;/TASK&gt;</pre></code>\n            <p>The stack trace says that the process or application <code>test</code> was blocked <code>for more than 5 seconds</code>. We might recognise this user space application by the name, but why is it blocked? It’s always helpful to check the stack trace when looking for a cause. The most interesting line here is <code>do_exit (linux/kernel/exit.c:433 (discriminator 4) linux/kernel/exit.c:825 (discriminator 4))</code>. The <a href=\"https://elixir.bootlin.com/linux/v6.6.67/source/kernel/exit.c#L825\"><u>source code</u></a> points to the <code>coredump_task_exit</code> function. Additionally, checking the process metrics revealed that the application crashed during the time when the warning message appeared in the log. When a process is terminated based on some set of signals (abnormally), <a href=\"https://man7.org/linux/man-pages/man5/core.5.html\"><u>the Linux kernel can provide a core dump file</u></a>, if enabled. The mechanism — when a process terminates, the kernel makes a snapshot of the process memory before exiting and either writes it to a file or sends it through the socket to another handler — can be <a href=\"https://systemd.io/COREDUMP/\"><u>systemd-coredump</u></a> or your custom one. When it happens, the kernel moves the process to the <code>D</code> state to preserve its memory and early termination. The higher the process memory usage, the longer it takes to get a core dump file, and the higher the chance of getting a hung task warning.</p><p>Let’s check our hypothesis by triggering it with a small Go program. We’ll use the default Linux coredump handler and will decrease the hung task threshold to 1 second.</p><p>Coredump settings:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">$ sudo sysctl -a --pattern kernel.core\nkernel.core_pattern = core\nkernel.core_pipe_limit = 16\nkernel.core_uses_pid = 1</pre></code>\n            <p>You can make changes with <a href=\"https://man7.org/linux/man-pages/man8/sysctl.8.html\"><u>sysctl</u></a>:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">$ sudo sysctl -w kernel.core_uses_pid=1</pre></code>\n            <p>Hung task settings:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">$ sudo sysctl -a --pattern hung\nkernel.hung_task_all_cpu_backtrace = 0\nkernel.hung_task_check_count = 4194304\nkernel.hung_task_check_interval_secs = 0\nkernel.hung_task_panic = 0\nkernel.hung_task_timeout_secs = 1\nkernel.hung_task_warnings = -1</pre></code>\n            <p>Go program:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">$ cat main.go\npackage main\n\nimport (\n\t&quot;os&quot;\n\t&quot;time&quot;\n)\n\nfunc main() {\n\t_, err := os.ReadFile(&quot;test.file&quot;)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\ttime.Sleep(8 * time.Minute) \n}</pre></code>\n            <p>This program reads a 10 GB file into process memory. Let’s create the file:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">$ yes this is 10GB file | head -c 10GB &gt; test.file</pre></code>\n            <p>The last step is to build the Go program, crash it, and watch our kernel log:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">$ go mod init test\n$ go build .\n$ GOTRACEBACK=crash ./test\n$ (Ctrl+\\)</pre></code>\n            <p>Hooray! We can see our hung task warning:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">$ sudo dmesg -T | tail -n 31\nINFO: task test:8734 blocked for more than 22 seconds.\n      Not tainted 6.6.72-cloudflare-2025.1.7 #1\n      Blocked by coredump.\n&quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.\ntask:test            state:D stack:0     pid:8734  ppid:8406   task_flags:0x400448 flags:0x00004000</pre></code>\n            <p>By the way, have you noticed the <code>Blocked by coredump.</code> line in the log? It was recently added to the <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/akpm/mm.git/commit/?h=mm-nonmm-stable&id=23f3f7625cfb55f92e950950e70899312f54afb7\"><u>upstream</u></a> code to improve visibility and remove the blame from the process itself. The patch also added the <code>task_flags</code> information, as <code>Blocked by coredump</code> is detected via the flag <a href=\"https://elixir.bootlin.com/linux/v6.13.1/source/include/linux/sched.h#L1675\"><code><u>PF_POSTCOREDUMP</u></code></a>, and knowing all the task flags is useful for further root-cause analysis.</p><p><i>Summary</i>: This example showed that even if everything suggests that the application is the problem, the real root cause can be something else — in this case, <code>coredump</code>.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"example-3-or-rtnl_mutex\">Example #3 or rtnl_mutex</h3>\n      <a href=\"#example-3-or-rtnl_mutex\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>This one was tricky to debug. Usually, the alerts are limited by one or two different processes, meaning only a certain application or subsystem experiences an issue. In this case, we saw dozens of unrelated tasks hanging for minutes with no improvements over time. Nothing else was in the log, most of the system metrics were fine, and existing traffic was being served, but it was not possible to ssh to the server. New Kubernetes container creations were also stalling. Analyzing the stack traces of different tasks initially revealed that all the traces were limited to just three functions:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">rtnetlink_rcv_msg+0x9/0x3c0\ndev_ethtool+0xc6/0x2db0 \nbonding_show_bonds+0x20/0xb0</pre></code>\n            <p>Further investigation showed that all of these functions were waiting for <a href=\"https://elixir.bootlin.com/linux/v6.6.74/source/net/core/rtnetlink.c#L76\"><code><u>rtnl_lock</u></code></a> to be acquired. It looked like some application acquired the <code>rtnl_mutex</code> and didn’t release it. All other processes were in the <code>D</code> state waiting for this lock.</p><p>The RTNL lock is primarily used by the kernel networking subsystem for any network-related config, for both writing and reading. The RTNL is a global <b>mutex</b> lock, although <a href=\"https://lpc.events/event/18/contributions/1959/\"><u>upstream efforts</u></a> are being made for splitting up RTNL per network namespace (netns).</p><p>From the hung task reports, we can observe the “victims” that are being stalled waiting for the lock, but how do we identify the task that is holding this lock for too long? For troubleshooting this, we leveraged <code>BPF</code> via a <code>bpftrace</code> script, as this allows us to inspect the running kernel state. The <a href=\"https://elixir.bootlin.com/linux/v6.6.75/source/include/linux/mutex.h#L67\"><u>kernel&#39;s mutex implementation</u></a> has a struct member called <code>owner</code>. It contains a pointer to the <a href=\"https://elixir.bootlin.com/linux/v6.6.75/source/include/linux/sched.h#L746\"><code><u>task_struct</u></code></a> from the mutex-owning process, except it is encoded as type <code>atomic_long_t</code>. This is because the mutex implementation stores some state information in the lower 3-bits (mask 0x7) of this pointer. Thus, to read and dereference this <code>task_struct</code> pointer, we must first mask off the lower bits (0x7).</p><p>Our <code>bpftrace</code> script to determine who holds the mutex is as follows:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">#!/usr/bin/env bpftrace\ninterval:s:10 {\n  $rtnl_mutex = (struct mutex *) kaddr(&quot;rtnl_mutex&quot;);\n  $owner = (struct task_struct *) ($rtnl_mutex-&gt;owner.counter &amp; ~0x07);\n  if ($owner != 0) {\n    printf(&quot;rtnl_mutex-&gt;owner = %u %s\\n&quot;, $owner-&gt;pid, $owner-&gt;comm);\n  }\n}</pre></code>\n            <p>In this script, the <code>rtnl_mutex</code> lock is a global lock whose address can be exposed via <code>/proc/kallsyms</code> – using <code>bpftrace</code> helper function <code>kaddr()</code>, we can access the struct mutex pointer from the <code>kallsyms</code>. Thus, we can periodically (via <code>interval:s:10</code>) check if someone is holding this lock.</p><p>In the output we had this:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">rtnl_mutex-&gt;owner = 3895365 calico-node</pre></code>\n            <p>This allowed us to quickly identify <code>calico-node</code> as the process holding the RTNL lock for too long. To quickly observe where this process itself is stalled, the call stack is available via <code>/proc/3895365/stack</code>. This showed us that the root cause was a Wireguard config change, with function <code>wg_set_device()</code> holding the RTNL lock, and <code>peer_remove_after_dead()</code> waiting too long for a <code>napi_disable()</code> call. We continued debugging via a tool called <a href=\"https://drgn.readthedocs.io/en/latest/user_guide.html#stack-traces\"><code><u>drgn</u></code></a>, which is a programmable debugger that can debug a running kernel via a Python-like interactive shell. We still haven’t discovered the root cause for the Wireguard issue and have <a href=\"https://lore.kernel.org/lkml/CALrw=nGoSW=M-SApcvkP4cfYwWRj=z7WonKi6fEksWjMZTs81A@mail.gmail.com/\"><u>asked the upstream</u></a> for help, but that is another story.</p><p><i>Summary</i>: The hung task messages were the only ones which we had in the kernel log. Each stack trace of these messages was unique, but by carefully analyzing them, we could spot similarities and continue debugging with other instruments.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"epilogue\">Epilogue</h3>\n      <a href=\"#epilogue\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Your system might have different hung task warnings, and we have many others not mentioned here. Each case is unique, and there is no standard approach to debug them. But hopefully this blog post helps you better understand why it’s good to have these warnings enabled, how they work, and what the meaning is behind them. We tried to provide some navigation guidance for the debugging process as well:</p><ul><li><p>analyzing the stack trace might be a good starting point for debugging it, even if all the messages look unrelated, like we saw in example #3</p></li><li><p>keep in mind that the alert might be misleading, pointing to the victim and not the offender, as we saw in example #2 and example #3</p></li><li><p>if the kernel doesn’t schedule your application on the CPU, puts it in the D state, and emits the warning – the real problem might exist in the application code</p></li></ul><p>Good luck with your debugging, and hopefully this material will help you on this journey!</p>",
		"id": "3UHNgpNPKn2IAwDUzD4m3a",
		"localeList": {
			"name": "LOC: Searching for the cause of hung tasks in the Linux kernel",
			"enUS": "English for Locale",
			"zhCN": "Translated for Locale",
			"zhHansCN": "No Page for Locale",
			"zhTW": "Translated for Locale",
			"frFR": "No Page for Locale",
			"deDE": "No Page for Locale",
			"itIT": "No Page for Locale",
			"jaJP": "No Page for Locale",
			"koKR": "No Page for Locale",
			"ptBR": "No Page for Locale",
			"esLA": "No Page for Locale",
			"esES": "No Page for Locale",
			"enAU": "No Page for Locale",
			"enCA": "No Page for Locale",
			"enIN": "No Page for Locale",
			"enGB": "No Page for Locale",
			"idID": "No Page for Locale",
			"ruRU": "No Page for Locale",
			"svSE": "No Page for Locale",
			"viVN": "No Page for Locale",
			"plPL": "No Page for Locale",
			"arAR": "No Page for Locale",
			"nlNL": "No Page for Locale",
			"thTH": "No Page for Locale",
			"trTR": "No Page for Locale",
			"heIL": "No Page for Locale",
			"lvLV": "No Page for Locale",
			"etEE": "No Page for Locale",
			"ltLT": "No Page for Locale"
		},
		"meta_description": "The Linux kernel can produce a hung task warning. Searching the Internet and the kernel docs, you can find a brief explanation that the process is stuck in the uninterruptible state. That explains the warning’s meaning, but doesn’t provide the reason it occurred. In this blog post we’re going to explore how the warning works.",
		"metadata": {
			"title": "Searching for the cause of hung tasks in the Linux kernel",
			"description": "The Linux kernel can produce a hung task warning. Searching the Internet and the kernel docs, you can find a brief explanation that the process is stuck in the uninterruptible state. That explains the warning’s meaning, but doesn’t provide the reason it occurred. In this blog post we’re going to explore how the warning works.",
			"imgPreview": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2dasu8nuHwyI37n0WhScLi/4f710b8e0eeee6ba46efa49c4fb6ae49/Searching_for_the_cause_of_hung_tasks_in_the_Linux_kernel-OG.png"
		},
		"primary_author": {},
		"publicly_index": true,
		"published_at": "2025-02-14T14:00+00:00",
		"slug": "searching-for-the-cause-of-hung-tasks-in-the-linux-kernel",
		"tags": [
			{
				"id": "2UVIYusJwlvsmPYl2AvSuR",
				"name": "Deep Dive",
				"slug": "deep-dive"
			},
			{
				"id": "383iv0UQ6Lp0GZwOAxGq2p",
				"name": "Linux",
				"slug": "linux"
			},
			{
				"id": "73alK6sbtKLS6uB7ZrYrjj",
				"name": "Kernel",
				"slug": "kernel"
			},
			{
				"id": "3VJOfQ8TnNJwqu1GIGwPuA",
				"name": "Monitoring",
				"slug": "monitoring"
			}
		],
		"title": "Searching for the cause of hung tasks in the Linux kernel",
		"updated_at": "2025-03-03T07:09:45.578Z",
		"url": "https://blog.cloudflare.com/searching-for-the-cause-of-hung-tasks-in-the-linux-kernel"
	},
	"translations": {
		"posts.by": "By",
		"footer.gdpr": "GDPR",
		"lang_blurb1": "This post is also available in {lang1}.",
		"lang_blurb2": "This post is also available in {lang1} and {lang2}.",
		"lang_blurb3": "This post is also available in {lang1}, {lang2} and {lang3}.",
		"footer.press": "Press",
		"header.title": "The Cloudflare Blog",
		"search.clear": "Clear",
		"search.filter": "Filter",
		"search.source": "Source",
		"footer.careers": "Careers",
		"footer.company": "Company",
		"footer.support": "Support",
		"footer.the_net": "theNet",
		"search.filters": "Filters",
		"footer.our_team": "Our team",
		"footer.webinars": "Webinars",
		"page.more_posts": "More posts",
		"posts.time_read": "{time} min read",
		"search.language": "Language",
		"footer.community": "Community",
		"footer.resources": "Resources",
		"footer.solutions": "Solutions",
		"footer.trademark": "Trademark",
		"header.subscribe": "Subscribe",
		"footer.compliance": "Compliance",
		"footer.free_plans": "Free plans",
		"footer.impact_ESG": "Impact/ESG",
		"posts.follow_on_X": "Follow on X",
		"footer.help_center": "Help center",
		"footer.network_map": "Network Map",
		"header.please_wait": "Please Wait",
		"page.related_posts": "Related posts",
		"search.result_stat": "Results <strong>{search_range}</strong> of <strong>{search_total}</strong> for <strong>{search_keyword}</strong>",
		"footer.case_studies": "Case Studies",
		"footer.connect_2024": "Connect 2024",
		"footer.terms_of_use": "Terms of Use",
		"footer.white_papers": "White Papers",
		"footer.cloudflare_tv": "Cloudflare TV",
		"footer.community_hub": "Community Hub",
		"footer.compare_plans": "Compare plans",
		"footer.contact_sales": "Contact Sales",
		"header.contact_sales": "Contact Sales",
		"header.email_address": "Email Address",
		"page.error.not_found": "Page not found",
		"footer.developer_docs": "Developer docs",
		"footer.privacy_policy": "Privacy Policy",
		"footer.request_a_demo": "Request a demo",
		"page.continue_reading": "Continue reading",
		"footer.analysts_report": "Analyst reports",
		"footer.for_enterprises": "For enterprises",
		"footer.getting_started": "Getting Started",
		"footer.learning_center": "Learning Center",
		"footer.project_galileo": "Project Galileo",
		"pagination.newer_posts": "Newer Posts",
		"pagination.older_posts": "Older Posts",
		"posts.social_buttons.x": "Discuss on X",
		"search.icon_aria_label": "Search",
		"search.source_location": "Source/Location",
		"footer.about_cloudflare": "About Cloudflare",
		"footer.athenian_project": "Athenian Project",
		"footer.become_a_partner": "Become a partner",
		"footer.cloudflare_radar": "Cloudflare Radar",
		"footer.network_services": "Network services",
		"footer.trust_and_safety": "Trust & Safety",
		"header.get_started_free": "Get Started Free",
		"page.search.placeholder": "Search Cloudflare",
		"footer.cloudflare_status": "Cloudflare Status",
		"footer.cookie_preference": "Cookie Preferences",
		"header.valid_email_error": "Must be valid email.",
		"search.result_stat_empty": "Results <strong>{search_range}</strong> of <strong>{search_total}</strong>",
		"footer.connectivity_cloud": "Connectivity cloud",
		"footer.developer_services": "Developer services",
		"footer.investor_relations": "Investor relations",
		"page.not_found.error_code": "Error Code: 404",
		"search.autocomplete_title": "Insert a query. Press enter to send",
		"footer.logos_and_press_kit": "Logos & press kit",
		"footer.application_services": "Application services",
		"footer.get_a_recommendation": "Get a recommendation",
		"posts.social_buttons.reddit": "Discuss on Reddit",
		"footer.sse_and_sase_services": "SSE and SASE services",
		"page.not_found.outdated_link": "You may have used an outdated link, or you may have typed the address incorrectly.",
		"footer.report_security_issues": "Report Security Issues",
		"page.error.error_message_page": "Sorry, we can't find the page you are looking for.",
		"header.subscribe_notifications": "Subscribe to receive notifications of new posts:",
		"footer.cloudflare_for_campaigns": "Cloudflare for Campaigns",
		"header.subscription_confimation": "Subscription confirmed. Thank you for subscribing!",
		"posts.social_buttons.hackernews": "Discuss on Hacker News",
		"footer.diversity_equity_inclusion": "Diversity, equity & inclusion",
		"footer.critical_infrastructure_defense_project": "Critical Infrastructure Defense Project"
	}
}