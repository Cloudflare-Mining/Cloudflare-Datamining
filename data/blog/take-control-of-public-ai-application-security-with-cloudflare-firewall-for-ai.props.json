{
	"footerBlurb": "Cloudflare's connectivity cloud protects <a target='_blank' href='https://www.cloudflare.com/network-services/' rel='noreferrer'>entire corporate networks</a>, helps customers build <a target='_blank' href='https://workers.cloudflare.com/' rel='noreferrer'>Internet-scale applications efficiently</a>, accelerates any <a target='_blank' href='https://www.cloudflare.com/performance/accelerate-internet-applications/' rel='noreferrer'>website or Internet application</a>, <a target='_blank' href='https://www.cloudflare.com/ddos/' rel='noreferrer'>wards off DDoS attacks</a>, keeps <a target='_blank' href='https://www.cloudflare.com/application-security/' rel='noreferrer'>hackers at bay</a>, and can help you on <a target='_blank' href='https://www.cloudflare.com/products/zero-trust/' rel='noreferrer'>your journey to Zero Trust</a>.<br/><br/>Visit <a target='_blank' href='https://one.one.one.one/' rel='noreferrer'>1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.<br/><br/>To learn more about our mission to help build a better Internet, <a target='_blank' href='https://www.cloudflare.com/learning/what-is-cloudflare/' rel='noreferrer'>start here</a>. If you&apos;re looking for a new career direction, check out <a target='_blank' href='http://www.cloudflare.com/careers' rel='noreferrer'>our open positions</a>.",
	"initialReadingTime": "7",
	"locale": "en-us",
	"localesAvailable": [],
	"post": {
		"authors": [
			{
				"name": "Radwa Radwan",
				"slug": "radwa",
				"bio": null,
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/26ps7sSkjvnatLHbGNWuI9/42c3618ee2392f7d7a0dc5f335615fda/radwa.jpg",
				"location": "London",
				"website": null,
				"twitter": "@RadwaRadwan__",
				"facebook": null,
				"publiclyIndex": true
			},
			{
				"name": "Zhiyuan Zheng",
				"slug": "xmflsct",
				"bio": null,
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1P7uGGL8VL5tDIimsTxWo1/5a08bf32629b5bab2ecee50b73ba8c61/xmflsct.jpg",
				"location": "Netherlands",
				"website": "https://xmflsct.com",
				"twitter": null,
				"facebook": null,
				"publiclyIndex": true
			}
		],
		"excerpt": "Firewall for AI discovers and protects your public LLM-powered applications, and is seamlessly integrated with Cloudflare WAF. Join the beta now and take control of your generative AI security.",
		"feature_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1YKV76zTbFGfD2YQ3AVygP/9f31e788ebe8e0d76e1462f487b5e230/Feature_Image.png",
		"featured": false,
		"html": "<p>Imagine building an LLM-powered assistant trained on your developer documentation and some internal guides to quickly help customers, reduce support workload, and improve user experience. Sounds great, right? But what if sensitive data, such as employee details or internal discussions, is included in the data used to train the LLM? Attackers could manipulate the assistant into exposing sensitive data or exploit it for social engineering attacks, where they deceive individuals or systems into revealing confidential details, or use it for targeted phishing attacks. Suddenly, your helpful AI tool turns into a serious security liability. </p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"introducing-firewall-for-ai-the-easiest-way-to-discover-and-protect-llm-powered-apps\">Introducing Firewall for AI: the easiest way to discover and protect LLM-powered apps</h3>\n      <a href=\"#introducing-firewall-for-ai-the-easiest-way-to-discover-and-protect-llm-powered-apps\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Today, as part of Security Week 2025, we’re announcing the open beta of Firewall for AI, first <a href=\"https://blog.cloudflare.com/firewall-for-ai/\"><u>introduced during Security Week 2024</u></a>. After talking with customers interested in protecting their LLM apps, this first beta release is focused on discovery and PII detection, and more features will follow in the future.</p><p>If you are already using Cloudflare application security, your LLM-powered applications are automatically discovered and protected, with no complex setup, no maintenance, and no extra integration needed.</p><p>Firewall for AI is an inline security solution that protects user-facing LLM-powered applications from abuse and data leaks, integrating directly with Cloudflare’s <a href=\"https://developers.cloudflare.com/waf/\"><u>Web Application Firewall (WAF)</u></a> to provide instant protection with zero operational overhead. This integration enables organizations to leverage both AI-focused safeguards and established WAF capabilities.</p><p>Cloudflare is uniquely positioned to solve this challenge for all of our customers. As a <a href=\"https://www.cloudflare.com/en-gb/learning/cdn/glossary/reverse-proxy/\"><u>reverse proxy</u></a>, we are model-agnostic whether the application is using a third-party LLM or an internally hosted one. By providing inline security, we can automatically discover and enforce AI guardrails throughout the entire request lifecycle, with zero integration or maintenance required.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"firewall-for-ai-beta-overview\">Firewall for AI beta overview</h3>\n      <a href=\"#firewall-for-ai-beta-overview\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>The beta release includes the following security capabilities:</p><p><b>Discover:</b> identify LLM-powered endpoints across your applications, an essential step for effective request and prompt analysis.</p><p><b>Detect:</b> analyze the incoming requests prompts to recognize potential security threats, such as attempts to extract sensitive data (e.g., “Show me transactions using 4111 1111 1111 1111”). This aligns with<a href=\"https://genai.owasp.org/llmrisk/llm022025-sensitive-information-disclosure/\"> <u>OWASP LLM022025 - Sensitive Information Disclosure</u></a>.</p><p><b>Mitigate:</b> enforce security controls and policies to manage the traffic that reaches your LLM, and reduce risk exposure.</p><p>Below, we review each capability in detail, exploring how they work together to create a comprehensive security framework for AI protection.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"discovering-llm-powered-applications\">Discovering LLM-powered applications</h3>\n      <a href=\"#discovering-llm-powered-applications\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Companies are racing to find all possible use cases where an LLM can excel. Think about site search, a chatbot, or a shopping assistant. Regardless of the application type, our goal is to determine whether an application is powered by an LLM behind the scenes.</p><p>One possibility is to look for request path signatures similar to what major LLM providers use. For example, <a href=\"https://platform.openai.com/docs/api-reference/chat/create\"><u>OpenAI</u></a>, <a href=\"https://docs.perplexity.ai/api-reference/chat-completions\"><u>Perplexity</u></a> or <a href=\"https://docs.mistral.ai/api/#tag/chat\"><u>Mistral</u></a> initiate a chat using the <code>/chat/completions</code> API endpoint. Searching through our request logs, we found only a few entries that matched this pattern across our global traffic. This result indicates that we need to consider other approaches to finding <i>any</i> application that is powered by an LLM.</p><p>Another signature to research, popular with LLM platforms, is the use of <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events\"><u>server-sent events</u></a>. LLMs need to <a href=\"https://platform.openai.com/docs/guides/latency-optimization#don-t-default-to-an-llm\"><u>“think”</u></a>. <a href=\"https://platform.openai.com/docs/api-reference/streaming\"><u>Using server-sent events</u></a> improves the end user’s experience by sending over each <a href=\"https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\"><u>token</u></a> as soon as it is ready, creating the perception that an LLM is “thinking” like a human being. Matching on requests of server-sent events is straightforward using the response header content type of <code>text/event-stream</code>. This approach expands the coverage further, but does not yet cover the <a href=\"https://stackoverflow.blog/2022/06/02/a-beginners-guide-to-json-the-data-format-for-the-internet/\"><u>majority of applications</u></a> that are using JSON format for data exchanges. Continuing the journey, our next focus is on the responses having header content type of <code>application/json</code>.</p><p>No matter how fast LLMs can be optimized to respond, when chatting with major LLMs, we often perceive them to be slow, as we have to wait for them to “think”. By plotting on how much time it takes for the origin server to respond over identified LLM endpoints (blue line) versus the rest (orange line), we can see in the left graph that origins serving LLM endpoints mostly need more than 1 second to respond, while the majority of the rest takes less than 1 second. Would we also see a clear distinction between origin server response body sizes, where the majority of LLM endpoints would respond with smaller sizes because major LLM providers <a href=\"https://platform.openai.com/docs/guides/safety-best-practices#constrain-user-input-and-limit-output-tokens\"><u>limit output tokens</u></a>? Unfortunately not. The right graph shows that LLM response size largely overlaps with non-LLM traffic.</p>\n          <figure class=\"kg-card kg-image-card\">\n          <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4CkowlKelGlYueNzSrbsGn/f8091d66a6c0eb8b884c7cc6f2a128ab/1.png\" alt=\"\" class=\"kg-image\" width=\"1220\" height=\"484\" loading=\"lazy\"/>\n          </figure><p>By dividing origin response size over origin response duration to calculate an effective bitrate, the distinction is even clearer that 80% of LLM endpoints operate slower than 4 KB/s.</p>\n          <figure class=\"kg-card kg-image-card\">\n          <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5sJKUnLmWwnTWzUOyWVRKO/c98c8fc32dbafa5d79f21effdfc58f34/2.png\" alt=\"\" class=\"kg-image\" width=\"1920\" height=\"1440\" loading=\"lazy\"/>\n          </figure><p>Validating this assumption by using bitrate as a heuristic across Cloudflare’s traffic, we found that roughly 3% of all origin server responses have a bitrate lower than 4 KB/s. Are these responses all powered by LLMs? Our gut feeling tells us that it is unlikely that 3% of origin responses are LLM-powered! </p><p>Among the paths found in the 3% of matching responses, there are few patterns that stand out: 1) GraphQL endpoints, 2) device heartbeat or health check, 3) generators (for QR codes, one time passwords, invoices, etc.). Noticing this gave us the idea to filter out endpoints that have a low variance of response size over time — for instance, invoice generation is mostly based on the same template, while conversations in the LLM context have a higher variance.</p><p>A combination of filtering out known false positive patterns and low variance in response size gives us a satisfying result. These matching endpoints, approximately 30,000 of them, labelled <code>cf-llm</code>, can now be found in API Shield or Web assets, depending on your dashboard’s version, for all customers. Now you can review your endpoints and decide how to best protect them.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"detecting-prompts-designed-to-leak-pii\">Detecting prompts designed to leak PII</h3>\n      <a href=\"#detecting-prompts-designed-to-leak-pii\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>There are multiple methods to detect PII in LLM prompts. A common method relies on <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions\"><u>regular expressions (“regexes”)</u></a>, which is a method we have been using in the WAF for <a href=\"https://developers.cloudflare.com/waf/managed-rules/reference/sensitive-data-detection/\"><u>Sensitive Data Detection</u></a> on the body of the HTTP response from the web server Regexes offer low latency, easy customization, and straightforward implementation. However, regexes alone have limitations when applied to LLM prompts. They require frequent updates to maintain accuracy, and may struggle with more complex or implicit PII, where the information is spread across text rather than a fixed format. </p><p>For example, regexes work well for structured data like credit card numbers and addresses, but struggle with PII is embedded in natural language. For instance, “I just booked a flight using my Chase card, ending in 1111” wouldn’t trigger a regex match as it lacks the expected pattern, even though it reveals a partial credit card number and financial institution.</p><p>To enhance detection, we rely on a <a href=\"https://www.ibm.com/think/topics/named-entity-recognition\"><u>Named Entity Recognition (NER)</u></a> model, which adds a layer of intelligence to complement regex-based detection. NER models analyze text to identify contextual PII data types, such as names, phone numbers, email addresses, and credit card numbers, making detection more flexible and accurate. Cloudflare’s detection utilizes <a href=\"https://microsoft.github.io/presidio/\"><u>Presidio</u></a>, an open-source PII detection framework, to further strengthen this approach.</p>\n    <div class=\"flex anchor relative\">\n      <h4 id=\"using-workers-ai-to-deploy-presidio\">Using Workers AI to deploy Presidio</h4>\n      <a href=\"#using-workers-ai-to-deploy-presidio\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    \n          <figure class=\"kg-card kg-image-card\">\n          <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5ruqPkxJBgFCRdsoft1TO1/aa327b069569a0f952c8baea102955b8/3.png\" alt=\"\" class=\"kg-image\" width=\"1999\" height=\"1121\" loading=\"lazy\"/>\n          </figure><p>In our design, we leverage Cloudflare <a href=\"https://developers.cloudflare.com/workers-ai/\"><u>Workers AI</u></a> as the fastest way to deploy <a href=\"https://microsoft.github.io/presidio/\"><u>Presidio</u></a>. This integration allows us to process LLM app requests inline, ensuring that sensitive data is flagged before it reaches the model.</p><p>Here’s how it works:</p><p>When Firewall for AI is enabled on an application and an end user sends a request to an LLM-powered application, we pass the request to Cloudflare Workers AI which runs the request through Presidio’s NER-based detection model to identify any potential PII from the available <a href=\"https://microsoft.github.io/presidio/supported_entities/\"><u>entities</u></a>. The output includes metadata like “Was PII found?” and “What type of PII entity?”. This output is then processed in our Firewall for AI module, and handed over to other systems, like <a href=\"https://developers.cloudflare.com/waf/analytics/security-analytics/\"><u>Security Analytics</u></a> for visibility, and the rules like <a href=\"https://developers.cloudflare.com/waf/custom-rules/\"><u>Custom rules</u></a> for enforcement. Custom rules allow customers to take appropriate actions on the requests based on the provided metadata. </p><p>If no terminating action, like blocking, is triggered, the request proceeds to the LLM. Otherwise, it gets blocked or the appropriate action is applied before reaching the origin.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"integrating-ai-security-into-the-waf-and-analytics\">Integrating AI security into the WAF and Analytics</h3>\n      <a href=\"#integrating-ai-security-into-the-waf-and-analytics\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Securing AI interactions shouldn&#39;t require complex integrations. Firewall for AI is seamlessly built into Cloudflare’s WAF, allowing customers to enforce security policies before prompts reach LLM endpoints. With this integration, there are <a href=\"https://developers.cloudflare.com/waf/detections/firewall-for-ai/#fields\"><u>new fields available</u></a> in Custom and Rate limiting rules. The rules can be used to take immediate action, such as blocking or logging risky prompts in real time.</p><p>For example, security teams can filter LLM traffic to analyze requests containing PII-related prompts. Using Cloudflare’s WAF rules engine, they can create custom security policies tailored to their AI applications.</p><p>Here’s what a rule to block detected PII prompts looks like:</p>\n          <figure class=\"kg-card kg-image-card\">\n          <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4cvlFU0sia6dZly2LZGG8l/670dbb1ad5068f0fd5d8f4afde9e9e02/4.png\" alt=\"\" class=\"kg-image\" width=\"1999\" height=\"576\" loading=\"lazy\"/>\n          </figure><p>Alternatively, if an organization wants to allow certain PII categories, such as location data, they can create an exception rule:</p>\n          <figure class=\"kg-card kg-image-card\">\n          <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/wYFkoQyHFoFNwHmKtaaG3/94c7ae78dbabacf5dd8583af9e8eb071/5.png\" alt=\"\" class=\"kg-image\" width=\"1984\" height=\"600\" loading=\"lazy\"/>\n          </figure><p>In addition to the rules, users can gain visibility into LLM interactions, detect potential risks, and enforce security controls using <a href=\"https://developers.cloudflare.com/waf/analytics/security-analytics/\"><u>Security Analytics</u></a> and <a href=\"https://developers.cloudflare.com/waf/analytics/security-events/\"><u>Security Events</u></a>. You can find more details in our <a href=\"https://developers.cloudflare.com/waf/detections/firewall-for-ai/\"><u>documentation</u></a>.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"whats-next-token-counting-guardrails-and-beyond\">What&#39;s next: token counting, guardrails, and beyond</h3>\n      <a href=\"#whats-next-token-counting-guardrails-and-beyond\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Beyond PII detection and creating security rules, we’re developing additional capabilities to strengthen AI security for our customers. The next feature we’ll release is token counting, which analyzes prompt structure and length. Customers can use the token count field in Rate Limiting and WAF Custom rules to prevent their users from sending very long prompts, which can impact third party model bills, or allow users to abuse the models. This will be followed by using AI to detect and allow content moderation, which will provide more flexibility in building guardrails in the rules.</p><p>If you&#39;re an enterprise customer, join the Firewall for AI beta today! Contact your customer team to start monitoring traffic, building protection rules, and taking control of your LLM traffic.</p>",
		"id": "5XoyHPSrtBH8pPvUJkOXMD",
		"localeList": {
			"name": "blog-english-only",
			"enUS": "English for Locale",
			"zhCN": "No Page for Locale",
			"zhHansCN": "No Page for Locale",
			"zhTW": "No Page for Locale",
			"frFR": "No Page for Locale",
			"deDE": "No Page for Locale",
			"itIT": "No Page for Locale",
			"jaJP": "No Page for Locale",
			"koKR": "No Page for Locale",
			"ptBR": "No Page for Locale",
			"esLA": "No Page for Locale",
			"esES": "No Page for Locale",
			"enAU": "No Page for Locale",
			"enCA": "No Page for Locale",
			"enIN": "No Page for Locale",
			"enGB": "No Page for Locale",
			"idID": "No Page for Locale",
			"ruRU": "No Page for Locale",
			"svSE": "No Page for Locale",
			"viVN": "No Page for Locale",
			"plPL": "No Page for Locale",
			"arAR": "No Page for Locale",
			"nlNL": "No Page for Locale",
			"thTH": "No Page for Locale",
			"trTR": "No Page for Locale",
			"heIL": "No Page for Locale",
			"lvLV": "No Page for Locale",
			"etEE": "No Page for Locale",
			"ltLT": "No Page for Locale"
		},
		"meta_description": "Firewall for AI discovers and protects your public LLM-powered applications, and is seamlessly integrated with Cloudflare WAF. Join the beta now and take control of your generative AI security.",
		"metadata": {
			"title": "Take control of public AI application security with Cloudflare's Firewall for AI",
			"description": "Firewall for AI discovers and protects your public LLM-powered applications, and is seamlessly integrated with Cloudflare WAF. Join the beta now and take control of your generative AI security.",
			"imgPreview": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3yOEeoBpzjcicmAF2xPv89/0ba5c796e1d48880ca4e57466706efba/OG_Share_2024__15_.png"
		},
		"primary_author": {},
		"publicly_index": true,
		"published_at": "2025-03-19T13:00+00:00",
		"slug": "take-control-of-public-ai-application-security-with-cloudflare-firewall-for-ai",
		"tags": [
			{
				"id": "3DmitkNK6euuD5BlhuvOLW",
				"name": "Security Week",
				"slug": "security-week"
			},
			{
				"id": "6Mp7ouACN2rT3YjL1xaXJx",
				"name": "Security",
				"slug": "security"
			},
			{
				"id": "6gMpGK5HugYKaxJbvTMOHp",
				"name": "LLM",
				"slug": "llm"
			},
			{
				"id": "7aiJ6fRFqrU0OyfOvaW264",
				"name": "Web Asset Discovery",
				"slug": "web-asset-discovery"
			}
		],
		"title": "Take control of public AI application security with Cloudflare's Firewall for AI",
		"updated_at": "2025-03-19T13:00:03.173Z",
		"url": "https://blog.cloudflare.com/take-control-of-public-ai-application-security-with-cloudflare-firewall-for-ai"
	},
	"translations": {
		"posts.by": "By",
		"footer.gdpr": "GDPR",
		"lang_blurb1": "This post is also available in {lang1}.",
		"lang_blurb2": "This post is also available in {lang1} and {lang2}.",
		"lang_blurb3": "This post is also available in {lang1}, {lang2} and {lang3}.",
		"footer.press": "Press",
		"header.title": "The Cloudflare Blog",
		"search.clear": "Clear",
		"search.filter": "Filter",
		"search.source": "Source",
		"footer.careers": "Careers",
		"footer.company": "Company",
		"footer.support": "Support",
		"footer.the_net": "theNet",
		"search.filters": "Filters",
		"footer.our_team": "Our team",
		"footer.webinars": "Webinars",
		"page.more_posts": "More posts",
		"posts.time_read": "{time} min read",
		"search.language": "Language",
		"footer.community": "Community",
		"footer.resources": "Resources",
		"footer.solutions": "Solutions",
		"footer.trademark": "Trademark",
		"header.subscribe": "Subscribe",
		"footer.compliance": "Compliance",
		"footer.free_plans": "Free plans",
		"footer.impact_ESG": "Impact/ESG",
		"posts.follow_on_X": "Follow on X",
		"footer.help_center": "Help center",
		"footer.network_map": "Network Map",
		"header.please_wait": "Please Wait",
		"page.related_posts": "Related posts",
		"search.result_stat": "Results <strong>{search_range}</strong> of <strong>{search_total}</strong> for <strong>{search_keyword}</strong>",
		"footer.case_studies": "Case Studies",
		"footer.connect_2024": "Connect 2024",
		"footer.terms_of_use": "Terms of Use",
		"footer.white_papers": "White Papers",
		"footer.cloudflare_tv": "Cloudflare TV",
		"footer.community_hub": "Community Hub",
		"footer.compare_plans": "Compare plans",
		"footer.contact_sales": "Contact Sales",
		"header.contact_sales": "Contact Sales",
		"header.email_address": "Email Address",
		"page.error.not_found": "Page not found",
		"footer.developer_docs": "Developer docs",
		"footer.privacy_policy": "Privacy Policy",
		"footer.request_a_demo": "Request a demo",
		"page.continue_reading": "Continue reading",
		"footer.analysts_report": "Analyst reports",
		"footer.for_enterprises": "For enterprises",
		"footer.getting_started": "Getting Started",
		"footer.learning_center": "Learning Center",
		"footer.project_galileo": "Project Galileo",
		"pagination.newer_posts": "Newer Posts",
		"pagination.older_posts": "Older Posts",
		"posts.social_buttons.x": "Discuss on X",
		"search.icon_aria_label": "Search",
		"search.source_location": "Source/Location",
		"footer.about_cloudflare": "About Cloudflare",
		"footer.athenian_project": "Athenian Project",
		"footer.become_a_partner": "Become a partner",
		"footer.cloudflare_radar": "Cloudflare Radar",
		"footer.network_services": "Network services",
		"footer.trust_and_safety": "Trust & Safety",
		"header.get_started_free": "Get Started Free",
		"page.search.placeholder": "Search Cloudflare",
		"footer.cloudflare_status": "Cloudflare Status",
		"footer.cookie_preference": "Cookie Preferences",
		"header.valid_email_error": "Must be valid email.",
		"search.result_stat_empty": "Results <strong>{search_range}</strong> of <strong>{search_total}</strong>",
		"footer.connectivity_cloud": "Connectivity cloud",
		"footer.developer_services": "Developer services",
		"footer.investor_relations": "Investor relations",
		"page.not_found.error_code": "Error Code: 404",
		"search.autocomplete_title": "Insert a query. Press enter to send",
		"footer.logos_and_press_kit": "Logos & press kit",
		"footer.application_services": "Application services",
		"footer.get_a_recommendation": "Get a recommendation",
		"posts.social_buttons.reddit": "Discuss on Reddit",
		"footer.sse_and_sase_services": "SSE and SASE services",
		"page.not_found.outdated_link": "You may have used an outdated link, or you may have typed the address incorrectly.",
		"footer.report_security_issues": "Report Security Issues",
		"page.error.error_message_page": "Sorry, we can't find the page you are looking for.",
		"header.subscribe_notifications": "Subscribe to receive notifications of new posts:",
		"footer.cloudflare_for_campaigns": "Cloudflare for Campaigns",
		"header.subscription_confimation": "Subscription confirmed. Thank you for subscribing!",
		"posts.social_buttons.hackernews": "Discuss on Hacker News",
		"footer.diversity_equity_inclusion": "Diversity, equity & inclusion",
		"footer.critical_infrastructure_defense_project": "Critical Infrastructure Defense Project"
	}
}