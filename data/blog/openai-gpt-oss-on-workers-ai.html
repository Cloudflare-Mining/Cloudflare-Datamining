<div class="mb2 gray5">3 min read</div><img class="mr2" src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3u7Xdt96jG4JXqVMYvTDLs/2ed329bac21f5c17fbbc3e843ddc980a/image2.png" alt="">
<div class="post-content lh-copy gray1">
	<p>OpenAI has just <a href="http://openai.com/index/introducing-gpt-oss"><u>announced their latest open-weight models</u></a> — and we are excited to share that we are working with them as a Day 0 launch partner to make these models available in Cloudflare's <a href="https://www.cloudflare.com/developer-platform/products/workers-ai">Workers AI</a>. Cloudflare developers can now access OpenAI's first open model, leveraging these powerful new capabilities on our platform. The new models are available starting today at <code>@cf/openai/gpt-oss-120b</code> and <code>@cf/openai/gpt-oss-20b</code>.</p>
	<p>Workers AI has always been a champion for open models and we’re thrilled to bring OpenAI's new open models to our platform today. Developers who want transparency, customizability, and deployment flexibility can rely on Workers AI as a place to deliver AI services. Enterprises that need the ability to run open models to ensure complete data security and privacy can also deploy with Workers AI. We are excited to join OpenAI in fulfilling their mission of making the benefits of AI broadly accessible to builders of any size.</p>
	<div class="flex anchor relative">
		<h3 id="the-technical-model-specs">The technical model specs</h3>
		<a href="https://blog.cloudflare.com/#the-technical-model-specs" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>The <a href="https://openai.com/index/gpt-oss-model-card"><u>OpenAI models</u></a> have been released in two sizes: a 120 billion parameter model and a 20 billion parameter model. Both of them are Mixture-of-Experts models – a popular architecture for recent model releases – that allow relevant experts to be called for a query instead of running through all the parameters of the model. Interestingly, these models run natively at an FP4 quantization, which means that they have a smaller GPU memory footprint than a 120 billion parameter model at FP16. Given the <a href="https://www.cloudflare.com/learning/ai/what-is-quantization">quantization</a> and the MoE architecture, the new models are able to run faster and more efficiently than more traditional dense models of that size.</p>
	<p>These models are text-only; however, they have reasoning capabilities, tool calling, and two new exciting features with Code Interpreter and Web Search (support coming soon). We’ve implemented Code Interpreter on top of <a href="https://blog.cloudflare.com/containers-are-available-in-public-beta-for-simple-global-and-programmable"><u>Cloudflare Containers</u></a> in a novel way that allows for stateful code execution (read on below).</p>
	<div class="flex anchor relative">
		<h3 id="the-model-on-workers-ai">The model on Workers AI</h3>
		<a href="https://blog.cloudflare.com/#the-model-on-workers-ai" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>We’re landing these new models with a few tweaks: supporting the new <a href="https://platform.openai.com/docs/api-reference/responses"><u>Responses API</u></a> format as well as the historical <a href="https://platform.openai.com/docs/guides/text?api-mode=chat"><u>Chat Completions API</u></a> format (coming soon). The Responses API format is recommended by OpenAI to interact with their models, and we’re excited to support that on Workers AI.</p>
	<p>If you call the model through:</p>
	<ul>
		<li>
			<p>Workers Binding, it will accept/return Responses API – <code>env.AI.run(“@cf/openai/gpt-oss-120b”)</code></p>
		</li>
		<li>
			<p>REST API on /run endpoint, it will accept/return Responses API – <code>https://api.cloudflare.com/client/v4/accounts/&lt;account_id&gt;/ai/run/@cf/openai/gpt-oss-120b</code></p>
		</li>
		<li>
			<p>REST API on new /responses endpoint, it will accept/return Responses API – <code>https://api.cloudflare.com/client/v4/accounts/&lt;account_id&gt;/ai/v1</code><code><b>/responses</b></code></p>
		</li>
		<li>
			<p>REST API for OpenAI Compatible endpoint, it will return Chat Completions (coming soon)– <code>https://api.cloudflare.com/client/v4/accounts/&lt;account_id&gt;/ai/v1/chat/completions</code></p>
		</li>
	</ul>
	<pre class="language-shell"><code class="language-shell">curl https://api.cloudflare.com/client/v4/accounts/&lt;account_id&gt;/ai/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $CLOUDFLARE_API_KEY" \
  -d '{
    "model": "@cf/openai/gpt-oss-120b",
    "reasoning": {"effort": "medium"},
    "input": [
      {
        "role": "user",
        "content": "What are the benefits of open-source models?"
      }
    ]
  }'
</code></pre>

	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6eUpzGy6RKcoPXd9MPBFSk/89d18f2535427cdb564426a4b33f9d4d/image1.png" alt="BLOG-2912 2" class="kg-image" width="1999" height="531" loading="lazy">
	</figure>
	<div class="flex anchor relative">
		<h3 id="code-interpreter-cloudflare-sandboxes-the-perfect-fit">Code Interpreter + Cloudflare Sandboxes = the perfect fit</h3>
		<a href="https://blog.cloudflare.com/#code-interpreter-cloudflare-sandboxes-the-perfect-fit" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>To effectively answer user queries, <a href="https://www.cloudflare.com/learning/ai/what-is-large-language-model">Large Language Models (LLMs)</a> often struggle with logical tasks such as mathematics or coding. Instead of attempting to reason through these problems, LLMs typically utilize a tool call to execute AI-generated code that solves these problems. OpenAI's new models are specifically trained for stateful Python code execution and include a built-in feature called Code Interpreter, designed to address this challenge.</p>
	<p>We’re particularly excited about this. Cloudflare not only has an inference platform (<a href="https://developers.cloudflare.com/workers-ai"><u>Workers AI</u></a>), but we also have an ecosystem of compute and storage products that allow people to build full applications on top of our <a href="https://www.cloudflare.com/developer-platform">Developer Platform</a>. This means that we are uniquely suited to support the model’s Code Interpreter capabilities, not only for one-time code execution, but for <i>stateful </i>code execution as well.</p>
	<p>We’ve built support for Code Interpreter on top of Cloudflare’s <a href="https://developers.cloudflare.com/changelog/2025-06-24-announcing-sandboxes"><u>Sandbox</u></a> product that allows for a secure environment to run AI-generated code. The <a href="https://github.com/cloudflare/sandbox-sdk"><u>Sandbox SDK</u></a> is built on our latest <a href="https://blog.cloudflare.com/containers-are-available-in-public-beta-for-simple-global-and-programmable"><u>Containers</u></a> product and Code Interpreter is the perfect use case to bring all these products together. When you use Code Interpreter, we spin up a Sandbox container scoped to your session that stays alive for 20 minutes, so the code can be edited for subsequent queries to the model. We’ve also pre-warmed Sandboxes for Code Interpreter to ensure the fastest start up times.</p>
	<p>We’ll be publishing an example of how you can use the gpt-oss model on Workers AI and Sandboxes with the OpenAI SDK to make calls to Code Interpreter on our <a href="https://developers.cloudflare.com/workers-ai/guides/demos-architectures"><u>Developer Docs</u></a>.</p>
	<div class="flex anchor relative">
		<h3 id="give-it-a-try">Give it a try!</h3>
		<a href="https://blog.cloudflare.com/#give-it-a-try" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>We’re beyond excited for OpenAI’s new open models, and we hope you are too. Super grateful to our friends from <a href="https://docs.vllm.ai/en/latest/index.html"><u>vLLM</u></a> and <a href="https://huggingface.co"><u>HuggingFace</u></a> for supporting efficient model serving on launch day. Read up on the <a href="https://developers.cloudflare.com/workers-ai/models/gpt-oss-120b"><u>Developer Docs</u></a> to learn more about the details and how to get started on building with these new models and capabilities.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4D11uWyDAooDrElGBVcL8f/568d689efc4e9ef56fe7c0eff0dc9d17/image3.png" alt="BLOG-2912 3" class="kg-image" width="1200" height="306" loading="lazy">
	</figure>
	<p></p>
</div>