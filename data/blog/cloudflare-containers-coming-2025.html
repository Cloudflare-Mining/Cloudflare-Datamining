<div class="mb2 gray5">12 min read</div><img class="mr2" src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4NhWmuxpd8JCJR7FL2UlvH/c754fcd867187fc7589e47fe84052164/Feature_Image.png" alt="">
<div class="post-content lh-copy gray1">
	<p>It is almost the end of Developer Week and we haven’t talked about containers: until now. As some of you <a href="https://blog.cloudflare.com/container-platform-preview"><u>may know</u></a>, we’ve been working on a container platform behind the scenes for some time.</p>
	<p>In late June, we plan to release Containers in open beta, and today we’ll give you a sneak peek at what makes it unique.</p>
	<p>Workers are the simplest way to ship software around the world with little overhead. But sometimes you need to do more. You might want to:</p>
	<ul>
		<li>
			<p>Run user-generated code in any language</p>
		</li>
		<li>
			<p>Execute a CLI tool that needs a full Linux environment</p>
		</li>
		<li>
			<p>Use several gigabytes of memory or multiple CPU cores</p>
		</li>
		<li>
			<p>Port an existing application from AWS, GCP, or Azure without a major rewrite</p>
		</li>
	</ul>
	<p>Cloudflare Containers let you do all of that while being simple, scalable, and global.</p>
	<p>Through a deep integration with <a href="https://www.cloudflare.com/developer-platform/products/workers">Workers</a> and an architecture built on <a href="https://www.cloudflare.com/developer-platform/products/durable-objects">Durable Objects</a>, Workers can be your:</p>
	<ul>
		<li>
			<p><b>API Gateway</b>: Letting you control routing, authentication, caching, and rate-limiting before requests reach a container</p>
		</li>
		<li>
			<p><b>Service Mesh</b>: Creating private connections between containers with a programmable routing layer</p>
		</li>
		<li>
			<p><b>Orchestrator</b>: Allowing you to write custom scheduling, scaling, and health checking logic for your containers</p>
		</li>
	</ul>
	<p>Instead of having to deploy new services, write custom Kubernetes operators, or wade through control plane configuration to extend the platform, you just write code.</p>
	<p>Let’s see what it looks like.</p>
	<div class="flex anchor relative">
		<h2 id="deploying-different-application-types">Deploying different application types</h2>
		<a href="https://blog.cloudflare.com/#deploying-different-application-types" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>

	<div class="flex anchor relative">
		<h3 id="a-stateful-workload-executing-ai-generated-code">A stateful workload: executing AI-generated code</h3>
		<a href="https://blog.cloudflare.com/#a-stateful-workload-executing-ai-generated-code" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>First, let’s take a look at a stateful example.</p>
	<p>Imagine you are building a platform where end-users can run code generated by an <a href="https://www.cloudflare.com/learning/ai/what-is-large-language-model">LLM</a>. This code is untrusted, so each user needs their own secure sandbox. Additionally, you want users to be able to run multiple requests in sequence, potentially writing to local files or saving in-memory state.</p>
	<p>To do this, you need to create a container on-demand for each user session, then route subsequent requests to that container. Here’s how you can accomplish this:</p>
	<p>First, you write some <a href="https://github.com/cloudflare/containers-demos/blob/main/ai/wrangler.jsonc#L6"><u>basic Wrangler config</u></a>, then you route requests to containers via your Worker:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">import { Container } from "cloudflare:workers";

export default {
  async fetch(request, env) {
    const url = new URL(request.url);

    if (url.pathname.startsWith("/execute-code")) {
      const { sessionId, messages } = await request.json();
      // pass in prompt to get the code from Llama 4
      const codeToExecute = await env.AI.run("@cf/meta/llama-4-scout-17b-16e-instruct", { messages });

      // get a different container for each user session
      const id = env.CODE_EXECUTOR.idFromName(sessionId);
      const sandbox = env.CODE_EXECUTOR.get(id);

      // execute a request on the container
      return sandbox.fetch("/execute-code", { method: "POST", body: codeToExecute });
    }

    // ... rest of Worker ...
  },
};

// define your container using the Container class from cloudflare:workers
export class CodeExecutor extends Container {
  defaultPort = 8080;
  sleepAfter = "1m";
}</code></pre>
	<p>Then, deploy your code with a single command: <code>wrangler deploy</code>. This builds your container image, pushes it to Cloudflare’s registry, readies containers to boot quickly across the globe, and deploys your Worker.</p>
	<pre class="language-Rust"><code class="language-Rust">$ wrangler deploy</code></pre>
	<p>That’s it.</p>
	<p>How does it work?</p>
	<p>Your Worker creates and starts up containers on-demand. Each time you call <code>env.CODE_EXECUTOR.get(id)</code> with a unique ID, it sends requests to a unique container instance. The container will automatically boot on the first <code>fetch</code>, then put itself to sleep after a configurable timeout, in this case 1 minute. You only pay for the time that the container is actively running.</p>
	<p>When you request a new container, we boot one in a Cloudflare location near the incoming request. This means that low-latency workloads are well-served no matter the region. Cloudflare takes care of all the pre-warming and caching so you don’t have to think about it.</p>
	<p>This allows each user to run code in their own secure environment.</p>
	<div class="flex anchor relative">
		<h3 id="stateless-and-global-ffmpeg-everywhere">Stateless and global: FFmpeg everywhere</h3>
		<a href="https://blog.cloudflare.com/#stateless-and-global-ffmpeg-everywhere" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Stateless and autoscaling applications work equally well on Cloudflare Containers.</p>
	<p>Imagine you want to run a container that takes a video file and turns it into an animated GIF using <a href="https://www.ffmpeg.org"><u>FFmpeg</u></a>. Unlike the previous example, any container can serve any request, but you still don’t want to send bytes across an ocean and back unnecessarily. So, ideally the app can be deployed everywhere.</p>
	<p>To do this, you declare a container in Wrangler config and turn on <code>autoscaling</code>. This specific configuration ensures that one instance is always running and if CPU usage increases beyond 75% of capacity, additional instances are added:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">"containers": [
  {
    "class_name": "GifMaker",
    "image": "./Dockerfile", // container source code can be alongside Worker code
    "instance_type": "basic",
    "autoscaling": {
      "minimum_instances": 1,
      "cpu_target": 75,
    }
  }
],
// ...rest of wrangler.jsonc...</code></pre>
	<p>To route requests, you just call <code>env.GIF_MAKER.fetch</code> and requests are automatically sent to the closest container:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">import { Container } from "cloudflare:workers";

export class GifMaker extends Container {
  defaultPort: 1337,
}

export default {
  async fetch(request, env) {
    const url = new URL(request.url);

    if (url.pathname === "/make-gif") {
      return env.GIF_MAKER.fetch(request)
    }

    // ... rest of Worker ...
  },
};</code></pre>

	<div class="flex anchor relative">
		<h3 id="going-beyond-the-basics">Going beyond the basics</h3>
		<a href="https://blog.cloudflare.com/#going-beyond-the-basics" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>From the examples above, you can see that getting a basic container service running on Workers just takes a few lines of config and a little Workers code. There’s no need to worry about capacity, artifact registries, regions, or scaling.</p>
	<p>For more advanced use, we’ve designed Cloudflare Containers to run on top of Durable Objects and work in tandem with Workers. Let’s take a look at the underlying architecture and see some of the advanced use cases it enables.</p>
	<div class="flex anchor relative">
		<h2 id="durable-objects-as-programmable-sidecars">Durable Objects as programmable sidecars</h2>
		<a href="https://blog.cloudflare.com/#durable-objects-as-programmable-sidecars" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Routing to containers is enabled using <a href="https://developers.cloudflare.com/durable-objects"><u>Durable Objects</u></a> under the hood. In the examples above, the <code>Container</code> class from <code>cloudflare:workers</code> just wraps a container-enabled Durable Object and provides helper methods for common patterns. In the rest of this post, we’ll look at examples using Durable Objects directly, as this should shed light on the platform’s underlying design.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/tEAz34lNlHaJtLQVp1qia/734fc01c90e2aca8e5d75c060f09be9e/1.png" alt="" class="kg-image" width="1720" height="860" loading="lazy">
	</figure>
	<p>Each Durable Object acts as a programmable sidecar that can proxy requests to the container and manages its lifecycle. This allows you to control and extend your containers in ways that are hard on other platforms.&nbsp;</p>
	<p>You can manually start, stop, and execute commands on a specific container by calling RPC methods on its Durable Object, which now has a new object at <code>this.ctx.container</code>:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">class MyContainer extends DurableObject {
  // these RPC methods are callable from a Worker
  async customBoot(entrypoint, envVars) {
    this.ctx.container.start({ entrypoint, env: envVars });
  }

  async stopContainer() {
    const SIGTERM = 15;
    this.ctx.container.signal(SIGTERM);
  }

  async startBackupScript() {
    await this.ctx.container.exec(["./backup"]);
  }
}</code></pre>
	<p>You can also monitor your container and run hooks in response to Container status changes.</p>
	<p>For instance, say you have a CI job that runs builds in a Container. You want to post a message to a <a href="https://developers.cloudflare.com/queues"><u>Queue</u></a> based on the exit status. You can easily program this behavior:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">class BuilderContainer extends DurableObject {
  constructor(ctx, env) {
    super(ctx, env)
    async function onContainerExit() {
      await this.env.QUEUE.send({ status: "success", message: "Build Complete" });
    }

    async function onContainerError(err) {
      await this.env.QUEUE.send({ status: "error", message: err});
    }

    this.ctx.container.start();
    this.ctx.container.monitor().then(onContainerExit).catch(onContainerError); 
  }

  async isRunning() { return this.ctx.container.running; }
}</code></pre>
	<p>And lastly, if you have state that needs to be loaded into a container each time it runs, you can use status hooks to persist state from the container before it sleeps and to reload state into the container after it starts:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">import { startAndWaitForPort } from "./helpers"

class MyContainer extends DurableObject {
  constructor(ctx, env) {
    super(ctx, env)
    this.ctx.blockConcurrencyWhile(async () =&gt; {
      this.ctx.storage.sql.exec('CREATE TABLE IF NOT EXISTS state (value TEXT)');
      this.ctx.storage.sql.exec("INSERT INTO state (value) SELECT '' WHERE NOT EXISTS 
(SELECT * FROM state)");
      await startAndWaitForPort(this.ctx.container, 8080);
      await this.setupContainer();
      this.ctx.container.monitor().then(this.onContainerExit); 
    });
  }

  async setupContainer() {
    const initialState = this.ctx.storage.sql.exec('SELECT * FROM state LIMIT 1').one().value;
    return this.ctx.container
      .getTcpPort(8080)
      .fetch("http://container/state", { body: initialState, method: 'POST' });
  }

  async onContainerExit() {
    const response = await this.ctx.container
      .getTcpPort(8080)
      .fetch('http://container/state');
    const newState = await response.text();
    this.ctx.storage.sql.exec('UPDATE state SET value = ?', newState);
  }
}</code></pre>

	<div class="flex anchor relative">
		<h2 id="building-around-your-containers-with-workers">Building around your Containers with Workers</h2>
		<a href="https://blog.cloudflare.com/#building-around-your-containers-with-workers" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Not only do Durable Objects allow you to have fine-grained control over the Container lifecycle, the whole Workers platform allows you to extend routing and scheduling behavior as you see fit.</p>
	<div class="flex anchor relative">
		<h3 id="using-workers-as-an-api-gateway">Using Workers as an API gateway</h3>
		<a href="https://blog.cloudflare.com/#using-workers-as-an-api-gateway" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Workers provide programmable ingress logic from <a href="https://www.cloudflare.com/network"><u>over 300 locations</u></a> around the world. In this sense, they provide similar functionality to an <a href="https://www.cloudflare.com/learning/security/api/what-is-an-api-gateway">API gateway</a>.</p>
	<p>For instance, let’s say you want to route requests to a different version of a container based on information in a header. This is accomplished in a few lines of code:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">export default {
  async fetch(request, env) {
    const isExperimental = request.headers.get("x-version") === "experimental";
    
    if (isExperimental) {
      return env.MY_SERVICE_EXPERIMENTAL.fetch(request);
    } else {
      return env.MY_SERVICE_STANDARD.fetch(request);
    }
  },
};</code></pre>
	<p>Or you want to rate limit and authenticate requests to the container:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">async fetch(request, env) {
  const url = new URL(request.url);

  if (url.pathname.startsWith('/api/')) {
    const token = request.headers.get("token");

    const isAuthenticated = await authenticateRequest(token);
    if (!isAuthenticated) {
      return new Response("Not authenticated", { status: 401 });
    }

    const { withinRateLimit } = await env.MY_RATE_LIMITER.limit({ key: token });
    if (!withinRateLimit) {
      return new Response("Rate limit exceeded for token", { status: 429 });
    }

    return env.MY_APP.fetch(request);
  }
  // ...
}</code></pre>

	<div class="flex anchor relative">
		<h3 id="using-workers-as-a-service-mesh">Using Workers as a service mesh</h3>
		<a href="https://blog.cloudflare.com/#using-workers-as-a-service-mesh" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>

	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/56gJk7HEDJs4dsNXDkBX1x/7c9d6be661d0cd6baea13caeedf478c0/2.png" alt="" class="kg-image" width="1999" height="1000" loading="lazy">
	</figure>
	<p>By default, Containers are private and can only be accessed via Workers, which can connect to one of many container ports. From within the container, you can expose a plain HTTP port, but requests will still be encrypted from the end user to the moment we send the data to the container’s TCP port in the host. Due to the communication being relayed through the Cloudflare network, the container does not need to set up <a href="https://www.cloudflare.com/application-services/products/ssl">TLS certificates</a> to have secure connections in its open ports.</p>
	<p>You can connect to the container through a WebSocket from the client too. See <a href="https://github.com/cloudflare/containers-demos/tree/main/websockets"><u>this repository</u></a> for a full example of using Websockets.</p>
	<p>Just as the Durable Object can act as proxy <i>to the container</i>, it can act as a proxy <i>from the container </i>as well. When setting up a container, you can toggle Internet access off and ensure that outgoing requests pass through Workers.</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">// ... when starting the container...
this.ctx.container.start({ 
  workersAddress: '10.0.0.2:8080',
  enableInternet: false, // 'enableInternet' is false by default
});

// ... container requests to '10.0.0.2:8080' securely route to a different service...
override async onContainerRequest(request: Request) {
  const containerId = this.env.SUB_SERVICE.idFromName(request.headers['X-Account-Id']);
  return this.env.SUB_SERVICE.get(containerId).fetch(request);
}</code></pre>
	<p>You can ensure all traffic in and out of your container is secured and encrypted end to end without having to deal with networking yourself.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/9PzlxveRZ6NNBiNeZTiWs/c70e5db9cc7d63c02a21f21769801bc4/3.png" alt="" class="kg-image" width="1999" height="1000" loading="lazy">
	</figure>
	<p>This allows you to protect and connect containers within Cloudflare’s network… or even when connecting to <a href="https://blog.cloudflare.com/workers-virtual-private-cloud"><u>external private networks</u></a>.</p>
	<div class="flex anchor relative">
		<h3 id="using-workers-as-an-orchestrator">Using Workers as an orchestrator</h3>
		<a href="https://blog.cloudflare.com/#using-workers-as-an-orchestrator" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>You might require custom scheduling and scaling logic that goes beyond what Cloudflare provides out of the box.</p>
	<p>We don’t want you having to manage complex chains of API calls or writing an <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator"><u>operator</u></a> to get the logic you need. Just write some Worker code.</p>
	<p>For instance, imagine your containers have a long startup period that involves loading data from an external source. You need to pre-warm containers manually, and need control over the specific region to prewarm. Additionally, you need to set up manual health checks that are accessible via Workers. You’re able to achieve this fairly simply with Workers and Durable Objects.</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">import { Container, DurableObject } from "cloudflare:workers";

// A singleton Durable Object to manage and scale containers

class ContainerManager extends DurableObject {
  scale(region, instanceCount) {
    for (let i = 0; i &lt; instanceCount; i++) {
      const containerId = env.CONTAINER.idFromName(`instance-${region}-${i}`);
      // spawns a new container with a location hint
      await env.CONTAINER.get(containerId, { locationHint: region }).start();
    }
  }

  async setHealthy(containerId, isHealthy) {
    await this.ctx.storage.put(containerId, isHealthy);
  }
}

// A Container class for the underlying compute

class MyContainer extends Container {
  defaultPort = 8080;

  async onContainerStart() {
    // run healthcheck every 500ms
    await this.scheduleEvery(0.5, 'healthcheck');
  }

  async healthcheck() {
    const manager = this.env.MANAGER.get(
      this.env.MANAGER.idFromName("manager")
    );
    const id = this.ctx.id.toString();

    await this.container.fetch("/_health")
      .then(() =&gt; manager.setHealthy(id, true))
      .catch(() =&gt; manager.setHealthy(id, false));
  }
}</code></pre>
	<p>The <code>ContainerManager </code>Durable Object exposes the <code>scale</code> RPC call, which you can call as needed with a <code>region</code> and <code>instanceCount</code> which scales up the number of active Container instances in a given region <a href="https://developers.cloudflare.com/durable-objects/reference/data-location/#provide-a-location-hint"><u>using a location hint</u></a>. The <code>this.schedule</code> code executes a manually defined <code>healthcheck</code> method on the Container and tracks its state in the Manager for use by other logic in your system.</p>
	<p>These building blocks let users handle complex scheduling logic themselves. For a more detailed example using standard Durable Objects, see <a href="https://github.com/cloudflare/containers-demos/tree/main/load-balancer"><u>this repository</u></a>.</p>
	<p>We are excited to see the patterns you come up with when orchestrating complex applications built with containers, and trust that between Workers and Durable Objects, you’ll have the tools you need.</p>
	<div class="flex anchor relative">
		<h2 id="integrating-with-more-of-cloudflares-developer-platform">Integrating with more of Cloudflare’s Developer Platform</h2>
		<a href="https://blog.cloudflare.com/#integrating-with-more-of-cloudflares-developer-platform" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Since it is <a href="https://blog.cloudflare.com/welcome-to-developer-week-2025"><u>Developer Week 2025</u></a>, we would be remiss to not talk about <a href="https://developers.cloudflare.com/workflows"><u>Workflows</u></a>, which <a href="https://blog.cloudflare.com/workflows-ga-production-ready-durable-execution"><u>just went GA</u></a>, and <a href="https://agents.cloudflare.com"><u>Agents</u></a>, which <a href="https://blog.cloudflare.com/building-ai-agents-with-mcp-authn-authz-and-durable-objects"><u>just got even better</u></a>.</p>
	<p>Let’s finish up by taking a quick look at how you can integrate Containers with these two tools.</p>
	<div class="flex anchor relative">
		<h3 id="running-a-short-lived-job-with-workflows-r2">Running a short-lived job with Workflows &amp; R2</h3>
		<a href="https://blog.cloudflare.com/#running-a-short-lived-job-with-workflows-r2" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>You need to download a large file from <a href="https://developers.cloudflare.com/r2"><u>R2</u></a>, compress it, and upload it. You want to ensure that this succeeds, but don’t want to write retry logic and error handling yourself. Additionally, you don’t want to deal with rotating R2 API tokens or worry about network connections — it should be secure by default.</p>
	<p>This is a perfect opportunity for a <a href="https://developers.cloudflare.com/workflows"><u>Workflow</u></a> using Containers. The container can do the heavy lifting of compressing files, Workers can stream the data to and from R2, and the Workflow can ensure durable execution.</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">export class EncoderWorkflow extends WorkflowEntrypoint&lt;Env, Params&gt; {
  async run(event: WorkflowEvent&lt;Params&gt;, step: WorkflowStep) {
    const id = this.env.ENCODER.idFromName(event.instanceId);
    const container = this.env.ENCODER.get(id);

    await step.do('init container', async () =&gt; {
      await container.init();
    });

    await step.do('compress the object with zstd', async () =&gt; {
      await container.ensureHealthy();
      const object = await this.env.ARTIFACTS.get(event.payload.r2Path);
      const result = await container.fetch('http://encoder/zstd', {
        method: 'POST', body: object.body 
      });
      await this.env.ARTIFACTS.put(`results${event.payload.r2Path}`, result.body);
    });

    await step.do('cleanup container', async () =&gt; {
      await container.destroy();
    });
  }
}</code></pre>

	<div class="flex anchor relative">
		<h3 id="calling-a-container-from-an-agent">Calling a Container from an Agent</h3>
		<a href="https://blog.cloudflare.com/#calling-a-container-from-an-agent" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Lastly, imagine you have an AI agent that needs to spin up cloud infrastructure (you like to live dangerously). To do this, you want to use <a href="https://github.com/hashicorp/terraform"><u>Terraform</u></a>, but since it’s run from the command line, you can’t run it on Workers.</p>
	<p>By defining a <a href="https://developers.cloudflare.com/agents/concepts/tools"><u>tool</u></a>, you can enable your Agent to run the shell commands from a container:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">// Make tools that call to a container from an agent

const createExternalResources = tool({
  description: "runs Terraform in a container to create resources",
  parameters: z.object({ sessionId: z.number(), config: z.string() }),
  execute: async ({ sessionId, config }) =&gt; {
    return this.env.TERRAFORM_RUNNER.get(sessionId).applyConfig(config);
  },
});

// Expose RPC Methods that call to the container

class TerraformRunner extends DurableObject {
  async applyConfig(config) {
    await this.ctx.container.getTcpPort(8080).fetch(APPLY_URL, {
      method: 'POST',
      body: JSON.stringify({ config }),
    });
  }

  // ...rest of DO...
}</code></pre>
	<p>Containers are so much more powerful when combined with other tools. Workers make it easy to do so in a secure and simple way.</p>
	<div class="flex anchor relative">
		<h2 id="pay-for-what-you-use-and-use-the-right-tool">Pay for what you use and use the right tool</h2>
		<a href="https://blog.cloudflare.com/#pay-for-what-you-use-and-use-the-right-tool" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>The deep integration between Workers and Containers also makes it easy to pick the right tool for the job with regards to cost.</p>
	<p>With Cloudflare Containers, you only pay for what you use. Charges start when a request is sent to the container or it is manually started. Charges stop after the container goes to sleep, which can happen automatically after a configurable timeout. This makes it easy to scale to zero, and allows you to get high utilization even with highly-variable traffic.</p>
	<p>Containers are billed for every 10ms that they are actively running at the following rates:</p>
	<ul>
		<li>
			<p>Memory: $0.0000025 per GB-second</p>
		</li>
		<li>
			<p>CPU: $0.000020 per vCPU-second</p>
		</li>
		<li>
			<p>Disk $0.00000007 per GB-second
			</p>
		</li>
	</ul>
	<p>After 1 TB of free data transfer per month, egress from a Container will be priced per-region. We'll be working out the details between now and the beta, and will be launching with clear, transparent pricing across all dimensions so you know where you stand.</p>
	<p>Workers are lighter weight than containers and <a href="https://blog.cloudflare.com/workers-pricing-scale-to-zero"><u>save you money by not charging when waiting on I/O</u></a>. This means that if you can, running on a Worker helps you save on cost. Luckily, on Cloudflare it is easy to route requests to the right tool.</p>
	<div class="flex anchor relative">
		<h3 id="cost-comparison">Cost comparison</h3>
		<a href="https://blog.cloudflare.com/#cost-comparison" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Comparing containers and functions services on paper is always going to be an apples to oranges exercise, and results can vary so much depending on use case. But to share a real example of our own, a year ago when Cloudflare acquired Baselime, Baselime was a heavy user of AWS Lambda. By moving to Cloudflare, <a href="https://blog.cloudflare.com/80-percent-lower-cloud-cost-how-baselime-moved-from-aws-to-cloudflare"><u>they lowered their cloud compute bill by 80%</u></a>.</p>
	<p>Below we wanted to share one representative example that compares costs for an application that uses both containers and serverless functions together. It’d be easy for us to come up with a contrived example that uses containers sub-optimally on another platform, for the wrong types of workloads. We won’t do that here. We know that navigating cloud costs can be challenging, and that cost is a critical part of deciding what type of compute to use for which pieces of your application.</p>
	<p>In the example below, we’ll compare Cloudflare Containers + Workers against Google Cloud Run, a very well-regarded container platform that we’ve been impressed by.</p>
	<div class="flex anchor relative">
		<h4 id="example-application">Example application</h4>
		<a href="https://blog.cloudflare.com/#example-application" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Imagine that you run an application that serves 50 million requests per month, and each request consumes an average 500 ms of wall-time. Requests to this application are not all the same though — half the requests require a container, and the other half can be served just using serverless functions.</p>
	<table>
		<tbody>
			<tr>
				<td>
					<p>Requests per month</p>
				</td>
				<td>
					<p>Wall-time (duration)</p>
				</td>
				<td>
					<p>Compute required</p>
				</td>
				<td>
					<p>Cloudflare</p>
				</td>
				<td>
					<p>Google Cloud</p>
				</td>
			</tr>
			<tr>
				<td>
					<p>25 million</p>
				</td>
				<td>
					<p>500ms</p>
				</td>
				<td>
					<p>Container + serverless functions</p>
				</td>
				<td>
					<p>Containers + Workers</p>
				</td>
				<td>
					<p>Google Cloud Run + Google Cloud Run Functions</p>
				</td>
			</tr>
			<tr>
				<td>
					<p>25 million</p>
				</td>
				<td>
					<p>500ms</p>
				</td>
				<td>
					<p>Serverless functions</p>
				</td>
				<td>
					<p>Workers</p>
				</td>
				<td>
					<p>Google Cloud Run Functions</p>
				</td>
			</tr>
		</tbody>
	</table>
	<div class="flex anchor relative">
		<h4 id="container-pricing">Container pricing</h4>
		<a href="https://blog.cloudflare.com/#container-pricing" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>On both Cloud Run and Cloudflare Containers, a container can serve multiple requests. On some platforms, such as AWS Lambda, each container instance is limited to a single request, pushing cost up significantly as request count grows. In this scenario, 50 requests can run simultaneously on a container with 4 GB memory and half of a vCPU. This means that to serve 25 million requests of 500ms each, we need 625,000 seconds worth of compute</p>
	<p>In this example, traffic is bursty and we want to avoid paying for idle-time, so we’ll use Cloud Run’s request-based pricing.</p>
	<table>
		<tbody>
			<tr>
				<td>
					<p>
					</p>
				</td>
				<td>
					<p>Price per vCPU second</p>
				</td>
				<td>
					<p>Price per GB-second of memory</p>
				</td>
				<td>
					<p>Price per 1m requests</p>
				</td>
				<td>
					<p>Monthly Price for Compute + Requests</p>
				</td>
			</tr>
			<tr>
				<td>
					<p>Cloudflare Containers</p>
				</td>
				<td>
					<p>$0.000020</p>
				</td>
				<td>
					<p>$0.0000025</p>
				</td>
				<td>
					<p>$0.30</p>
				</td>
				<td>
					<p>$20.00</p>
				</td>
			</tr>
			<tr>
				<td>
					<p>Google Cloud Run</p>
				</td>
				<td>
					<p>$0.000024</p>
				</td>
				<td>
					<p>$0.0000025</p>
				</td>
				<td>
					<p>$0.40</p>
				</td>
				<td>
					<p>$23.75</p>
				</td>
			</tr>
		</tbody>
	</table>
	<p><sup><i>* Comparison does not include free tiers for either provider and uses a single Tier 1 GCP region</i></sup></p>
	<p>Compute pricing for both platforms are comparable. But as we showed earlier in this post, Containers on Cloudflare run anywhere, on-demand, without configuring and managing regions. Each container has a programmable sidecar with its own database, backed by Durable Objects. It’s the depth of integration with the rest of the platform that makes containers on Cloudflare uniquely programmable.</p>
	<div class="flex anchor relative">
		<h4 id="function-pricing">Function pricing</h4>
		<a href="https://blog.cloudflare.com/#function-pricing" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>The other requests can be served with less compute, and code written in <a href="https://developers.cloudflare.com/workers/languages/javascript"><u>JavaScript</u></a>, <a href="https://developers.cloudflare.com/workers/languages/typescript"><u>TypeScript</u></a>, <a href="https://developers.cloudflare.com/workers/languages/python"><u>Python</u></a> or <a href="https://developers.cloudflare.com/workers/languages/rust"><u>Rust</u></a>, so we’ll use Workers and Cloud Run Functions.</p>
	<p>These 25 million requests also run for 500 ms each, and each request spends 480 ms waiting on I/O. This means that Workers will <a href="https://blog.cloudflare.com/workers-pricing-scale-to-zero"><u>only charge for 20 ms of “CPU-time”</u></a>, the time that the Worker actually spends using compute. This ratio of low CPU time to high wall time is extremely common when building AI apps that make inference requests, or even when just building REST APIs and other business logic. Most time is spent waiting on I/O. Based on our data, we typically see Workers use less than 5 ms of CPU time per request vs seconds of wall time (waiting on APIs or I/O).</p>
	<p>The Cloud Run Function will use an instance with 0.083 vCPU and 128 MB memory and charge on both CPU-s and GiB-s for the full 500 ms of wall-time.</p>
	<table>
		<tbody>
			<tr>
				<td>
					<p>
					</p>
				</td>
				<td>
					<p>Total Price for “wall-time”</p>
				</td>
				<td>
					<p>Total Price for “CPU-time”</p>
				</td>
				<td>
					<p>Total Price for Compute + Requests</p>
				</td>
			</tr>
			<tr>
				<td>
					<p>Cloudflare Workers</p>
				</td>
				<td>
					<p>N/A</p>
				</td>
				<td>
					<p>$0.83</p>
				</td>
				<td>
					<p>$8.33</p>
				</td>
			</tr>
			<tr>
				<td>
					<p>Google Cloud Run Functions</p>
				</td>
				<td>
					<p>$1.44</p>
				</td>
				<td>
					<p>N/A</p>
				</td>
				<td>
					<p>$11.44</p>
				</td>
			</tr>
		</tbody>
	</table>
	<p><sup><i>* Comparison does not include free tiers and uses a single Tier 1 GCP region.</i></sup></p>
	<p>This comparison assumes you have configured Google Cloud Run Functions with a max of 20 concurrent requests per instance. On Google Cloud Run Functions, the maximum number of concurrent requests an instance can handle varies based on the efficiency of your function, and your own tolerance for tail latency that can be introduced by traffic spikes.&nbsp;</p>
	<p>Workers automatically scale horizontally, don’t require you to configure concurrency settings (and hope to get it right), and can run in <a href="https://www.cloudflare.com/en-gb/network"><u>over 300 locations</u></a>.</p>
	<div class="flex anchor relative">
		<h4 id="a-holistic-view-of-costs">A holistic view of costs</h4>
		<a href="https://blog.cloudflare.com/#a-holistic-view-of-costs" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>The most important cost metric is the total cost of developing and running an application. And the only way to get the best results is to use the right compute for the job. So the question boils down to friction and integration. How easily can you integrate the ideal building blocks together?</p>
	<p>As more and more software makes use of <a href="https://www.cloudflare.com/learning/ai/what-is-generative-ai">generative AI</a>, and makes inference requests to LLMs, modern applications must communicate and integrate with a myriad of services. Most systems are increasingly real-time and chatty, often holding open long-lived connections, performing tasks in parallel. Running an instance of an application in a VM or container and calling it a day might have worked 10 years ago, but when we talk to developers in 2025, they are most often bringing many forms of compute to the table for particular use cases.</p>
	<p>This shows the importance of picking a platform where you can seamlessly shift traffic from one source of compute to another. If you want to <a href="https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit"><u>rate-limit</u></a>, <a href="https://blog.cloudflare.com/full-stack-development-on-cloudflare-workers"><u>serve server-side rendered pages, API responses and static assets</u></a>, handle authentication and authorization, make<a href="https://developers.cloudflare.com/workers-ai"><u> inference requests to AI models</u></a>, run core business logic via <a href="https://blog.cloudflare.com/workflows-ga-production-ready-durable-execution"><u>Workflows</u></a>, or <a href="https://blog.cloudflare.com/cloudflare-acquires-arroyo-pipelines-streaming-ingestion-beta"><u>ingest streaming data</u></a>, just handle the request in Workers. Save the heavier compute only for where it is actually the only option. With Cloudflare Workers and Containers, this is as simple as an if-else statement in your Worker. This makes it easy to pick the right tool for the job.</p>
	<div class="flex anchor relative">
		<h2 id="coming-june-2025">Coming June 2025</h2>
		<a href="https://blog.cloudflare.com/#coming-june-2025" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>We are collecting feedback and putting the finishing touches on our APIs now, and will release the open beta to the public in late June 2025.</p>
	<p>From day one of building Cloudflare Workers, it’s been our goal to build an integrated platform, where Cloudflare products work together as a system, rather than just as a collection of separate products. We’ve taken this same approach with Containers, and aim to make Cloudflare not only the best place to deploy containers across the globe, but the best place to deploy the types of complete applications that developers are building, that use containers in tandem with serverless functions, <a href="https://developers.cloudflare.com/workflows"><u>Workflows</u></a>, <a href="https://agents.cloudflare.com"><u>Agents</u></a>, and <a href="https://developers.cloudflare.com"><u>much more</u></a>.</p>
	<p>We’re excited to get this into your hands soon. Stay on the lookout this summer.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6tb0K0eJoK6L4QrUCTWISx/4346edb7593b47768cebcb48369cfa35/4.png" alt="" class="kg-image" width="1999" height="550" loading="lazy">
	</figure>
	<p></p>
</div>