<div class="post-content lh-copy gray1">
	<p>两周前，我们写了关于<a href="https://blog.cloudflare.com/cloudflares-response-to-csam-online/">Cloudflare处理儿童性虐待材料（CSAM）的方法</a>。在2010年，我们向公共推出服务的几个月内，我们首次与美国国家失踪与受虐儿童中心（NCMEC）合作，NCMEC是一家总部位于美国的组织，是消除这种可憎内容的信息交流中心。过去九年来，我们的信任&amp;安全团队与<a href="http://www.missingkids.com/" target="_blank">NCMEC</a>，国际刑警组织（<a href="https://www.interpol.int/en/Crimes/Crimes-against-children" target="_blank">Interpol</a>）以及全球近60个其他公共和私人机构合作设计了我们的项目。我们为从互联网上移除CSAM内容所做的工作而感到自豪。</p>
	<p>在某些方面，最令人讨厌的案例是我们最容易解决的。尽管Cloudflare无法删除其他人托管的内容，但是如果该站点很明显专用于共享CSAM，或者如果该站点的运营商及其托管商无法采取适当措施，那么我们将采取步骤终止对该站点的服务。当我们终止网站时，我们会清除缓存——这在全球范围内几秒钟内就会生效——我们还会阻止网站再次使用Cloudflare的网络。</p>
	<h2 id="-">解决棘手的问题</h2>
	<p>困难的情况是，当我们的客户运行一个允许用户生成内容（比如论坛）的服务时，用户上传了CSAM，或者他们被黑客攻击了，或者有恶意员工将CSAM存储在其服务器上。我们已经看到了很多这样的例子，那些想要做正确事情的服务完全被CSAM打了个措手不及，而CSAM最终出现在了它们的站点上。尽管在这些情况下客户站点并非主观或恶意，但我们仍然需要快速识别并删除该内容。</p>
	<p>今天，我们很自豪可以采取措施，帮助处理这些困难的情况。从今天开始，每个Cloudflare客户都可以登录到他们的控制面板，并启用对CSAM扫描工具的访问。随着CSAM扫描工具扫过从开发到生产的整个过程，该工具将检查启用了CSAM扫描的所有互联网属性是否包含此非法内容。当Cloudflare标记到CSAM材料时，它将自动向您发送通知，阻止访问该内容（使用451“出于法律原因被阻止”状态码），并采取措施支持对该内容的正确报告，以遵守法律义务。</p>
	<figure class="kg-card kg-image-card kg-width-wide"><img src="https://blog.cloudflare.com/content/images/2020/02/csam-tool.png" class="kg-image"></figure>
	<p>CSAM扫描将通过Cloudflare控制面板免费提供给所有客户，无论他们的计划级别如何。您可以在控制面板的“缓存”选项卡中找到此工具。我们希望，通过向所有客户免费开放这一工具，我们可以为在线对抗CSAM做出更大的贡献，并帮助保护我们的客户免受CSAM可能给他们的业务带来的法律和声誉风险。</p>
	<p>这是一个漫长的旅程，我们可以承诺为我们的数百万用户提供这项服务。要从技术和政策的角度理解我们在做什么，以及为什么它具有挑战性，您需要对跟踪CSAM的最新技术有所了解。</p>
	<h2 id="--1">寻找相似图片</h2>
	<p>Cloudflare于2009年首次构想这一技术，与此同时，达特茅斯大学的一位名叫Hany Farid的教授正在研究一种可以将图像与NCMEC维护的哈希表进行比较的软件。微软率先开发了一个名为PhotoDNA的工具，该工具利用Farid教授的研究成果来自动识别CSAM。</p>
	<p>早期，微软在内部将PhotoDNA用于其服务，并在2009年底<a href="https://blogs.msdn.com/b/microsoftuseducation/archive/2009/12/17/microsoft-donates-photodna-technology-to-make-the-internet-safer-for-kids.aspx" target="_blank">将这一技术捐赠给了NCMEC</a>，以帮助管理其他组织对它的使用。社交网络中有一些最早的采用者。2011年，<a href="http://www.huffingtonpost.com/2011/05/20/facebook-photodna-microsoft-child-pornography_n_864695.html" target="_blank">Facebook推出了一项技术实施</a>，作为滥用程序的一部分。<a href="https://www.theguardian.com/technology/2013/jul/22/twitter-photodna-child-abuse" target="_blank">Twitter在2014年将其合并</a>。</p>
	<p>这个过程称为模糊哈希。传统的哈希算法（如MD5、SHA1和SHA256）采用任意长度的文件（如图像或文档），并输出一个固定长度的数字，该数字实际上就是文件的数字指纹。例如，如果您对此图片采用MD5算法，则生成的指纹为<strong>605c83bf1bba62e85f4f5fccc56bc128</strong>。</p>
	<figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://blog.cloudflare.com/content/images/2020/02/base-image.jpg" class="kg-image">
		<figcaption>基本图像</figcaption>
	</figure>
	<p>如果我们将图片中的一个像素从纯白色改为略偏白色，它在视觉上是一样的，但是指纹完全变成了<strong>42ea4fb30a440d8787477c6c37b9daed</strong>。正如您可以从两个指纹中看到的，对图像的一个小更改会导致对传统哈希输出的一个巨大的、不可预测的更改。</p>
	<figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://blog.cloudflare.com/content/images/2020/02/base-image-pixel-changed.jpg" class="kg-image">
		<figcaption>更改了单个像素的基本图像</figcaption>
	</figure>
	<p></p>
	<p>这对于哈希的某些用途非常有用，在这些用途中，您要确定正在查看的文档是否与您之前看到的文档完全相同。例如，如果有人在数字契约中添加了额外的零，那么您会希望其签名中使用的文档的哈希不再有效。</p>
	<h2 id="--2">模糊哈希</h2>
	<p>然而，在CSAM的情况下，这种传统哈希的特性是一种不利条件。为了避免被发现，发布CSAM的罪犯会调整大小，添加噪音，或者以其他方式改变图像，使其看起来一样，但结果会产生完全不同的哈希值。</p>
	<p>模糊散列的工作方式有所不同。它并非确定两张照片是否完全相同，而是尝试了解一张照片的本质。这使软件可以计算两个图像的哈希值，然后比较两个图像之间的“差距”。虽然经过修改的两张照片之间的模糊哈希可能仍然不同，但与传统哈希方法不同的是，您可以将两者进行比较，以查看图像的相似程度。</p>
	<p>因此，在上面的两张图片中，第一张图片的模糊哈希是</p>
	<pre><code>00e308346a494a188e1042333147267a
653a16b94c33417c12b433095c318012
5612442030d1484ce82c613f4e224733
1dd84436734e4a5c6e25332e507a8218
6e3b89174e30372d</code></pre>
	<p>以及第二张图片是</p>
	<pre><code>00e308346a494a188e1042333147267a
653a16b94c33417c12b433095c318012
5612442030d1484ce82c613f4e224733
1dd84436734e4a5c6e25332e507a8218
6e3b89174e30372d</code></pre>
	<p>两者之间在像素方面只有细微的差别，并且模糊散列是相同的。</p>
	<figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://blog.cloudflare.com/content/images/2020/02/base-image-altered-2.jpeg" class="kg-image">
		<figcaption>增加饱和度，更改为棕褐色，添加边框然后添加随机噪声后的基本图像。</figcaption>
	</figure>
	<p></p>
	<p>模糊哈希是为了能够识别本质上相似的图像而设计的。例如，我们对狗的图像进行了修改，首先增强颜色，然后将其改为棕褐色，然后添加边框，最后添加随机噪声来修改狗的图像。新图像的模糊哈希为</p>
	<pre><code>00d9082d6e454a19a20b4e3034493278
614219b14838447213ad3409672e7d13
6e0e4a2033de545ce731664646284337
1ecd4038794a485d7c21233f547a7d2e
663e7c1c40363335</code></pre>
	<p>这看起来与上面未修改图像的哈希非常不同，但是我们可以通过查看模糊哈希值彼此之间的差距来进行比较。</p>
	<p>两幅图像之间的最大可能差距约为5百万单位。这两个模糊哈希值之间只相差4913个单位（数字越小，图像越相似），这表明它们实质上是相同的图像。</p>
	<p>将其与两张无关的照片进行比较。下图的模糊散列为</p>
	<pre><code>011a0d0323102d048148c92a4773b60d
0d343c02120615010d1a47017d108b14
d36fff4561aebb2f088a891208134202
3e21ff5b594bff5eff5bff6c2bc9ff77
1755ff511d14ff5b</code></pre>
	<figure class="kg-card kg-image-card kg-width-wide"><img src="https://blog.cloudflare.com/content/images/2020/02/image-1.jpg" class="kg-image"></figure>
	<p>下图的模糊散列为</p>
	<pre><code>062715154080356b8a52505955997751
9d221f4624000209034f1227438a8c6a
894e8b9d675a513873394a2f3d000722
781407ff475a36f9275160ff6f231eff
465a17f1224006ff</code></pre>
	<figure class="kg-card kg-image-card kg-width-wide"><img src="https://blog.cloudflare.com/content/images/2020/02/image-2.jpg" class="kg-image"></figure>
	<p>两个哈希之间的差距计算结果为713061。通过实验，我们可以设置一个距离阈值，在这个阈值下，您可以认为两张照片可能是相关的。</p>
	<h2 id="--3">模糊哈希的故意黑匣子</h2>
	<p>它是如何工作的？虽然现在已经有很多关于模糊哈希的研究成果得到发表，但该过程的内部结构却有意留有一些奥秘。《纽约时报》最近<a href="https://www.nytimes.com/interactive/2019/11/09/us/internet-child-sex-abuse.html" target="_blank">写了一个报道</a>，这可能是有关此类技术如何运作的最公开讨论。其中的挑战在于，如果CSAM的犯罪制作人和发布者确切地知道这些工具是如何运作的，那么他们就有可能精心设计改变自己的形象，从而打败它。需要说明的是，Cloudflare将代表网站运营商在我们的安全站点内运行CSAM筛选工具。我们不会直接将软件分发给用户。我们将继续警惕可能会滥用该平台的行为，并会在必要时立即采取行动。</p>
	<h2 id="--4">假阴性和假阳性之间的权衡</h2>
	<p>我们一直在与许多权威机构合作，研究如何才能最好地将这一功能推广给我们的客户。对于像Cloudflare这样拥有众多不同客户的网络来说，其中的一个挑战是如何设定模糊哈希之间差距比较的适当阈值。</p>
	<p>如果阈值太严格——这意味着它更接近于传统哈希，并且两个图像实际上必须相同才能触发匹配——那么您更有可能出现许多假阴性（即未标记的CSAM）。如果阈值太宽松，则可能会有许多误报。误报看起来似乎不那么坏，但是人们有理由担心，大规模地增加误报的可能性可能会浪费有限的资源，<a href="https://www.nytimes.com/interactive/2019/09/28/us/child-sex-abuse.html" target="_blank">并使现有的生态系统不堪重负</a>。我们将努力迭代CSAM扫描工具，为网站所有者提供更精细的控制，同时支持生态系统的持续有效性。今天，我们相信我们可以为客户提供良好的第一套选择，这将使我们能够更快地标记CSAM，而不会过分占用生态系统的资源。</p>
	<h2 id="--5">针对不同的客户设置不同的阈值</h2>
	<p>我们与客户的对话也反映了他们对精细方法的渴望。当我们问到对他们来说怎样才合适时，他们的回答会根据业务类型，现有滥用流程的复杂程度以及在其站点上发布CSAM的可能暴露水平和风险承受能力而发生根本性的变化。</p>
	<p>例如，一个使用Cloudflare的成熟社交网络和一个经验丰富的滥用团队可能希望将门槛设置得相当宽松，但不希望材料被自动封禁，因为他们有资源手动审查标记的内容。</p>
	<p>一家专门为新父母提供论坛的初创公司可能希望阈值设置得非常宽松，并希望自动阻止任何点击，因为他们尚未建立一支完备的滥用团队，而且如果有CSAM材料发布，其品牌面临的风险将非常高——即使这会导致一些假阳性。</p>
	<p>商业金融机构可能希望将阈值设置得非常严格，因为它们不太可能拥有用户生成的内容，并且对误报的容忍度较低，但是随后要自动阻止检测到的任何内容，因为如果他们的系统被泄漏到已知的CSAM主机，他们希望立即停止它。</p>
	<h2 id="--6">不同司法管辖区的不同要求</h2>
	<p>我们的客户所处的位置以及适用于他们的法律法规也可能会带来挑战。根据客户业务所在的位置和用户所在的位置，他们可以选择使用一个、多个或所有不同的可用哈希列表。</p>
	<p>换句话说，一种尺度不适于衡量所有网站，并且在理想情况下，我们认为，允许单个站点所有者设置最适合其特定站点的参数将带来更低的假阴性率。如果我们试着为我们的每一个客户设定一个全球标准，就可以标记出更多的CSAM。</p>
	<h2 id="--7">随着时间的推移改进工具</h2>
	<p>随着时间的推移，我们希望能够改善客户的CSAM筛选。我们期待着将来为（拥有全球各地用户的）众多客户网站提供更多来自全球代理商的哈希列表。我们致力于实现这种灵活性，而不会给打击这一可怕罪行的生态系统带来过多负担。</p>
	<p>最后，我们相信，我们有机会帮助建立下一代模糊哈希。例如，该软件现在只能扫描计算机内存中的静止图像，而不能扫描流媒体图像。我们正在与前达特茅斯学院教授——Hany Farid（现任教于加州伯克利）——进行对话，探讨如何建立一个更灵活的模糊哈希系统，以便在图片发布之前对其进行标记。</p>
	<h2 id="--8">问题与责任</h2>
	<p>当我们开始考虑提供CSAM扫描时，我们问了自己一个问题，那就是我们是否适合这样做。我们普遍关注对儿童的恐怖犯罪的描述，并认为它不应该出现在互联网上，然而Cloudflare是一个网络基础设施提供商，而不是一个内容平台。</p>
	<p>但是我们认为在这个领域我们应该扮演一个适当的角色。从根本上说，Cloudflare为我们的200多万客户提供了工具，而这些工具之前只有互联网巨头才有。我们提供的安全、性能和可靠性服务通常是免费的，如果没有我们，这些服务的价格将非常昂贵，或者仅限Facebook和谷歌这样的互联网巨头使用。</p>
	<p>如今，一些初创公司正在努力打造成为下一个互联网巨头，并与Facebook和谷歌竞争，因为它们可以使用Cloudflare实现安全、快速和可靠的在线服务。但是，随着在处理像CSAM这样的极其困难的问题上的监管障碍不断增加，他们中的许多人缺乏先进的工具来主动扫描CSAM。你必须变得强大，才能进入这个让你有机会使用这些工具的俱乐部，而且，令人担忧的是，成为这个俱乐部的一员正日益成为发展壮大的先决条件。</p>
	<p>如果我们想与互联网巨头竞争，我们需要将这些工具更广泛地提供给较小的组织。从这个角度来看，我们认为帮助使这个强大的工具大众化来对抗CSAM是非常有意义的。</p>
	<p>我们希望这将有助于使我们的客户建立适合他们自己社区的更复杂的内容审核团队，并使他们能够以负责任的方式进行扩展，从而与当今的互联网巨头竞争。这与我们帮助建立一个更好的互联网的使命直接一致，这就是为什么我们宣布将为所有客户免费提供这项服务。</p>
</div>