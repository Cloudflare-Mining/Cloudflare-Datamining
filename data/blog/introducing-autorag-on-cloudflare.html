<div class="mb2 gray5">8 min read</div><img class="mr2" src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2SZ1fpLEMXLfjidRspvQ3p/35aaef41cf7231cf349019d54143c00e/Feature_Image.png" alt="">
<div class="post-content lh-copy gray1">
	<p>Today we’re excited to announce <b>AutoRAG </b>in open beta, a fully managed Retrieval-Augmented Generation (RAG) pipeline powered by Cloudflare, designed to simplify how developers integrate context-aware AI into their applications. RAG is a method that improves the accuracy of AI responses by retrieving information from your own data, and providing it to the large language model (LLM) to generate more grounded responses.</p>
	<p>Building a RAG pipeline is a patchwork of moving parts. You have to stitch together multiple tools and services — your data storage, a vector database, an embedding model, LLMs, and custom indexing, retrieval, and generation logic — all just to get started. Maintaining it is even harder. As your data changes, you have to manually reindex and regenerate embeddings to keep the system relevant and performant. What should be a simple “ask a question, get a smart answer” experience becomes a brittle pipeline of glue code, fragile integrations, and constant upkeep.</p>
	<p>AutoRAG removes that complexity. With just a few clicks, it delivers a fully-managed RAG pipeline end-to-end: from ingesting your data and automatically chunking and embedding it, to storing vectors in Cloudflare’s <a href="https://developers.cloudflare.com/vectorize"><u>Vectorize</u></a> database, performing semantic retrieval, and generating high-quality responses using <a href="https://developers.cloudflare.com/workers-ai"><u>Workers AI</u></a>. AutoRAG continuously monitors your data sources and indexes in the background so your AI stays fresh without manual effort. It abstracts away the mess, letting you focus on building smarter, faster applications on Cloudflare’s developer platform. Get started today in the <a href="https://dash.cloudflare.com/?to=%2F%3Aaccount%2Fai%2Fautorag"><u>Cloudflare Dashboard</u></a>!</p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/JUFdbkiDN2U?si=GcWZNvsjoEFrTZ57" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
	<div class="flex anchor relative">
		<h3 id="why-use-rag-in-the-first-place">Why use RAG in the first place?</h3>
		<a href="https://blog.cloudflare.com/#why-use-rag-in-the-first-place" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>LLMs like Llama 3.3 from Meta are powerful, but they only know what they’ve been trained on. They often struggle to produce accurate answers when asked about new, proprietary, or domain-specific information. System prompts providing relevant information can help, but they bloat input size and are limited by context windows. Fine-tuning a model is expensive and requires ongoing retraining to keep up to date.</p>
	<p>RAG solves this by retrieving relevant information from your data source at query time, combining it with the user’s input query, and feeding both into the LLM to generate responses grounded with your data. This makes RAG a great fit for AI-driven support bots, internal knowledge assistants, semantic search across documentation, and other use cases where the source of truth is always evolving.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5zrM30iI2E1ZlmTQvAsx0D/fcef1f00b048a147fc3bc459895cc19c/1.png" alt="" class="kg-image" width="1882" height="740" loading="lazy">
	</figure>
	<div class="flex anchor relative">
		<h3 id="whats-under-the-hood-of-autorag">What’s under the hood of AutoRAG?</h3>
		<a href="https://blog.cloudflare.com/#whats-under-the-hood-of-autorag" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>AutoRAG sets up a RAG pipeline for you, using the building blocks of Cloudflare’s developer platform. Instead of you having to write code to create a RAG system using <a href="https://developers.cloudflare.com/workers-ai"><u>Workers AI</u></a>, <a href="https://developers.cloudflare.com/vectorize"><u>Vectorize</u></a>, and <a href="https://developers.cloudflare.com/ai-gateway"><u>AI Gateway</u></a>, you just create an AutoRAG instance and point it at a data source, like an <a href="https://developers.cloudflare.com/r2"><u>R2 </u></a>storage bucket.</p>
	<p>Behind the scenes, AutoRAG is powered by two processes: <b>indexing</b> and <b>querying</b>.</p>
	<ul>
		<li>
			<p><b>Indexing</b> is an asynchronous process that runs in the background. It kicks off as soon as you create an AutoRAG, and automatically continues in cycles — reprocessing new or updated files after each previous job completes. During indexing, your content is transformed into vectors optimized for semantic search.</p>
		</li>
		<li>
			<p><b>Querying</b> is a synchronous process triggered when a user sends a search request. AutoRAG takes the query, retrieves the most relevant content from your vector database, and uses it to generate a context-aware response using an LLM.</p>
		</li>
	</ul>
	<p>Let’s take a closer look at how they work.</p>
	<h4>Indexing process</h4>
	<p>When you connect a data source, AutoRAG automatically ingests, transforms, and stores it as vectors, optimizing it for semantic search when querying:</p>
	<ol>
		<li>
			<p><b>File ingestion from data source: </b>AutoRAG reads directly from your data source. Today, it supports integration with Cloudflare R2, where you can store documents like PDFs, images, text, HTML, CSV, and more for processing.
				<i>Check out the </i><a href="https://blog.cloudflare.com/#rag-to-riches-in-under-5-minutes"><b><i><u>RAG to riches in 5 minutes tutorial below</u></i></b></a><i> to learn how you can use Browser Rendering to parse webpages to use within your AutoRAG.</i>
			</p>
		</li>
		<li>
			<p><b>Markdown conversion:</b> AutoRAG uses <a href="https://developers.cloudflare.com/workers-ai/markdown-conversion"><u>Workers AI’s Markdown Conversion</u></a> to convert all files into structured Markdown. This ensures consistency across diverse file types. For images, Workers AI is used to perform object detection followed by vision-to-language transformation to convert images into Markdown text.</p>
		</li>
		<li>
			<p><b>Chunking:</b> The extracted text is chunked into smaller pieces to improve retrieval granularity.</p>
		</li>
		<li>
			<p><b>Embedding:</b> Each chunk is embedded using Workers AI’s embedding model to transform the content into vectors.</p>
		</li>
		<li>
			<p><b>Vector storage: </b>The resulting vectors, along with metadata like source location and file name, are stored in a Cloudflare’s Vectorize database created on your account.</p>
		</li>
	</ol>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5UK62iIO747BOe7JgazkBP/19a65b75cc4ad6b7fba31bff301cc133/Indexing.png" alt="" class="kg-image" width="1868" height="900" loading="lazy">
	</figure>
	<h4>Querying process</h4>
	<p>When an end user makes a request, AutoRAG orchestrates the following:</p>
	<ol>
		<li>
			<p><b>Receive query from AutoRAG API: </b>The query workflow begins when you send a request to either the AutoRAG’s AI Search or Search endpoint.</p>
		</li>
		<li>
			<p><b>Query rewriting (optional): </b>AutoRAG provides the option to rewrite the input query using one of Workers AI’s LLMs to improve retrieval quality by transforming the original query into a more effective search query.</p>
		</li>
		<li>
			<p><b>Embedding the query: </b>The rewritten (or original) query is transformed into a vector via the same embedding model used to embed your data so that it can be compared against your vectorized data to find the most relevant matches.</p>
		</li>
		<li>
			<p><b>Vector search in Vectorize: </b>The query vector is searched against stored vectors in the associated Vectorize database for your AutoRAG.</p>
		</li>
		<li>
			<p><b>Metadata + content retrieval: </b>Vectorize returns the most relevant chunks and their metadata. And the original content is retrieved from the R2 bucket. These are passed to a text-generation model.</p>
		</li>
		<li>
			<p><b>Response generation:</b> A text-generation model from Workers AI is used to generate a response using the retrieved content and the original user’s query.</p>
		</li>
	</ol>
	<p>The end result is an AI-powered answer grounded in your private data — accurate, and up to date.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7ueRtSqcc6BcQL27SyFMzi/30712fdf3a50115f9560f6c3e82f76db/3.png" alt="" class="kg-image" width="1999" height="964" loading="lazy">
	</figure>
	<div class="flex anchor relative">
		<h3 id="rag-to-riches-in-under-5-minutes">RAG to riches in under 5 minutes</h3>
		<a href="https://blog.cloudflare.com/#rag-to-riches-in-under-5-minutes" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Most of the time, getting started with AutoRAG is as simple as pointing it to an existing R2 bucket — just drop in your content, and you're ready to go. But what if your content isn’t already in a bucket? What if it’s still on a webpage or needs to first be rendered dynamically by a frontend UI? You're in luck, because with the <a href="https://developers.cloudflare.com/browser-rendering"><b><u>Browser Rendering API</u></b></a>, you can crawl your own websites to gather information that powers your RAG. The Browser Rendering REST API is now<b> generally available</b>, offering endpoints for common browser actions including extracting HTML content, capturing screenshots, and generating PDFs. Additionally, a crawl endpoint is coming soon, making it even easier to ingest websites.</p>
	<p>In this walkthrough, we’ll show you how to take your website and feed it into AutoRAG for Q&amp;A. We’ll use a Cloudflare Worker to render web pages in a headless browser, upload the content to R2, and hook that into AutoRAG for semantic search and generation.</p>
	<h4>Step 1. Create a Worker to fetch webpages and upload into R2</h4>
	<p>We’ll create a Cloudflare Worker that uses Puppeteer to visit your URL, render it, and store the full HTML in your R2 bucket. If you already have an R2 bucket with content you’d like to build a RAG for then you can skip this step.</p>
	<ol>
		<li>
			<p>Create a new Worker project named <code>browser-r2-worker</code> by running:</p>
		</li>
	</ol>
	<pre class="language-Rust"><code class="language-Rust">npm create cloudflare@latest -- browser-r2-worker</code></pre>
	<p>For setup, select the following options:</p>
	<ul>
		<li>
			<p><i>What would you like to start with?</i> Choose Hello World Starter.</p>
		</li>
		<li>
			<p><i>Which template would you like to use?</i> Choose Worker only.</p>
		</li>
		<li>
			<p><i>Which language do you want to use? </i>Choose TypeScript.</p>
		</li>
	</ul>
	<p>
		2. Install <code>@cloudflare/puppeteer</code>, which allows you to control the Browser Rendering instance:</p>
	<pre class="language-Rust"><code class="language-Rust">npm i @cloudflare/puppeteer</code></pre>
	<p>3. Create a new R2 bucket named <code>html-bucket</code> by running:&nbsp;</p>
	<pre class="language-Rust"><code class="language-Rust">npx wrangler r2 bucket create html-bucket</code></pre>
	<p>4. Add the following configurations to your Wrangler configuration file, so your Worker can use browser rendering and your new R2 bucket:</p>
	<pre class="language-Rust"><code class="language-Rust">{
	"compatibility_flags": ["nodejs_compat"],
	"browser": {
		"binding": "MY_BROWSER"
	},
	"r2_buckets": [
		{
			"binding": "HTML_BUCKET",
			"bucket_name": "html-bucket",
		}
	],
}</code></pre>
	<p>5. Replace the contents of src/index.ts with the following skeleton script:</p>
	<pre class="language-Rust"><code class="language-Rust">import puppeteer from "@cloudflare/puppeteer";

// Define our environment bindings
interface Env {
	MY_BROWSER: any;
	HTML_BUCKET: R2Bucket;
}

// Define request body structure
interface RequestBody {
	url: string;
}

export default {
	async fetch(request: Request, env: Env): Promise&lt;Response&gt; {
		// Only accept POST requests
		if (request.method !== 'POST') {
return new Response('Please send a POST request with a target URL', { status: 405 });
		}

		// Get URL from request body
		const body = await request.json() as RequestBody;
		// Note: Only use this parser for websites you own
		const targetUrl = new URL(body.url); 

		// Launch browser and create new page
		const browser = await puppeteer.launch(env.MY_BROWSER);
		const page = await browser.newPage();

		// Navigate to the page and fetch its html
		await page.goto(targetUrl.href);
		const htmlPage = await page.content();

		// Create filename and store in R2
		const key = targetUrl.hostname + '_' + Date.now() + '.html';
		await env.HTML_BUCKET.put(key, htmlPage);

		// Close browser
		await browser.close();

		// Return success response
		return new Response(JSON.stringify({
			success: true,
			message: 'Page rendered and stored successfully',
			key: key
		}), {
			headers: { 'Content-Type': 'application/json' }
		});
	}
} satisfies ExportedHandler&lt;Env&gt;;</code></pre>
	<p>6. Once the code is ready, you can deploy it to your Cloudflare account by running:</p>
	<pre class="language-Rust"><code class="language-Rust">npx wrangler deploy</code></pre>
	<p>7. To test your Worker, you can use the following cURL request to fetch the HTML file of a page. In this example we are fetching this blog page to upload into the html-bucket bucket:</p>
	<pre class="language-Rust"><code class="language-Rust">curl -X POST https://browser-r2-worker.&lt;YOUR_SUBDOMAIN&gt;.workers.dev \
-H "Content-Type: application/json" \
-d '{"url": "https://blog.cloudflare.com/introducing-autorag-on-cloudflare"}'</code></pre>
	<h4>Step 2. Create your AutoRAG and monitor the indexing</h4>
	<p>Now that you have created your R2 bucket and filled it with your content that you’d like to query from, you are ready to create an AutoRAG instance:</p>
	<ol>
		<li>
			<p>In your <a href="https://dash.cloudflare.com/?to=%2F%3Aaccount%2Fai%2Fautorag"><u>Cloudflare dashboard</u></a>, navigate to AI &gt; AutoRAG</p>
		</li>
		<li>
			<p>Select Create AutoRAG and complete the setup process:</p>
			<ol>
				<li>
					<p><b>Select the R2 bucket</b> which contains your knowledge base, in this case, select the <code>html-bucket</code>.</p>
				</li>
				<li>
					<p><b>Select an embedding model </b>used to convert your data to vector representation. It is recommended to use the Default.</p>
				</li>
				<li>
					<p><b>Select an LLM </b>to use to generate your responses. It is recommended to use the Default.</p>
				</li>
				<li>
					<p><b>Select or create an AI Gateway</b> to monitor and control your model usage.</p>
				</li>
				<li>
					<p><b>Name your AutoRAG</b> as <code>my-rag</code>.</p>
				</li>
				<li>
					<p><b>Select or create a Service API token</b> to grant AutoRAG access to create and access resources in your account.</p>
				</li>
			</ol>
		</li>
		<li>
			<p>Select Create to spin up your AutoRAG.</p>
		</li>
	</ol>
	<p>Once you’ve created your AutoRAG, it will automatically create a Vectorize database in your account and begin indexing the data. You can view the progress of your indexing job in the Overview page of your AutoRAG. The indexing time may vary depending on the number and type of files you have in your data source.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5qgy5VRqvKjBhdmSZ4riEE/e7dc59a4c615838704d9ec323bfdabfa/4.png" alt="" class="kg-image" width="1679" height="841" loading="lazy">
	</figure>
	<h4>Step 3. Test and add to your application</h4>
	<p>Once AutoRAG finishes indexing your content, you’re ready to start asking it questions. You can open up your AutoRAG instance, navigate to the Playground tab, and ask a question based on your uploaded content, like “What is AutoRAG?”.</p>
	<p>Once you’re happy with the results in the Playground, you can integrate AutoRAG directly into the application that you are building. If you are using a Worker to build your application, then you can use the AI binding to directly call your AutoRAG:&nbsp;</p>
	<pre class="language-Rust"><code class="language-Rust">{
  "ai": {
    "binding": "AI"
  }
}</code></pre>
	<p>Then, query your AutoRAG instance from your Worker code by calling the <code>aiSearch()</code> method. Alternatively you can use the <code>Search()</code> method to get a list of retrieved results without an AI generated response.</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">const answer = await env.AI.autorag('my-rag').aiSearch({
   query: 'What is AutoRAG?'
});</code></pre>
	<p>For more information on how to add AutoRAG into your application, go to your AutoRAG then navigate to Use AutoRAG for more instructions.</p>
	<div class="flex anchor relative">
		<h3 id="start-building-today">Start building today</h3>
		<a href="https://blog.cloudflare.com/#start-building-today" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>During the open beta, AutoRAG is <b>free to enable</b>. Compute operations for indexing, retrieval and augmentation incur no additional cost during this phase.</p>
	<p>AutoRAG is built entirely on top of Cloudflare’s Developer Platform, using the same tools you’d reach for if you were building a RAG pipeline yourself. When you create an AutoRAG instance, it provisions and runs on top of Cloudflare services within your own account, giving you full visibility into performance, cost, and behavior with fewer black boxes.</p>
	<p>These services include:</p>
	<ul>
		<li>
			<p><a href="https://developers.cloudflare.com/r2"><b><u>R2</u></b></a><b>: </b>stores your source data.</p>
		</li>
		<li>
			<p><a href="https://developers.cloudflare.com/vectorize"><b><u>Vectorize</u></b></a><b>:</b> stores vector embeddings and powers semantic retrieval.</p>
		</li>
		<li>
			<p><a href="https://developers.cloudflare.com/workers-ai"><b><u>Workers AI</u></b></a><b>: </b>converts images to markdown, generates embeddings, rewrites queries, and generates responses.</p>
		</li>
		<li>
			<p><a href="https://developers.cloudflare.com/ai-gateway"><b><u>AI Gateway</u></b></a><b>:</b> tracks and controls your model’s usage.</p>
		</li>
	</ul>
	<p>To help manage resources during the beta, each account is limited to <b>10 AutoRAG</b> instances, with up to <b>100,000 files</b> <b>per AutoRAG</b>.&nbsp;</p>
	<div class="flex anchor relative">
		<h3 id="whats-on-the-roadmap">What’s on the roadmap?</h3>
		<a href="https://blog.cloudflare.com/#whats-on-the-roadmap" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>We’re just getting started with AutoRAG and we have more planned throughout 2025 to make it more powerful and flexible. Here are a few things we’re actively working on:</p>
	<ul>
		<li>
			<p><b>More data source integrations:</b> We’re expanding beyond R2, with support for new input types like direct website URL parsing (powered by browser rendering) and structured data sources like Cloudflare <a href="https://developers.cloudflare.com/d1"><u>D1</u></a>.</p>
		</li>
		<li>
			<p><b>Smarter, higher-quality responses: </b>We’re exploring built-in reranking, recursive chunking, and other processing techniques to improve the quality and relevance of generated answers.</p>
		</li>
	</ul>
	<p>These features will roll out incrementally, and we’d love your feedback as we shape what’s next. AutoRAG is built to evolve with your use cases so stay tuned.</p>
	<div class="flex anchor relative">
		<h3 id="try-it-out-today">Try it out today!</h3>
		<a href="https://blog.cloudflare.com/#try-it-out-today" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Get started with AutoRAG today by visiting the <a href="https://dash.cloudflare.com/?to=%2F%3Aaccount%2Fai%2Fautorag"><u>Cloudflare Dashboard</u></a>, navigate to AI &gt; AutoRAG, and select Create AutoRAG. Whether you’re building an AI-powered search experience, an internal knowledge assistant, or just experimenting with LLMs, AutoRAG gives you a fast and flexible way to get started with RAG on Cloudflare’s global network. For more details, refer to the <a href="https://developers.cloudflare.com/autorag"><u>Developer Docs</u></a>. Also, try out the <a href="https://developers.cloudflare.com/browser-rendering"><u>Browser Rendering API</u></a> that is now generally available for your browser action needs.</p>
	<p>We’re excited to see what you build and we’re here to help. Have questions or feedback? Join the conversation on the <a href="https://discord.com/channels/595317990191398933/1356674457355423895"><u>Cloudflare Developers Discord</u></a>.</p>
</div>