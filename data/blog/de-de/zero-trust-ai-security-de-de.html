<div class="mb2 gray5">7 min read</div>
<div class="post-content lh-copy gray1">
	<p><strong>Leistungsstarke Cloudflare One-Tools, damit Ihre Teams KI-Dienste sicher nutzen können</strong></p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image1-18.png" class="kg-image" alt="Zero Trust Security for AI" loading="lazy" width="1801" height="1013"></figure>
	<p>Cloudflare One ermöglicht Teams jeder Größe, die besten Tools im Internet sicher zu nutzen, ohne sich um deren Verwaltung oder die Performance sorgen zu müssen. Wir freuen uns, Cloudflare One for AI ankündigen zu können, eine neue Reihe von Funktionen, die Ihrem Team dabei helfen, mit den neuesten KI-Diensten zu arbeiten und gleichzeitig ein Zero Trust-Sicherheitsniveau zu wahren.</p>
	<h3 id="gro%C3%9Fe-sprachmodelle-gr%C3%B6%C3%9Fere-herausforderungen-f%C3%BCr-die-sicherheit">Große Sprachmodelle, größere Herausforderungen für die Sicherheit</h3>
	<p>Ein Large Language Model (LLM, großes Sprachenmodell), wie OpenAIs GPT oder Googles Bard, besteht aus einem neuronalen Netzwerk, das anhand einer Reihe von Daten trainiert wurde, um Text auf der Grundlage einer Aufforderung (dem sogenannten „Prompt“) vorherzusagen und zu generieren. Nutzer können Fragen stellen, Feedback einholen und sich auf den Dienst stützen, um Outputs zu erzeugen – von Gedichten bis hin zu <a href="https://blog.samrhea.com/posts/2022/five-minute-ai-site" target="_blank">Cloudflare Workers-Anwendungen</a>.</p>
	<p>Die Tools haben auch eine verblüffende Ähnlichkeit mit einem echten Menschen. Wie bei einigen persönlichen Gesprächen im wirklichen Leben kann auch bei diesen KI-Diensten ein übermäßiges Preisgeben von Informationen (ein als „Oversharing“ bezeichnetes Phänomen) zu einem <a href="https://mashable.com/article/samsung-chatgpt-leak-details" target="_blank">ernsthaften Problem</a> werden. Dieses Risiko vervielfacht sich durch die Arten von Anwendungsfällen, in denen LLM-Modelle ihre Stärken haben. Mit diesen Tools können Entwickler schwierige Programmieraufgaben lösen oder Sachbearbeiter prägnante Berichte aus einer Unmenge von Notizen erstellen. Das ist zwar hilfreich, aber jede Eingabe in eine Eingabeaufforderung wird zu einem Teil der Daten, der die Kontrolle Ihres Unternehmens verlässt.</p>
	<p>Als Reaktion auf Tools wie ChatGPT wurde versucht, den Dienst komplett zu verbieten, entweder auf Unternehmensebene oder sogar <a href="https://www.reuters.com/technology/germany-principle-could-block-chat-gpt-if-needed-data-protection-chief-2023-04-03" target="_blank">für eine ganze Nation</a>. Unserer Ansicht nach sollte dies nicht notwendig sein. Mit Cloudflare One wollen wir Ihnen die Möglichkeit geben, die von Ihnen benötigten Tools sicher und ohne Performance-Einbußen zu nutzen – egal wo sie sich befinden. Bestehenden Nutzern der Zero Trust-Produkte von Cloudflare One werden diese Funktionen bekannt vorkommen. Wir freuen uns jedoch darauf, Ihnen Fälle zu zeigen, in denen Sie die jetzt verfügbaren Tools nutzen können, damit Ihr Team die Vorteile der neuesten LLM-Funktionen nutzen kann.</p>
	<h3 id="nutzung-messen">Nutzung messen</h3>
	<p>Bei SaaS-Anwendungen kann sich jeder Nutzer einfach anmelden und loslegen. Durch diesen Komfort belasten diese Tools aber auch die IT-Budgets und Sicherheitsrichtlinien. Teams bezeichnen dieses Problem als „<a href="https://blog.cloudflare.com/introducing-shadow-it-discovery">Schatten-IT</a>“ – die Nutzung von Anwendungen und Diensten, die im Unternehmen eigentlich nicht genehmigt sind.</p>
	<p>Was das Budget betrifft, so haben wir von Kunden gehört, die bereits seit einiger Zeit mit LLMs experimentieren, sich aber nicht sicher sind, wie sie die Entscheidung für eine kommerzielle Lizenzierung treffen sollen. Welche Dienste und Funktionen benötigen Ihre Nutzer und wie viele Lizenzen sollten sie kaufen?</p>
	<p>In puncto Sicherheit können KIs einerseits die Arbeit deutlich erleichtern, andererseits aber verheerende Auswirkungen auf die Datenkontrolle haben. Die Teammitglieder behandeln diese KI wie einen Gesprächspartner für schmerzhafte Probleme. Die Dienste laden Nutzer dazu ein, ihre Fragen und Probleme mitzuteilen. Manchmal kann der Kontext innerhalb dieser Prompts sensible Informationen enthalten, die ein Unternehmen niemals verlassen sollten. Selbst wenn Teams einen einzigen Anbieter auswählen und genehmigen, bevorzugen Mitglieder Ihres Unternehmens möglicherweise eine andere KI und verwenden diese weiterhin in ihrem Arbeitsablauf.</p>
	<p>Cloudflare One-Kunden jedes Tarifs <a href="https://developers.cloudflare.com/cloudflare-one/analytics/access" target="_blank">können jetzt die Nutzung von KIs überprüfen</a>. Ihre IT-Abteilung kann Cloudflare Gateway einsetzen und passiv beobachten, wie viele Nutzer welche Dienste auswählen, um so die Lizenzpläne für Unternehmen zu prüfen.</p>
	<figure class="kg-card kg-image-card kg-width-wide"><img src="https://blog.cloudflare.com/content/images/2023/05/image6-5.png" class="kg-image" alt="" loading="lazy" width="1879" height="682"></figure>
	<p>Administratoren können die Nutzung dieser Dienste auch mit einem einzigen Klick blockieren. Das ist aber heute gar nicht unser Ziel. Sie sollten diese Funktion nutzen, wenn Sie ChatGPT als genehmigtes Modell ausgewählt haben und sicherstellen möchten, dass Ihre Teammitglieder keine anderen Dienste mehr nutzen. Wir hoffen jedoch, dass Sie nicht alle diese Dienste vollständig blockieren. Für Cloudflare hat es Priorität, Ihnen die Möglichkeit zu geben, diese Tools sicher zu nutzen.</p>
	<h3 id="den-api-zugriff-kontrollieren">Den API-Zugriff kontrollieren</h3>
	<p>Als unsere Teams mit dem ChatGPT-Service von OpenAI zu experimentieren begannen, waren wir erstaunt darüber, was er bereits über Cloudflare wusste. Wir baten ChatGPT, Anwendungen mit <a href="https://workers.cloudflare.com" target="_blank">Cloudflare Workers</a> zu erstellen oder uns bei der Konfiguration einer <a href="https://www.cloudflare.com/products/zero-trust/access" target="_blank">Cloudflare Access</a>-Richtlinie zu helfen, und in den meisten Fällen waren die Ergebnisse präzise und hilfreich.</p>
	<p>In einigen Fällen verfehlten die Ergebnisse das Ziel. Die KI verwendete veraltete Informationen oder wir stellten Fragen zu Funktionen, die erst kürzlich eingeführt worden waren. Zum Glück können diese KIs lernen und wir können helfen. Wir können diese Modelle mit gezielten Eingaben trainieren und <a href="https://openai.com/blog/chatgpt-plugins" target="_blank">Plugins einbinden</a>, um unseren Kunden bessere KI-gesteuerte Erfahrungen bei der Nutzung von Cloudflare-Diensten zu bieten.</p>
	<p>Wir haben von Kunden gehört, die das Gleiche tun wollen und die, wie wir, Trainingsdaten sicher freigeben und dem Plugin eines KI-Dienstes Zugang gewähren müssen. Die Sicherheitssuite von Cloudflare One geht über menschliche Nutzer hinaus und kann Teams die Möglichkeit geben, den Zero Trust-Zugriff auf sensible Daten über APIs sicher freizugeben.</p>
	<p>Zunächst können Teams <a href="https://developers.cloudflare.com/cloudflare-one/identity/service-tokens" target="_blank">Service-Token</a> erstellen, die externe Dienste vorlegen müssen, um auf Daten zuzugreifen, die über Cloudflare One verfügbar sind. Administratoren können diese Token an Systeme weitergeben, die API-Anfragen stellen, und jede einzelne Anfrage protokollieren. Bei Bedarf können die Teams diese Token mit einem einzigen Klick widerrufen.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download-7.png" class="kg-image" alt="" loading="lazy" width="1600" height="1317"></figure>
	<p>Nach der Erstellung und Ausgabe von Service-Token können Administratoren Richtlinien erstellen, um bestimmten Diensten den Zugriff auf ihre Trainingsdaten zu ermöglichen. Diese Richtlinien verifizieren das Service-Token und können erweitert werden, um Land, IP-Adresse oder ein mTLS-Zertifikat zu verifizieren. Es können auch Richtlinien erstellt werden, die menschliche Nutzer dazu verpflichten, sich bei einem Identitätsanbieter zu authentifizieren und eine MFA-Abfrage auszufüllen, bevor sie auf sensible Trainingsdaten oder -dienste zugreifen.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--1--4.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>Mit <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-apps" target="_blank">Cloudflare Tunnel</a> können Teams einem KI-Dienst erlauben, sich mit ihrer Infrastruktur zu verbinden, ohne Löcher in ihre Firewalls schlagen zu müssen. Cloudflare Tunnel stellt eine verschlüsselte, nur ausgehende Verbindung zum Netzwerk von Cloudflare her, bei der jede Anfrage anhand der Zugriffsregeln überprüft wird, die für einen oder mehrere durch Cloudflare One geschützte Dienste konfiguriert wurden.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--2--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>Die Zero Trust-Zugangskontrolle von Cloudflare ermöglicht Ihnen, für jede einzelne Anfrage an die Daten, die Ihr Unternehmen diesen Tools zur Verfügung stellen möchte, eine Authentifizierung durchzusetzen. Bleibt jedoch noch das Problem, dass Ihre Teammitglieder vielleicht von sich aus zu viele Daten preisgeben.</p>
	<h3 id="daten-uploads-einschr%C3%A4nken">Daten-Uploads einschränken</h3>
	<p>Administratoren können einen KI-Dienst auswählen, Schatten-IT-Alternativen blockieren und den Zugriff auf ihre Trainingsdaten sorgfältig kontrollieren. Letztlich sind aber immer noch Menschen an diesen KI-Experimenten beteiligt. Jeder von uns kann versehentlich einen Sicherheitsvorfall verursachen, indem er bei der Nutzung eines KI-Dienstes – selbst eines genehmigten Dienstes – zu viele Informationen preisgibt.</p>
	<p>Wir gehen davon aus, dass sich die KI-Playgrounds weiterentwickeln und mehr Funktionen für die Datenverwaltung bieten werden, aber wir glauben nicht, dass Sie darauf warten müssen, um diese Dienste in Ihre Arbeitsabläufe zu integrieren. Der <a href="https://developers.cloudflare.com/cloudflare-one/policies/data-loss-prevention/dlp-policies" target="_blank">Data Loss Prevention (DLP)-Service von Cloudflare</a> kann einen Schutz bieten, um Oversharing zu stoppen, bevor es zu einem Vorfall für Ihr Sicherheitsteam kommt.</p>
	<p>Sagen Sie uns zunächst, welche Daten Ihnen wichtig sind. Wir bieten einfache, vorkonfigurierte Optionen, mit denen Sie nach Eingaben suchen können, die wie Sozialversicherungsnummern oder Kreditkartennummern aussehen. Cloudflare DLP kann auch nach Mustern suchen, die auf von Ihrem Team konfigurierten, regulären Ausdrücken basieren.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--3--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>Sobald Sie die Daten definiert haben, die Ihr Unternehmen niemals verlassen dürfen, können Sie genau festlegen, wie diese Daten mit KI-Diensten geteilt werden können und wie nicht. Vielleicht sind einige Nutzer berechtigt, mit Projekten zu experimentieren, die sensible Daten enthalten. In diesem Fall können Sie eine Regel erstellen, die es nur einer Active Directory- oder Okta-Gruppe erlaubt, diese Art von Informationen hochzuladen, während alle anderen gesperrt sind.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--4--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<h3 id="die-nutzung-kontrollieren-%E2%80%93-ganz-ohne-proxy">Die Nutzung kontrollieren – ganz ohne Proxy</h3>
	<p>Die im heutigen Blog-Beitrag vorgestellten Tools konzentrieren sich auf Funktionen, die sich auf Daten in der Übertragung (Data-in-Motion) beziehen. Wir wollen auch sicherstellen, dass Fehlkonfigurationen in den Anwendungen nicht zu Sicherheitsverstößen führen. Die neue Plugin-Funktion in ChatGPT bringt beispielsweise das Wissen und die Arbeitsabläufe externer Dienste in den KI-Interaktionsfluss ein. Das kann jedoch auch dazu führen, dass die Dienste hinter den Plugins mehr Zugriff haben, als Sie wollen</p>
	<p>Der <a href="https://www.cloudflare.com/products/zero-trust/casb" target="_blank">Cloud Access Security Broker</a> (CASB) von Cloudflare scannt Ihre SaaS-Anwendungen auf potenzielle Probleme, die auftreten können, wenn Nutzer Änderungen vornehmen. Egal, ob Sie auf Dateien aufmerksam gemacht werden, die jemand versehentlich im Internet veröffentlicht hat, oder ob Sie überprüfen, ob Ihre <a href="https://developers.cloudflare.com/cloudflare-one/applications/scan-apps/casb-integrations/github/#security-findings" target="_blank">GitHub-Repositories die richtigen Mitgliedschaftseinstellungen haben</a>, der CASB von Cloudflare macht den manuellen Aufwand überflüssig, der erforderlich ist, um jede einzelne Einstellung in Ihren SaaS-Anwendungen auf potenzielle Probleme zu überprüfen.</p>
	<p>Wir arbeiten aktuell an neuen Integrationen mit beliebten KI-Diensten, um nach Fehlkonfigurationen zu suchen. Diese Integrationen werden bald verfügbar sein. Wie die meisten Nutzer dieser Dienste lernen auch wir immer noch mehr darüber, wo potenzielle Pannen auftreten können, und wir freuen uns, Administratoren, die unsere CASB nutzen, unsere erste Welle von Kontrollen für KI-Dienste zur Verfügung stellen zu können.</p>
	<h3 id="was-kommt-als-n%C3%A4chstes">Was kommt als Nächstes?</h3>
	<p>Die Nützlichkeit dieser Tools wird nur noch zunehmen. Die Fähigkeit von KI-Diensten, zu coachen und Output zu generieren, wird es Entwicklern aller Fachbereiche und Disziplinen noch einfacher machen, die nächste große Innovation zu entwickeln.</p>
	<p>Wir teilen ein ähnliches Ziel. Die Produkte von Cloudflare sind darauf ausgerichtet, Nutzern bei der Erstellung von Anwendungen und Diensten zu helfen. Dank unserer <a href="https://workers.cloudflare.com" target="_blank">Workers-Plattform</a> müssen Sie sich nicht mehr darum sorgen, wo Sie Ihre Anwendung einsetzen oder wie Sie Ihre Dienste skalieren können. Cloudflare löst diese Probleme, damit sich die Nutzer auf die Entwicklung konzentrieren können. In Kombination mit den KI-Diensten erwarten wir, dass Tausende neuer Entwickler die nächste Welle von Produkten auf den Weg bringen, die auf Cloudflare basieren und durch KI-Coaching und -Generierung inspiriert sind.</p>
	<p>Wir haben bereits Dutzende von Projekten florieren sehen, die auf Cloudflare Workers mit Hilfe von Tools wie ChatGPT entwickelt wurden. Wir planen die Einführung neuer Integrationen mit diesen Modellen, um dies noch nahtloser zu gestalten und eine bessere Cloudflare-spezifische Anleitung für das Chat-Erlebnis zu bieten.</p>
	<p>Wir wissen auch, dass die Sicherheitsrisiken dieser Tools zunehmen werden. Wir werden Cloudflare One weiterhin mit Funktionen ausstatten, mit denen Sie den durch diese Tools entstehenden Risiken einen Schritt voraus sein können. Kann's losgehen? Melden Sie sich hier an, um Cloudflare One für Teams mit bis zu 50 Nutzern kostenlos zu nutzen.</p>
</div>