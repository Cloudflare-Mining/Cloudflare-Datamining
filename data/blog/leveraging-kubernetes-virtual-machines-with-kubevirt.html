<div class="mb2 gray5">7 min read</div><img class="mr2" src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7v6vcpBs9iDewJJksZuaqX/445edc7c7c28d06f1170f049ec8bf086/image1.png" alt="">
<div class="post-content lh-copy gray1">
	<p></p>
	<p>Cloudflare runs several <a href="https://kubernetes.io/docs/concepts/security/multi-tenancy"><u>multi-tenant</u></a> <a href="https://kubernetes.io"><u>Kubernetes</u></a> clusters across our core data centers. These general-purpose clusters run on bare metal and power our <a href="https://www.cloudflare.com/learning/network-layer/what-is-the-control-plane"><u>control plane</u></a>, analytics, and various engineering tools such as build infrastructure and continuous integration.</p>
	<p>Kubernetes is a container orchestration platform. It enables software engineers to deploy containerized applications to a cluster of machines. This enables teams to build highly-available software on a scalable and resilient platform.</p>
	<p>In this blog post we discuss our Kubernetes architecture, why we needed virtualization, and how we’re using it today.</p>
	<div class="flex anchor relative">
		<h2 id="multi-tenant-clusters">Multi-tenant clusters</h2>
		<a href="https://blog.cloudflare.com/#multi-tenant-clusters" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p><a href="https://www.cloudflare.com/learning/cloud/what-is-multitenancy"><u>Multi-tenancy</u></a> is a concept where one system can share its resources among a wide range of customers. This model allows us to build and manage a small number of general purpose Kubernetes clusters for our internal application teams. Keeping the number of clusters small reduces our operational toil. This model shrinks costs and increases computational efficiency by sharing hardware. Multi-tenancy also allows us to scale more efficiently. Scaling is done at either a cluster or application level. Cluster operators scale the platform by adding more hardware. Teams scale their applications by updating their Kubernetes manifests. They can scale <a href="https://en.wikipedia.org/wiki/Scalability#Vertical_or_scale_up"><u>vertically</u></a> by increasing their <a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers"><u>resource</u></a> requests or <a href="https://en.wikipedia.org/wiki/Scalability#Horizontal_or_scale_out"><u>horizontally</u></a> by increasing the number of replicas.</p>
	<p>All of our Kubernetes clusters are multi-tenant with various components enabled for a secure and resilient platform.</p>
	<p><a href="https://kubernetes.io/docs/concepts/workloads/pods"><u>Pods</u></a> are secured using the latest standards recommended by the Kubernetes project. We use <a href="https://kubernetes.io/docs/concepts/security/pod-security-admission"><u>Pod Security Admission</u></a> (PSA) and <a href="https://kubernetes.io/docs/concepts/security/pod-security-standards"><u>Pod Security Standards</u></a> to ensure all workloads are following best practices. By default, all namespaces use the most <a href="https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted"><u>restrictive</u></a> profile, and only a few Kubernetes control plane namespaces are granted <a href="https://kubernetes.io/docs/concepts/security/pod-security-standards/#privileged"><u>privileged</u></a> access. For additional policies not covered by PSA, we built custom <a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#validatingadmissionwebhook"><u>Validating Webhooks</u></a> on top of the <a href="https://github.com/kubernetes-sigs/controller-runtime/tree/main/pkg/webhook/admission"><u>controller-runtime</u></a> framework. PSA and our custom policies ensure clusters are secure and workloads are isolated.</p>
	<div class="flex anchor relative">
		<h2 id="our-need-for-virtualization">Our need for virtualization</h2>
		<a href="https://blog.cloudflare.com/#our-need-for-virtualization" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>A select number of teams needed tight integration with the Linux kernel. Examples include Docker daemons for build infrastructure and the ability to simulate servers running the software and configuration of our <a href="https://www.cloudflare.com/network"><u>global network</u></a>. With our pod security requirements, these workloads are not permitted to interface with the host kernel at a deep level (e.g. no <a href="https://en.wikipedia.org/wiki/Iptables"><u>iptables</u></a> or <a href="https://en.wikipedia.org/wiki/Sysctl"><u>sysctls</u></a>). Doing so may disrupt other tenants sharing the node and open additional <a href="https://www.cloudflare.com/learning/security/glossary/attack-vector"><u>attack vectors</u></a> if an application was compromised. A virtualization platform would enable these workloads to interact with their own kernel within a secured Kubernetes cluster.</p>
	<p>We considered various different virtualization solutions. Running a separate virtualization platform outside of Kubernetes would have worked, but would not tightly integrate containerized workloads with virtual machines. It would also be an additional operational burden on our team, as backups, alerting, and fleet management would have to exist for both our Kubernetes and virtual machine clusters.</p>
	<p>We then looked for solutions that run virtual machines within Kubernetes. Teams could already manually deploy <a href="https://www.qemu.org"><u>QEMU</u></a> pods, but this was not an elegant solution. We needed a better way. There were several other options, but <a href="https://kubevirt.io"><u>KubeVirt</u></a> was the tool that met the majority of our requirements. Other solutions required a privileged container to run a virtual machine, but KubeVirt did not – this was a crucial requirement in our goal of creating a more secure multi-tenant cluster. KubeVirt also uses a feature of the Kubernetes API called <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources"><u>Custom Resource Definitions</u></a> (CRDs), which extends the Kubernetes API with new objects, increasing the flexibility of Kubernetes beyond its built-in types. For KubeVirt, this includes objects such as VirtualMachine and VirtualMachineInstanceReplicaSet. We felt the use of CRDs would allow KubeVirt to grow as more features were added.</p>
	<div class="flex anchor relative">
		<h2 id="what-is-kubevirt">What is KubeVirt?</h2>
		<a href="https://blog.cloudflare.com/#what-is-kubevirt" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>KubeVirt is a virtualization platform that enables users to run virtual machines within Kubernetes. With KubeVirt, <a href="https://www.cloudflare.com/learning/cloud/what-is-a-virtual-machine"><u>virtual machines</u></a> run alongside containerized workloads on the same platform. Kubernetes primitives such as <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies"><u>network policies</u></a>, <a href="https://kubernetes.io/docs/concepts/configuration/configmap"><u>configmaps</u></a>, and <a href="https://kubernetes.io/docs/concepts/services-networking/service"><u>services</u></a> all integrate with virtual machines. KubeVirt scales with our needs and is successfully running hundreds of virtual machines across several clusters. We frequently <a href="https://blog.cloudflare.com/automatic-remediation-of-kubernetes-nodes"><u>remediate Kubernetes nodes</u></a>, so virtual machines and pods are always exercising their startup/shutdown processes.</p>
	<div class="flex anchor relative">
		<h2 id="how-cloudflare-uses-kubevirt">How Cloudflare uses KubeVirt</h2>
		<a href="https://blog.cloudflare.com/#how-cloudflare-uses-kubevirt" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>There are a number of internal projects leveraging virtual machines at Cloudflare. We’ll touch on a few of our more popular use cases:</p>
	<ol>
		<li>
			<p>Kubernetes scalability testing</p>
		</li>
		<li>
			<p>Development environments</p>
		</li>
		<li>
			<p>Kernel and iPXE testing</p>
		</li>
		<li>
			<p>Build pipelines</p>
		</li>
	</ol>
	<div class="flex anchor relative">
		<h3 id="kubernetes-scalability-testing">
			Kubernetes scalability testing</h3>
		<a href="https://blog.cloudflare.com/#kubernetes-scalability-testing" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<h4>Setup process</h4>
	<p>Our staging clusters are much smaller than our largest production clusters. They also run on bare metal and mirror the configuration we have for each production cluster. This is extremely useful when rolling out new software, operating systems, or kernel changes; however, they miss bugs that only surface at scale. We use KubeVirt to bridge this gap and virtualize Kubernetes clusters with hundreds of nodes and thousands of pods.</p>
	<p>The setup process for virtualized clusters differs from our bare metal provisioning steps. For bare metal, we use <a href="https://saltproject.io"><u>Salt</u></a> to provision clusters from start to finish. For our virtualized clusters we use <a href="https://www.ansible.com"><u>Ansible</u></a> and <a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm"><u>kubeadm</u></a>.&nbsp; Our bare metal staging clusters are responsible for testing and validating our Salt configuration. The virtualized clusters give us a vanilla Kubernetes environment without any Cloudflare customizations. Having a stock environment in addition to our Salt environment helps us isolate bugs down to a Kubernetes change, a kernel change, or a Cloudflare-specific configuration change.</p>
	<p>Our virtualized clusters consist of a KubeVirt <a href="https://kubevirt.io/api-reference/v1.2.2/definitions.html#_v1_virtualmachine"><u>VirtualMachine</u></a> object per node. We create three control-plane nodes and any number of worker nodes. Each virtual machine starts out as a vanilla Debian generic <a href="https://cdimage.debian.org/images/cloud"><u>cloud image</u></a>. Using KubeVirt’s <a href="https://kubevirt.io/user-guide/user_workloads/startup_scripts/#cloud-init"><u>cloud-init support</u></a>, the virtual machine downloads an internal <a href="https://www.ansible.com"><u>Ansible</u></a> <a href="https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_intro.html"><u>playbook</u></a> which installs a recent kernel, <a href="https://cri-o.io"><u>cri-o</u></a> (the container runtime we use), and <a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm"><u>kubeadm</u></a>.</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">- name: Add the Kubernetes gpg key
  apt_key:
    url: https://pkgs.k8s.io/core:/stable:/{{ kube_version }}/deb/Release.key
    keyring: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
    state: present

- name: Add the Kubernetes repository
  shell: echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/{{ kube_version }}/deb/ /" | tee /etc/apt/sources.list.d/kubernetes.list

- name: Add the CRI-O gpg key
  apt_key:
    url: https://pkgs.k8s.io/addons:/cri-o:/{{ crio_version }}/deb/Release.key
    keyring: /etc/apt/keyrings/cri-o-apt-keyring.gpg
    state: present

- name: Add the CRI-O repository
  shell: echo "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/{{ crio_version }}/deb/ /" | tee /etc/apt/sources.list.d/cri-o.list

- name: Install CRI-O and Kubernetes packages
  apt:
    name:
      - cri-o
      - kubelet
      - kubeadm
      - kubectl
    update_cache: yes
    state: present

- name: Enable and start CRI-O service
  service:
    state: started
    enabled: yes
    name: crio.service</code></pre>
	<p><sup><i>Ansible playbook steps to download and install Kubernetes tooling</i></sup></p>
	<p>Once each node has completed its individual playbook, we can <a href="http://ools/kubeadm/kubeadm-init"><u>initialize</u></a> and <a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join"><u>join</u></a> nodes to the cluster using another playbook that runs kubeadm. From there the cluster can be accessed by logging into a control plane node using kubectl.</p>
	<h4>Simulating at scale</h4>
	<p>When losing 10s or 100s of nodes at once, Kubernetes needs to act quickly to minimize downtime. The sooner it recognizes node failure, the faster it can reroute traffic to healthy pods.</p>
	<p>Using Kubernetes in KubeVirt we are able to simulate a large cluster undergoing a network cut and observe how Kubernetes reacts. The KubeVirt Kubernetes cluster allows us to rapidly iterate on configuration changes and code patches.</p>
	<p>The following Ansible playbook task simulates a network segmentation failure where only the control-plane nodes remain online.</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">- name: Disable network interfaces on all workers
  command: ifconfig enp1s0 down
  async: 5
  poll: 0
  ignore_errors: yes
  when: inventory_hostname in groups['kube-node']</code></pre>
	<p><sup><i>An Ansible role which disables the network on all worker nodes simultaneously.</i></sup></p>
	<p>This framework allows us to exercise the code in <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager"><u>controller-manager</u></a>, Kubernetes’s daemon that reconciles the fundamental state of the system (Nodes, Pods, etc). Our simulation platform helped us drastically shorten full traffic recovery time when a large number of Kubernetes nodes <a href="https://blog.cloudflare.com/major-data-center-power-failure-again-cloudflare-code-orange-tested"><u>become unreachable</u></a>. We upstreamed our <a href="https://github.com/kubernetes/kubernetes/pull/114296"><u>changes</u></a> to Kubernetes and more controller-manager speed improvements are coming soon.</p>
	<div class="flex anchor relative">
		<h3 id="development-environments">Development environments</h3>
		<a href="https://blog.cloudflare.com/#development-environments" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Compiling code on your laptop can be slow. Perhaps you’re working on a patch for a large open-source project (e.g. <a href="https://v8.dev"><u>V8</u></a> or <a href="https://clickhouse.com"><u>Clickhouse</u></a>) or need more bandwidth to upload and download containers. With KubeVirt, we enable our developers to rapidly iterate on software development and testing on <a href="https://blog.cloudflare.com/cloudflare-gen-12-server-bigger-better-cooler-in-a-2u1n-form-factor"><u>powerful server hardware</u></a>. KubeVirt <a href="https://kubevirt.io/user-guide/storage/disks_and_volumes/#persistentvolumeclaim"><u>integrates</u></a> with Kubernetes <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes"><u>Persistent Volumes</u></a>, which enables teams to persist their development environment across restarts.</p>
	<p>There are a number of teams at Cloudflare using KubeVirt for a variety of development and testing environments. Most notably is a project called Edge Test Fleet, which emulates a physical server and all the software that runs Cloudflare’s <a href="https://www.cloudflare.com/network"><u>global network</u></a>. Teams can test their code and configuration changes against the entire software stack without reserving dedicated hardware. Cloudflare uses <a href="https://blog.cloudflare.com/tag/salt"><u>Salt</u></a> to provision systems. It can be difficult to iterate and test Salt changes without a complete virtual environment. Edge Test Fleet makes iterating on Salt easier, ensuring states compile and render the right output. With Edge Test Fleet, new developers can better understand how Cloudflare’s global network works without touching staging or production.</p>
	<p>Additionally, one Cloudflare team developed a framework that allows users to build and test changes to <a href="https://blog.cloudflare.com/log-analytics-using-clickhouse"><u>Clickhouse</u></a> using a <a href="https://code.visualstudio.com"><u>VSCode</u></a> environment. This framework is generally applicable to all teams requiring a development environment. Once a template environment is provisioned, <a href="https://kubernetes.io/docs/concepts/storage/volume-pvc-datasource"><u>CSI Volume Cloning</u></a> can duplicate a golden volume, separating persistent environments for each developer.</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">apiVersion: v1
kind: PersistentVolumeClaim
name: devspace-jcichra-rootfs
namespace: dev-clickhouse-vms
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: rook-ceph-nvme
  dataSource:
    kind: PersistentVolumeClaim
    name: dev-rootfs
  resources:
    requests:
      storage: 500Gi</code></pre>
	<p><sup><i>A PersistentVolumeClaim that clones data from another volume using CSI Volume Cloning</i></sup></p>
	<div class="flex anchor relative">
		<h3 id="kernel-and-ipxe-testing">Kernel and iPXE testing</h3>
		<a href="https://blog.cloudflare.com/#kernel-and-ipxe-testing" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Unlike <a href="https://en.wikipedia.org/wiki/User_space_and_kernel_space"><u>user space</u></a> software development, when a kernel crashes, the entire system crashes. The <a href="https://blog.cloudflare.com/tag/kernel"><u>kernel</u></a> team uses KubeVirt for development. KubeVirt gives all kernel engineers, regardless of laptop OS or architecture, the same x86 environment and <a href="https://en.wikipedia.org/wiki/Hypervisor"><u>hypervisor</u></a>. Virtual machines on server hardware can be scaled up to more cores and memory than on laptops. The Cloudflare kernel team has also found low-level issues which only surface in environments with many CPUs.</p>
	<p>To make testing fast and easy, the kernel team serves <a href="https://ipxe.org"><u>iPXE</u></a> images via an <a href="https://nginx.org"><u>nginx</u></a> Pod and Service adjacent to the virtual machine. A recent kernel and Debian image are copied to the nginx pod via kubectl cp. The iPXE file can then be referenced in the KubeVirt virtual machine definition via the DNS name for the Kubernetes Service.</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">interfaces:
  name: default
  masquerade: {}
  model: e1000e
  ports:
    - port: 22
      dhcpOptions:
        bootFileName: http://httpboot.u-$K8S_USER.svc.cluster.local/boot.ipxe</code></pre>
	<p>When the virtual machine boots, it will get an IP address on the default interface behind <a href="https://en.wikipedia.org/wiki/Network_address_translation"><u>NAT</u></a> due to our <a href="https://kubevirt.io/user-guide/network/interfaces_and_networks/#masquerade"><u>masquerade</u></a> setting. Then it will download boot.ipxe, which describes what additional files should be downloaded to start the system. In this case, the kernel (<code>vmlinuz-amd64</code>), Debian (<code>baseimg-amd64.img</code>) and additional kernel modules (<code>modules-amd64.img</code>) are downloaded.</p>
	<figure class="kg-card kg-image-card">
		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/74Pndk3FS6TVPACarSKD4N/fc7c3add6bae3c2c8b5e086ef9061872/image2.png" alt="" class="kg-image" width="862" height="484" loading="lazy">
	</figure>
	<p><sup><i>UEFI iPXE boot connecting and downloading files from nginx pod in user’s namespace</i></sup></p>
	<p>Once the system is booted, a developer can log in to the system for testing:</p>
	<pre class="language-JavaScript"><code class="language-JavaScript">linux login: root
Password: 
Linux linux 6.6.35-cloudflare-2024.6.7 #1 SMP PREEMPT_DYNAMIC Mon Sep 27 00:00:00 UTC 2010 x86_64

The programs included with the Debian GNU/Linux system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
root@linux:~# </code></pre>
	<p>Custom kernels can be copied to the nginx pod via <code>kubectl cp</code>. Restarting the virtual machine will load that new kernel for testing. When a kernel panic occurs, the virtual machine can quickly be restarted with <code>virtctl restart linux</code> and it will go through the iPXE boot process again.</p>
	<div class="flex anchor relative">
		<h3 id="build-pipelines">Build pipelines</h3>
		<a href="https://blog.cloudflare.com/#build-pipelines" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Cloudflare leverages KubeVirt to build a majority of software at Cloudflare. Virtual machines give build system users full control over their pipeline. For example, Debian packages can easily be installed and separate container daemons (such as <a href="https://www.docker.com"><u>Docker</u></a>) can run all within a Kubernetes namespace using the <code>restricted</code> Pod Security Standard. KubeVirt’s <a href="https://kubevirt.io/user-guide/user_workloads/replicaset"><u>VirtualMachineReplicaSet</u></a> concept allows us to quickly scale up and down the number of build agents to match demand. We can roll out different sets of virtual machines with varying sizes, kernels, and operating systems.</p>
	<p>To scale efficiently, we leverage <a href="https://kubevirt.io/user-guide/storage/disks_and_volumes/#containerdisk"><u>container disks</u></a> to store our agent virtual machine images. Container disks allow us to store the virtual machine image (for example, a <a href="https://en.wikipedia.org/wiki/Qcow"><u>qcow</u></a> image) in our container registry. This strategy works well when the state in virtual machines is ephemeral. <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command"><u>Liveness probes</u></a> detect unhealthy or broken agents, shutting down the virtual machine and replacing them with a fresh instance. Other automation limits virtual machine uptime, capping it to 3–4 hours to keep build agents fresh.</p>
	<div class="flex anchor relative">
		<h2 id="next-steps">Next steps</h2>
		<a href="https://blog.cloudflare.com/#next-steps" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>We’re excited to expand our use of KubeVirt and unlock new capabilities for our internal users. KubeVirt’s Linux ARM64 support will allow us to build ARM64 packages in-cluster and simulate ARM64 systems.</p>
	<p>Projects like <a href="https://kubevirt.io/user-guide/operations/containerized_data_importer"><u>KubeVirt CDI</u></a> (Containerized Data Importer) will streamline our user’s virtual machine experience. Instead of users manually building container disks, we can provide a catalog of virtual machine images. It also allows us to copy virtual machine disks between namespaces.</p>
	<div class="flex anchor relative">
		<h2 id="conclusion">Conclusion</h2>
		<a href="https://blog.cloudflare.com/#conclusion" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>KubeVirt has proven to be a great tool for virtualization in our Kubernetes-first environment. We’ve unlocked the ability to support more workloads with our multi-tenant model. The KubeVirt platform allows us to offer a single compute platform supporting containers and virtual machines. Managing it has been simple, and upgrades have been straightforward and non-disruptive. We’re exploring additional features KubeVirt offers to improve the experience for our users.</p>
	<p>Finally, our team is expanding! We’re looking for more people passionate about Kubernetes to <a href="https://boards.greenhouse.io/cloudflare/jobs/5579824"><u>join our team</u></a> and help us push Kubernetes to the next level.</p>
</div>