{
	"initialReadingTime": "7",
	"locale": "en-us",
	"localesAvailable": [],
	"post": {
		"authors": [
			{
				"name": "André Cruz",
				"slug": "andre-cruz",
				"bio": null,
				"profile_image": "https://cf-assets.www.cloudflare.com/slt3lc6tev37/44BhO6kzQz5IiGfDAqLlOe/f24b31b19f55ca957ef98812861146dc/andre-cruz.jpg",
				"location": "Lisbon, Portugal",
				"website": null,
				"twitter": "@edevil",
				"facebook": null
			}
		],
		"excerpt": "We use Consul for service discovery, and we’ve deployed a cluster that spans several of our data centers. We were aware from the start that the DNS query latencies were not great from certain parts of the world that were furthest away from these data centers.",
		"feature_image": "https://cf-assets.www.cloudflare.com/slt3lc6tev37/lZtEYoEuiTfYE9d6hCWuF/066705059496b9595f820859c96ef2ca/the-benefits-of-serving-stale-dns-entries-when-using-consul.png",
		"featured": false,
		"html": "\n          <div class=\"flex anchor relative\">\n            <h2 id=\"introduction\">Introduction</h2>\n            <a href=\"#introduction\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>We use <a href=\"https://www.consul.io/\">Consul</a> for service discovery, and we’ve deployed a cluster that spans several of our data centers. This cluster exposes HTTP and DNS interfaces so that clients can query the Consul catalog and search for a particular service and the majority of the clients use DNS. We were aware from the start that the DNS query latencies were not great from certain parts of the world that were furthest away from these data centers. This, together with the fact that we use <a href=\"https://en.wikipedia.org/wiki/DNS_over_TLS\">DNS over TLS</a>, results in some long latencies. The TTL of these names being low makes it even more impractical when resolving these names in the hot path.</p><p>The usual way to solve these issues is by caching values so that at least subsequent requests are resolved quickly, and this is exactly what our resolver of choice, <a href=\"https://www.nlnetlabs.nl/projects/unbound/about/\">Unbound</a>, is configured to do. The problem remains when the cache expires. When it expires, the next client will have to wait while Unbound resolves the name using the network. To have a low recovery time in case some service needs to failover and clients need to use another address we use a small TTL (30 seconds) in our records and as such cache expirations happen often.</p><p>There are at least two strategies to deal with this: prefetching and stale cache.</p>\n          <div class=\"flex anchor relative\">\n            <h2 id=\"prefetching\">Prefetching</h2>\n            <a href=\"#prefetching\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>When prefetching is turned on, the server tries to refresh DNS records in the background before they expire. In practice, the way this works is: if an entry is served from cache and the TTL is less than 10% of the lifetime of the records, the server responds to the client, but in the background, it dispatches a job to refresh the record across the network. If it all goes as planned, the entry is refreshed in the cache before the TTL expires, and no client is ever left waiting for the network resolution.</p><p>This works very well for records that are accessed frequently, but poses issues in two situations: records that are accessed infrequently and records that have a small TTL. In both cases it is unlikely that a prefetch would be triggered, and so the cache expires and the next client will have to wait for the network resolution.</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/6NcCnqSXw360PiHjNzeq2y/950efc55a0899d17ffc3f9cd4b62f9ad/image1-6.png\" alt=\"\" class=\"kg-image\" width=\"825\" height=\"107\" loading=\"lazy\"/>\n            \n            </figure><p>In our case, the records have a 30 second TTL, so frequently no requests come in during the yellow &quot;prefetch&quot; stage, which bumps the records out of the cache and causes the next client to have to wait for the slow network resolution. Prefetching was already turned on in our Unbound configuration but this still was not enough for our use case.</p>\n          <div class=\"flex anchor relative\">\n            <h2 id=\"stale-cache\">Stale cache</h2>\n            <a href=\"#stale-cache\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>Another option is to serve stale records from the cache while we dispatch a job to refresh the record in the background without keeping the client waiting for the response. This would provide benefits in two different scenarios:</p><ul><li><p>General high latency - even after the TTL expires subsequent attempts will be returned from cache if the response takes too long to arrive.</p></li><li><p>Consul/network blips - if for some reason Consul is unavailable/unreachable, there is still a period of time that expired responses can be used instead of failing resolution.</p></li></ul><p>The first case is exactly our current scenario.</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/4ixBixKeeIwU63f485mr2U/e899e066d64620851885f86b1cfa23e3/image7.png\" alt=\"\" class=\"kg-image\" width=\"1041\" height=\"107\" loading=\"lazy\"/>\n            \n            </figure><p>Being able to serve stale entries from the cache for a period after the TTL expires affords us some time in which we can return a result to a client either immediately or after some small amount of time has passed. The latter is the behaviour that we are looking for which also makes us compliant with <a href=\"https://www.rfc-editor.org/rfc/rfc8767\">RFC 8767</a>, “Serving Stale Data to Improve DNS Resiliency”, published March 2020.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"previous-dealings-with-unbounds-stale-cache\">Previous dealings with Unbound's stale cache</h3>\n            <a href=\"#previous-dealings-with-unbounds-stale-cache\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        <p>Stale cache had been tried before at Cloudflare in 2017, and at that time, we encountered two problems:</p><p><b>1. Unbound could serve stale records from cache indefinitely</b>We could solve this through configuration that did not exist in 2017, but we had to test it.</p><p><b>2. Unbound serves negative/incomplete information from the expired cache</b>It was reported that Unbound would serve incomplete chains of responses to clients (for example, a CNAME record with no corresponding A/AAAA record).</p><p>This turned out to be unconfirmed but it is a failure mode that nevertheless we wanted to make sure Unbound could handle since it would be possible for parts of the response chain to be purged from the stale cache before others.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"test-configuration\">Test Configuration</h3>\n            <a href=\"#test-configuration\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        <p>As mentioned before we would need to test a current version of Unbound, come up with an up-to-date stale cache configuration, and test the scenarios that posed problems when we last tried to use it plus any others that we came up with. The Unbound version used for tests was 1.13.0 and the stale cache was configured thus:</p><ul><li><p><i>serve-expired: yes</i> - enable the stale cache.</p></li><li><p><i>serve-expired-ttl: 3600</i> - this limits the serving of expired resources to one hour after they expire and no response from upstream was obtained.</p></li><li><p><i>serve-expired-client-timeout: 500</i> - serve from stale cache only when upstream takes longer than 500ms to respond.</p></li></ul><p>The option <i>serve-expired-ttl-reset</i> was considered, which would cause the records to never expire, even with the upstream down indefinitely as long as there are regular requests for them, but it was deemed too dangerous since it could potentially last forever and applies to all entries.</p><p>Example consul zone: <b>service1.sd</b>.</p><p>While resolving this name we end up with:</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">;; ANSWER SECTION:\nservice1.sd. 120 IN CNAME service1.query.consul.\nservice1.query.consul. 30 IN A 192.0.2.1\n \n;; Query time: 230 msec</pre></code>\n            <p>If we dump Unbound&#39;s cache (unbound-control dump_cache), we can find the entries there:</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">service1.query.consul. 23  IN  A   192.0.2.1\nservice1.sd.   113 IN  CNAME   service1.query.consul.</pre></code>\n            <p>If we wait for the TTL of these entries to expire and dump the cache again, we notice that they don&#39;t show up anymore:</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">➜ unbound-control dump_cache | grep -e query.consul -e service1\n➜</pre></code>\n            <p>But if we block access to the Consul resolver, we can see that still the entries are returned:</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">;; ANSWER SECTION:\nservice1.sd. 119 IN CNAME service1.query.consul.\nservice1.query.consul. 30 IN A 192.0.2.1\n \n;; Query time: 503 msec</pre></code>\n            <p>Notice that Unbound waited 500ms before returning a response, which was the value we configured. This also shows that the dump cache method does not return expired entries even though they are present. So far so good.</p><h5><b>Test - Unbound could serve stale records from cache indefinitely</b></h5><p>After 3600 seconds pass we again try to resolve the same name:</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">➜ dig  service1.sd. @127.0.0.1\n \n; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; service1.sd. @127.0.0.1\n;; global options: +cmd\n;; connection timed out; no servers could be reached</pre></code>\n            <p>Dig gave up on waiting for a response from Unbound. So we see that after the configured time, Unbound will indeed stop serving the stale record, even if it has been requested recently. This is due to <i>serve-expired-ttl: 3600</i> and <i>serve-expired-ttl-reset</i> being set to &quot;no&quot; by default. These options were not available when we first tried Unbound’s stale cache.</p><h5><b>Test - Unbound serves negative/incomplete information from the expired cache</b></h5><p>Since the record we are resolving includes a CNAME and an A record with different TTLs, we will try to see if Unbound can be made to return an incomplete chain (CNAME with no A record).</p><p>We start by having both entries in cache, and block connections to the Consul resolver. We then remove from the cache the A entry:</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">$ /usr/sbin/unbound-control flush_type service1.query.consul. A\nok</pre></code>\n            <p>Now we attempt to query:</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">$ dig  service1.sd. @127.0.0.1\n...\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: SERVFAIL, id: 9532\n;; Query time: 22 msec</pre></code>\n            <p>Nothing was returned which is the result we were expecting.</p><p>Another scenario we wanted to test was to see if when <i>serve-expired-ttl</i> + A&#39;s TTL had passed, the CNAME would be returned on its own.</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">➜ dig  service1.sd. @127.0.0.1\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 48918\n;; ANSWER SECTION:\nservice1.sd. 48 IN CNAME service1.query.consul.\nservice1.query.consul. 30 IN A 192.0.2.1\n;; Query time: 430 msec\n;; WHEN: Thu Dec 31 17:07:55 WET 2020\n \n➜ dig  service1.sd. @127.0.0.1\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: SERVFAIL, id: 42432\n;; Query time: 509 msec\n;; WHEN: Thu Dec 31 17:07:56 WET 2020</pre></code>\n            <p>We lowered <i>serve-expired-ttl</i> to 40 to help testing the issue and we were able to see that as soon as the A entry was deemed not serve-able, the CNAME was also not returned, which is the behaviour that we want.</p><p>One last thing that we wanted to test was if the cache was really refreshed in the background while the stale entry was returned. <a href=\"https://developer.apple.com/download/more/?q=Additional%20Tools\">Network Link Conditioner</a> was used to simulate high latency:</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/2LzVKSaIVIOaKuMuHbq9Fa/fbf67d04de71f3fade1ad2c3bd1e7882/image16.png\" alt=\"\" class=\"kg-image\" width=\"669\" height=\"343\" loading=\"lazy\"/>\n            \n            </figure>\n            <pre class=\"language-bash\"><code class=\"language-bash\">➜ dig service1.service.consul @CONSUL_ADDRESS\n \n;; ANSWER SECTION:\nservice1.service.consul. 60 IN A 192.0.2.10\nservice1.service.consul. 60 IN A 192.0.2.12\n \n;; Query time: 3053 msec</pre></code>\n            <p>We can see that the artificial latency is working. We can now test if changes to the address are actually reflected on the consul record even though a stale record is served at first:</p>\n            <pre class=\"language-bash\"><code class=\"language-bash\">➜ dig service2.service.consul @127.0.0.1\n...\n;; ANSWER SECTION:\nservice2.service.consul. 30 IN A 192.0.2.100\n \n;; Query time: 501 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1)\n;; WHEN: Sat Jan 02 13:00:36 WET 2021\n;; MSG SIZE  rcvd: 89\n \n➜ dig service2.service.consul @127.0.0.1\n...\n;; ANSWER SECTION:\nservice2.service.consul. 58 IN A 192.0.2.200\n \n;; Query time: 0 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1)\n;; WHEN: Sat Jan 02 13:00:39 WET 2021\n;; MSG SIZE  rcvd: 89</pre></code>\n            <p>We can see that the first attempt was served from the stale cache, since the address was already changed on Consul to <i>192.0.2.200</i>, and the query time was 500ms. The next attempt was served from the fresh cache, hence the 0ms response time, and so we know that the cache was refreshed in the background.</p><h4><b>Test notes</b></h4><p>All the test scenarios completed successfully, even though we did find an <a href=\"https://github.com/NLnetLabs/unbound/issues/394\">issue</a> that has since been fixed upstream. We realised that the prefetching logic blocked the cache while it attempted to refresh the entry, which prevented stale entries from being served if the upstream was unresponsive. This fix is included in version 1.13.1.</p>\n          <div class=\"flex anchor relative\">\n            <h2 id=\"deployment-status\">Deployment status</h2>\n            <a href=\"#deployment-status\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>This change has already been deployed to all of our data centers, and while the change addressed our original use case, there were some interesting side-effects as can be seen from the graphs below.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"decreased-in-flight-requests\">Decreased in-flight requests</h3>\n            <a href=\"#decreased-in-flight-requests\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        \n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/5SEqkHk3xrVWSixpgdbdZa/ce9cbe52cb574b4274603917da9e2c8c/image2-2.png\" alt=\"\" class=\"kg-image\" width=\"1624\" height=\"844\" loading=\"lazy\"/>\n            \n            </figure><p>The graph above is from the Toronto data center which received the change at approximately 14:00 UTC. We can observe an attenuated curve, which indicates that spikes in the number of in-flight requests were probably caused by slow/unresponsive upstreams which are now served a stale response after a short while.</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/VG1RTOCYpAKbaGFm1wIzo/66db55a3724a7f484cb3cf6a175644e1/image5-2.png\" alt=\"\" class=\"kg-image\" width=\"1636\" height=\"865\" loading=\"lazy\"/>\n            \n            </figure><p>The same graph from the Perth data center, which received the change on a later day.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"decrease-in-p99-latency\">Decrease in P99 latency</h3>\n            <a href=\"#decrease-in-p99-latency\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        \n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/3sHaBdYvhCW0SdPdPLm03F/f5551ac3ae68ee8c6f35574f7fa3f5d1/image15.png\" alt=\"\" class=\"kg-image\" width=\"1622\" height=\"841\" loading=\"lazy\"/>\n            \n            </figure><p>The graph above is from the Lisbon data center_,_ which received the change at approximately 12:37 UTC. We can see that the long tail (P99) of request latencies decreases dramatically as we are now able to serve a response to clients in more situations without having them wait for a slow upstream network resolution that might not even succeed.</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/4205xzfOSup4fdebmcwW5G/4c8c9971ab1589cf4536400d145d3307/image10-2.png\" alt=\"\" class=\"kg-image\" width=\"1625\" height=\"892\" loading=\"lazy\"/>\n            \n            </figure><p>The effect is even more dramatic on the Paris data center.</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/61OoMQx3e3PjZVzVvQoSUe/203cbeaeb2542d9480c09f3fe0da5148/image8-2.png\" alt=\"\" class=\"kg-image\" width=\"795\" height=\"272\" loading=\"lazy\"/>\n            \n            </figure><p>The decrease in P99 latencies directly correlates to the start of serving stale entries, even though there are not many of them. In the graph above we can observe the number of stale records served per second for the same data center, using the last 3 minutes of datapoints.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"decreased-general-error-rate\">Decreased general error rate</h3>\n            <a href=\"#decreased-general-error-rate\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        \n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/49nNtzXobSQtD0tgnddiJL/cc4867491849f8a7b64ed74f938f61d5/image12.png\" alt=\"\" class=\"kg-image\" width=\"1635\" height=\"865\" loading=\"lazy\"/>\n            \n            </figure><p>This graph is from our Perth data center, which received the change on February 8. This is explained by now being able to serve some requests to unresponsive/slow upstreams, which previously would have resulted in a failed request.</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/6Pj6PgH2tsWfgRjFIOvZ7P/05e928116722350849fdc0e3334f2435/image19.png\" alt=\"\" class=\"kg-image\" width=\"1632\" height=\"862\" loading=\"lazy\"/>\n            \n            </figure><p>Graph from the Vientiane data center, which received the change on February 1.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"less-jitter-on-the-rate-of-load-balancer-queries-by-rrdns\">Less jitter on the rate of load balancer queries by RRDNS</h3>\n            <a href=\"#less-jitter-on-the-rate-of-load-balancer-queries-by-rrdns\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        \n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/6LFLwd8W5wriMKlsZZdCXG/0536db4e8cb6f4077ca6b780053c9f7d/image11.png\" alt=\"\" class=\"kg-image\" width=\"1634\" height=\"862\" loading=\"lazy\"/>\n            \n            </figure><p>Another graph from the Perth data center, which received the change on February 8. An explanation for this change is that resolvers usually retry after a small amount of time when they don&#39;t get any response, and so by returning a stale response instead of keeping the client waiting (and retrying), we prevent a surge of new queries for expired and slow to resolve records.</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/4Nlj6ruekdbxc5e86cDIVd/908c1adbb82920aaba7ba31bd2489297/image18.png\" alt=\"\" class=\"kg-image\" width=\"1633\" height=\"867\" loading=\"lazy\"/>\n            \n            </figure><p>A graph from the Doha data center, which received the change on February 1.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"miscellaneous-unbound-metrics\">Miscellaneous Unbound metrics</h3>\n            <a href=\"#miscellaneous-unbound-metrics\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        <p>This change also had a positive effect on several Unbound-specific metrics, below are several graphs from the Perth data center that received the change on February 8.</p>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/6tvgfdPirOIApYCRxmzujb/6a9684bff01f88c6cfe23ebb9e900a66/image6-2.png\" alt=\"\" class=\"kg-image\" width=\"791\" height=\"308\" loading=\"lazy\"/>\n            \n            </figure>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/1TnCvyvE1SxFM02ulD7wOA/9d031ed7b441c25b8755f48c3933060e/image13.png\" alt=\"\" class=\"kg-image\" width=\"790\" height=\"267\" loading=\"lazy\"/>\n            \n            </figure>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/1KnVnBNkHrtUnkuC4X4rlN/e05252b61e53927b303decff1916f7ad/image14.png\" alt=\"\" class=\"kg-image\" width=\"787\" height=\"229\" loading=\"lazy\"/>\n            \n            </figure>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/1K0X5VnGlDWyfj4GXhHwKR/8632ffd3994bd382f9e5fa4638916894/image4-4.png\" alt=\"\" class=\"kg-image\" width=\"789\" height=\"231\" loading=\"lazy\"/>\n            \n            </figure>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/78YTgVILYTXNqtkZCgPZhu/01a7dc9644f6100450cc9ffcbc4c5eb1/image9-1.png\" alt=\"\" class=\"kg-image\" width=\"788\" height=\"269\" loading=\"lazy\"/>\n            \n            </figure>\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/3lbt8d6fKHtHIi84k0SnyW/43dab47838c8031ac239238c3ea18cf0/image17.png\" alt=\"\" class=\"kg-image\" width=\"792\" height=\"270\" loading=\"lazy\"/>\n            \n            </figure><p>How it started vs how it&#39;s going</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"further-improvements\">Further improvements</h3>\n            <a href=\"#further-improvements\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        <p>In the future, we would like to tweak the <i>serve-expired-client-timeout</i> value, which is currently set to 500ms. It was chosen conservatively, at a time when we were cautiously experimenting with a feature that had been problematic in the past, and our gut feeling is that it can be at least halved without causing issues to further improve the client’s experience. There is also the possibility of using different values per data center, for example picking up the P90 resolve latency value which differs per datacenter, and this is something that we want to explore further.</p>\n          <div class=\"flex anchor relative\">\n            <h2 id=\"summary\">Summary</h2>\n            <a href=\"#summary\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>We are enabling Unbound to return expired entries from the cache whenever an upstream takes longer than 500ms to respond, while refreshing the cache in the background, unless 3600 seconds have elapsed from the record&#39;s original TTL.</p>",
		"id": "64s0ckd7FF53Lw8Q48zi1h",
		"localeList": {
			"name": "The benefits of serving stale DNS entries when using Consul Config",
			"enUS": "English for Locale",
			"zhCN": "No Page for Locale",
			"zhHansCN": "No Page for Locale",
			"zhTW": "No Page for Locale",
			"frFR": "No Page for Locale",
			"deDE": "No Page for Locale",
			"itIT": "No Page for Locale",
			"jaJP": "No Page for Locale",
			"koKR": "No Page for Locale",
			"ptBR": "No Page for Locale",
			"esLA": "No Page for Locale",
			"esES": "No Page for Locale",
			"enAU": "No Page for Locale",
			"enCA": "No Page for Locale",
			"enIN": "No Page for Locale",
			"enGB": "No Page for Locale",
			"idID": "No Page for Locale",
			"ruRU": "No Page for Locale",
			"svSE": "No Page for Locale",
			"viVN": "No Page for Locale",
			"plPL": "No Page for Locale",
			"arAR": "No Page for Locale",
			"nlNL": "No Page for Locale",
			"thTH": "No Page for Locale",
			"trTR": "No Page for Locale",
			"heIL": "No Page for Locale",
			"lvLV": "No Page for Locale",
			"etEE": "No Page for Locale",
			"ltLT": "No Page for Locale"
		},
		"meta_description": "We use Consul for service discovery, and we’ve deployed a cluster that spans several of our data centers. We were aware from the start that the DNS query latencies were not great from certain parts of the world that were furthest away from these data centers.",
		"metadata": {
			"title": "The benefits of serving stale DNS entries when using Consul",
			"description": "We use Consul for service discovery, and we’ve deployed a cluster that spans several of our data centers. We were aware from the start that the DNS query latencies were not great from certain parts of the world that were furthest away from these data centers.",
			"imgPreview": "https://cf-assets.www.cloudflare.com/slt3lc6tev37/7GzPQpRvt88dyIYifu1Kfn/2fe0778fae5cbbe41d6863ba12150b1c/the-benefits-of-serving-stale-dns-entries-when-using-consul-fKC6DN.png"
		},
		"primary_author": {},
		"published_at": "2021-03-08T14:00:00.000+00:00",
		"slug": "the-benefits-of-serving-stale-dns-entries-when-using-consul",
		"tags": [
			{
				"id": "5fZHv2k9HnJ7phOPmYexHw",
				"name": "DNS",
				"slug": "dns"
			},
			{
				"id": "5RrjSR5vIOJAfRdT8966hf",
				"name": "Cache",
				"slug": "cache"
			}
		],
		"title": "The benefits of serving stale DNS entries when using Consul",
		"updated_at": "2024-08-27T01:53:14.548Z",
		"url": "https://blog.cloudflare.com/the-benefits-of-serving-stale-dns-entries-when-using-consul"
	},
	"translations": {
		"posts.by": "By",
		"footer.gdpr": "GDPR",
		"lang_blurb1": "This post is also available in {lang1}.",
		"lang_blurb2": "This post is also available in {lang1} and {lang2}.",
		"lang_blurb3": "This post is also available in {lang1}, {lang2} and {lang3}.",
		"footer.blurb": "Cloudflare's connectivity cloud protects <a target='_blank' href='https://www.cloudflare.com/network-services/' rel='noreferrer'>entire corporate networks</a>, helps customers build <a target='_blank' href='https://workers.cloudflare.com/' rel='noreferrer'>Internet-scale applications efficiently</a>, accelerates any <a target='_blank' href='https://www.cloudflare.com/performance/accelerate-internet-applications/' rel='noreferrer'>website or Internet application</a>, <a target='_blank' href='https://www.cloudflare.com/ddos/' rel='noreferrer'>wards off DDoS attacks</a>, keeps <a target='_blank' href='https://www.cloudflare.com/application-security/' rel='noreferrer'>hackers at bay</a>, and can help you on <a target='_blank' href='https://www.cloudflare.com/products/zero-trust/' rel='noreferrer'>your journey to Zero Trust</a>.<br/><br/>Visit <a target='_blank' href='https://one.one.one.one/' rel='noreferrer'>1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.<br/><br/>To learn more about our mission to help build a better Internet, <a target='_blank' href='https://www.cloudflare.com/learning/what-is-cloudflare/' rel='noreferrer'>start here</a>. If you&apos;re looking for a new career direction, check out <a target='_blank' href='http://www.cloudflare.com/careers' rel='noreferrer'>our open positions</a>.",
		"footer.press": "Press",
		"header.title": "The Cloudflare Blog",
		"search.clear": "Clear",
		"search.filter": "Filter",
		"search.source": "Source",
		"footer.careers": "Careers",
		"footer.company": "Company",
		"footer.support": "Support",
		"footer.the_net": "theNet",
		"search.filters": "Filters",
		"footer.our_team": "Our team",
		"footer.webinars": "Webinars",
		"page.more_posts": "More posts",
		"posts.time_read": "{time} min read",
		"search.language": "Language",
		"footer.community": "Community",
		"footer.resources": "Resources",
		"footer.solutions": "Solutions",
		"footer.trademark": "Trademark",
		"header.subscribe": "Subscribe",
		"footer.compliance": "Compliance",
		"footer.free_plans": "Free plans",
		"footer.impact_ESG": "Impact/ESG",
		"posts.follow_on_X": "Follow on X",
		"footer.help_center": "Help center",
		"footer.network_map": "Network Map",
		"header.please_wait": "Please Wait",
		"page.related_posts": "Related posts",
		"search.result_stat": "Results <strong>{search_range}</strong> of <strong>{search_total}</strong> for <strong>{search_keyword}</strong>",
		"footer.case_studies": "Case Studies",
		"footer.connect_2024": "Connect 2024",
		"footer.terms_of_use": "Terms of Use",
		"footer.white_papers": "White Papers",
		"footer.cloudflare_tv": "Cloudflare TV",
		"footer.community_hub": "Community Hub",
		"footer.compare_plans": "Compare plans",
		"footer.contact_sales": "Contact Sales",
		"header.contact_sales": "Contact Sales",
		"header.email_address": "Email Address",
		"page.error.not_found": "Page not found",
		"footer.developer_docs": "Developer docs",
		"footer.privacy_policy": "Privacy Policy",
		"footer.request_a_demo": "Request a demo",
		"page.continue_reading": "Continue reading",
		"footer.analysts_report": "Analyst reports",
		"footer.for_enterprises": "For enterprises",
		"footer.getting_started": "Getting Started",
		"footer.learning_center": "Learning Center",
		"footer.project_galileo": "Project Galileo",
		"pagination.newer_posts": "Newer Posts",
		"pagination.older_posts": "Older Posts",
		"posts.social_buttons.x": "Discuss on X",
		"search.source_location": "Source/Location",
		"footer.about_cloudflare": "About Cloudflare",
		"footer.athenian_project": "Athenian Project",
		"footer.become_a_partner": "Become a partner",
		"footer.cloudflare_radar": "Cloudflare Radar",
		"footer.network_services": "Network services",
		"footer.trust_and_safety": "Trust & Safety",
		"header.get_started_free": "Get Started Free",
		"page.search.placeholder": "Search Cloudflare",
		"footer.cloudflare_status": "Cloudflare Status",
		"footer.cookie_preference": "Cookie Preferences",
		"header.valid_email_error": "Must be valid email.",
		"footer.connectivity_cloud": "Connectivity cloud",
		"footer.developer_services": "Developer services",
		"footer.investor_relations": "Investor relations",
		"page.not_found.error_code": "Error Code: 404",
		"footer.logos_and_press_kit": "Logos & press kit",
		"footer.application_services": "Application services",
		"footer.get_a_recommendation": "Get a recommendation",
		"posts.social_buttons.reddit": "Discuss on Reddit",
		"footer.sse_and_sase_services": "SSE and SASE services",
		"page.not_found.outdated_link": "You may have used an outdated link, or you may have typed the address incorrectly.",
		"footer.report_security_issues": "Report Security Issues",
		"page.error.error_message_page": "Sorry, we can't find the page you are looking for.",
		"header.subscribe_notifications": "Subscribe to receive notifications of new posts:",
		"footer.cloudflare_for_campaigns": "Cloudflare for Campaigns",
		"header.subscription_confimation": "Subscription confirmed. Thank you for subscribing!",
		"posts.social_buttons.hackernews": "Discuss on Hacker News",
		"footer.diversity_equity_inclusion": "Diversity, equity & inclusion",
		"footer.critical_infrastructure_defense_project": "Critical Infrastructure Defense Project"
	}
}