<div class="mb2 gray5">4 min read</div><img class="mr2" src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4Vbdg5q0h79G3DymW7YcZ0/fb0cb1e213d42c25526b552a6b2e8da8/third-times-the-cache-no-more.png" alt="">
<div class="post-content lh-copy gray1">
	<p></p>
	<p>Caching is a big part of how Cloudflare CDN makes the Internet faster and more reliable. When a visitor to a customer’s website requests an asset, we retrieve it from the customer’s origin server. After that first request, in many cases we <i>cache</i> that asset. Whenever anyone requests it again, we can serve it from one of our data centers close to them, dramatically speeding up load times.</p>
	<p>Did you notice the small caveat? We cache after the <i>first</i> request in <i>many</i> cases, not all. One notable exception since 2010 up until now: requests with <i>query strings</i>. When a request came with a query string (think <a href="https://example.com/image.jpg?width=500">https://example.com/image.jpg?width=500</a>; the <code>?width=500</code> is the query string), we needed to see it a whole <i>three</i> times before we would cache it on our <a href="https://support.cloudflare.com/hc/en-us/articles/200168256-Understand-Cloudflare-Caching-Level">default cache level</a>. Weird!</p>
	<p>This is a short tale of that strange exception, why we thought we needed it, and how, more than ten years later, we showed ourselves that we didn’t.</p>
	<div class="flex anchor relative">
		<h3 id="two-misses-too-many">Two MISSes too many</h3>
		<a href="https://blog.cloudflare.com/#two-misses-too-many" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>To see the exception in action, here’s a command we ran a couple weeks ago. It requests an image hosted on <code>example.com</code> five times and prints each response’s <a href="https://support.cloudflare.com/hc/en-us/articles/200172516-Understanding-Cloudflare-s-CDN#h_bd959d6a-39c0-4786-9bcd-6e6504dcdb97">CF-Cache-Status header</a>. That header tells us what the cache did while serving the request.</p>
	<pre class="language-bash"><code class="language-bash">❯ for i in {1..5}; do curl -svo /dev/null example.com/image.jpg 2&gt;&amp;1 | grep -e 'CF-Cache-Status'; sleep 3; done
&lt; CF-Cache-Status: MISS
&lt; CF-Cache-Status: HIT
&lt; CF-Cache-Status: HIT
&lt; CF-Cache-Status: HIT
&lt; CF-Cache-Status: HIT</code></pre>
	<p>The MISS means that we couldn’t find the asset in the cache and had to retrieve it from the origin server. On the HITs, we served the asset from cache.</p>
	<p>Now, just by adding a query string to the same request (<code>?query=val</code>):</p>
	<pre class="language-bash"><code class="language-bash">❯ for i in {1..5}; do curl -svo /dev/null example.com/image.jpg\?query\=val 2&gt;&amp;1 | grep -e 'CF-Cache-Status'; sleep 3; done
&lt; CF-Cache-Status: MISS
&lt; CF-Cache-Status: MISS
&lt; CF-Cache-Status: MISS
&lt; CF-Cache-Status: HIT
&lt; CF-Cache-Status: HIT</code></pre>
	<p>There they are - three MISSes, meaning two extra trips to the customer origin!</p>
	<p>We traced this surprising behavior back to a git commit from Cloudflare’s earliest days in 2010. Since then, it has spawned chat threads, customer escalations, and even an internal Solutions Engineering blog post that christened it the “third time’s the charm” quirk.</p>
	<p>It would be much less confusing if we could make the query string behavior align with the others, but why was the quirk here to begin with?</p>
	<div class="flex anchor relative">
		<h3 id="unpopular-queries">Unpopular queries</h3>
		<a href="https://blog.cloudflare.com/#unpopular-queries" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>From an engineering perspective, forcing three MISSes for query strings can make sense as a way to protect ourselves from unnecessary disk writes.</p>
	<p>That’s because for many requests with query strings in the URL, we may never see that URL requested again.</p>
	<ol>
		<li>
			<p>Some query strings simply pass along data to the origin server that may not actually result in a different response from the base URL, for example, a visitor’s browser metadata. We end up caching the same response behind many different, potentially unique, cache keys.</p>
		</li>
		<li>
			<p>Some query strings are <i>intended</i> to bypass caches. These “cache busting” requests append randomized query strings in order to force pulling from the origin, a strategy that some <a href="https://support.google.com/campaignmanager/answer/2837435?hl=en#zippy=%2Chow-does-cache-busting-work">ad managers use to count impressions</a>.</p>
		</li>
	</ol>
	<p>Unpopular requests are not a new problem for us. Previously, <a href="https://blog.cloudflare.com/why-we-started-putting-unpopular-assets-in-memory">we wrote about how we use an in-memory transient cache</a> to store requests we only ever see once (dubbed “one-hit-wonders”) so that they are never written to disk. This transient cache, enabled for just a subset of traffic, reduces our disk writes by 20-25%.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/57yHAVDQQJWmKXvIkZirLm/24ee2c3198f5af8b54a07c8e545ec9f8/image2-15.png" alt="This transient cache, enabled for just a subset of traffic, reduces our disk writes by 20-25%." class="kg-image" width="1149" height="647" loading="lazy">

	</figure>
	<p>Was this behavior from 2010 giving us similar benefits? Since then, our network has grown from 10,000 Internet properties to 25 million. It was time to re-evaluate. Just how much would our disk writes increase if we cached on the first request? How much better would cache hit ratios be?</p>
	<div class="flex anchor relative">
		<h3 id="hypotheses-querying-the-cache">Hypotheses: querying the cache</h3>
		<a href="https://blog.cloudflare.com/#hypotheses-querying-the-cache" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>Good news: our metrics showed only around 3.5% of requests use the default cache level with query strings. Thus, we shouldn’t expect more than a few percentage points difference in disk writes. Less good: <a href="https://www.cloudflare.com/learning/cdn/what-is-a-cache-hit-ratio">cache hit rate</a> shouldn’t increase much either.</p>
	<p>On the other hand, we also found that a significant portion of these requests are images, which could potentially take up lots of disk space and hike up cache eviction rates. Enough napkin math - we needed to start assessing real world data.</p>
	<div class="flex anchor relative">
		<h3 id="a-b-testing-caching-the-queries">A/B testing: caching the queries</h3>
		<a href="https://blog.cloudflare.com/#a-b-testing-caching-the-queries" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>We were able to validate our hypotheses using an <a href="https://en.wikipedia.org/wiki/A/B_testing">A/B test</a>, where half the machines in a data center use the old behavior and half do not. This enabled us to control for Internet traffic fluctuations over time and get more precise impact numbers.</p>
	<p>Other considerations: we limited the test to one data center handling a small slice of our traffic to minimize the impact of any negative side effects. We also disabled transient cache, which would nullify some of the I/O costs we expected to observe. By turning transient cache off for the experiment, we should see the upper bound of the disk write increase.</p>
	<p>We ran this test for a couple days and, as hypothesized, found a minor but acceptable increase in disk writes per request to the tune of 2.5%.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2QFiZGM6WpUd9OYZ135xLb/1a57482bbecd6e08f93d4102b7b0359a/image3-17.png" alt="We ran this test for a couple days and, as hypothesized, found a minor but acceptable increase in disk writes per request to the tune of 2.5%." class="kg-image" width="760" height="273" loading="lazy">

	</figure>
	<p>What’s more, we saw a modest hit rate increase of around +3% on average for our Enterprise customers. More hits meant fewer trips to origin servers and thus bandwidth savings for customers: in this case, a -5% decrease in total bytes served from origin.</p>
	<p>Note that we saw hit rate increases for certain customers across <i>all</i> plan types. Those with the biggest boost had a variety of query strings across different visitor populations (e.g. appending query strings such as <code>?resize=100px:*&amp;output-quality=60</code> <a href="https://developers.cloudflare.com/images/resizing-with-workers">to optimize serving images for different screen sizes</a>). A few additional HITs for many different, but still popular, cache keys really added up.</p>
	<div class="flex anchor relative">
		<h3 id="revisiting-old-assumptions">Revisiting old assumptions</h3>
		<a href="https://blog.cloudflare.com/#revisiting-old-assumptions" aria-hidden="true" class="relative sm:absolute sm:-left-5">
			<svg width="16" height="16" viewBox="0 0 24 24">
				<path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path>
			</svg>
		</a>
	</div>
	<p>What the aggregate hit rate increase implied was that for a significant portion of customers, our old query string behavior was too defensive. We were overestimating the proportion of query string requests that were one-hit-wonders.</p>
	<p>Given that these requests are a relatively small percentage of total traffic, we didn’t expect to see massive hit rate improvements. In fact, if the assumptions about many query string requests being one-hit-wonders were correct, we should hardly be seeing any difference at all. (One-hit-wonders are actually “one MISS wonders” in the context of hit rate.) Instead, we saw hit rate increases proportional to the affected traffic percentage. This, along with the minor I/O cost increases, signaled that the benefits of removing the behavior would outweigh the benefits of keeping it.</p>
	<p>Using a data-driven approach, we determined our caution around caching query string requests wasn’t nearly as effective at preventing disk writes of unpopular requests compared to our newer efforts, such as transient cache. It was a good reminder for us to re-examine past assumptions from time-to-time and see if they still held.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/29s2kKkqUOMWDmlFHY5qp8/60a7d113cde89a6e197d4536bd911e7b/image4-15.png" alt="Revisiting old assumptions" class="kg-image" width="1918" height="1068" loading="lazy">

	</figure>
	<p>Post-experiment, we gradually rolled out the change to verify that our cost expectations were met. At this time, we’re happy to report that we’ve left the “third time’s the charm” quirk behind for the history books. Long live “cache at first sight.”</p>
</div>