{
	"footerBlurb": "Cloudflare's connectivity cloud protects <a target='_blank' href='https://www.cloudflare.com/network-services/' rel='noreferrer'>entire corporate networks</a>, helps customers build <a target='_blank' href='https://workers.cloudflare.com/' rel='noreferrer'>Internet-scale applications efficiently</a>, accelerates any <a target='_blank' href='https://www.cloudflare.com/performance/accelerate-internet-applications/' rel='noreferrer'>website or Internet application</a>, <a target='_blank' href='https://www.cloudflare.com/ddos/' rel='noreferrer'>wards off DDoS attacks</a>, keeps <a target='_blank' href='https://www.cloudflare.com/application-security/' rel='noreferrer'>hackers at bay</a>, and can help you on <a target='_blank' href='https://www.cloudflare.com/products/zero-trust/' rel='noreferrer'>your journey to Zero Trust</a>.<br/><br/>Visit <a target='_blank' href='https://one.one.one.one/' rel='noreferrer'>1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.<br/><br/>To learn more about our mission to help build a better Internet, <a target='_blank' href='https://www.cloudflare.com/learning/what-is-cloudflare/' rel='noreferrer'>start here</a>. If you&apos;re looking for a new career direction, check out <a target='_blank' href='http://www.cloudflare.com/careers' rel='noreferrer'>our open positions</a>.",
	"initialReadingTime": "4",
	"locale": "en-us",
	"localesAvailable": [],
	"post": {
		"authors": [
			{
				"name": "Harley Turan",
				"slug": "harley",
				"bio": null,
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2ozodx2P7ECyPDX81E74NC/9757235a7313dcc5f6f559bb47c16620/harley.JPG",
				"location": null,
				"website": "https://hturan.com",
				"twitter": "@hturan",
				"facebook": null
			},
			{
				"name": "Dhravya Shah",
				"slug": "dhravya",
				"bio": "18, passionate dev who ships (a lot) Building a better (intern)et at Cloudflare AI. building Supermemory.ai. 2x acquired founder. reader, guitarist, space enthusiast",
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1xcx1Lxlh4a2yXgBcYSRtH/65fbda8d9808f1aa44367e666b159a06/dhravya.jpg",
				"location": "Austin, Texas",
				"website": "https://dhravya.dev",
				"twitter": "@dhravyashah",
				"facebook": null
			},
			{
				"name": "Michelle Chen",
				"slug": "michelle",
				"bio": null,
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1hrcl3aVtUbBuCMeuXETWy/93dbfbc7d41c09ba35d863312dbde89d/michelle.jpg",
				"location": null,
				"website": null,
				"twitter": "@_mchenco",
				"facebook": null
			}
		],
		"excerpt": "Introducing a new way to do function calling in Workers AI by running function code alongside your inference. Plus, a new @cloudflare/ai-utils package to make getting started as simple as possible",
		"feature_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5fJ5fF4luhUlJEOsRKqc8X/0b307037c96cd66d10efd4a49d98b93b/embedded-function-calling.png",
		"featured": false,
		"html": "\n            <figure class=\"kg-card kg-image-card \">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6s64pzMizJT22AKVCpeYu2/1db371bffec9a960c8f59c69330970bb/image2-14.png\" alt=\"Embedded function calling in Workers AI: easier, smarter, faster\" class=\"kg-image\" width=\"1800\" height=\"1013\" loading=\"lazy\"/>\n            \n            </figure>\n          <div class=\"flex anchor relative\">\n            <h2 id=\"introducing-embedded-function-calling-and-a-new-ai-utils-package\">Introducing embedded function calling and a new ai-utils package</h2>\n            <a href=\"#introducing-embedded-function-calling-and-a-new-ai-utils-package\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>Today, we’re excited to announce a novel way to do function calling that co-locates LLM inference with function execution, and a new ai-utils package that upgrades the developer experience for function calling.</p><p>This is a follow-up to our <a href=\"https://x.com/CloudflareDev/status/1803849609078284315\">mid-June announcement for traditional function calling</a>, which allows you to leverage a Large Language Model (LLM) to intelligently generate structured outputs and pass them to an API call. Function calling has been largely adopted and standardized in the industry as a way for AI models to help perform actions on behalf of a user.</p><p>Our goal is to make building with AI as easy as possible, which is why we’re introducing a new <a href=\"https://www.npmjs.com/package/@cloudflare/ai-utils\">@cloudflare/ai-utils</a> npm package that allows developers to get started quickly with embedded function calling. These helper tools drastically simplify your workflow by actually executing your function code and dynamically generating tools from OpenAPI specs. We’ve also open-sourced our ai-utils package, which you can find on <a href=\"https://github.com/cloudflare/ai-utils\">GitHub</a>. With both embedded function calling and our ai-utils, you’re one step closer to creating intelligent AI agents, and from there, the possibilities are endless.</p>\n          <div class=\"flex anchor relative\">\n            <h2 id=\"why-cloudflares-ai-platform\">Why Cloudflare’s AI platform?</h2>\n            <a href=\"#why-cloudflares-ai-platform\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>OpenAI has been the gold standard when it comes to having performant model inference and a great developer experience. However, they mostly support their closed-source models, while we want to also promote the open-source ecosystem of models. One of our goals with Workers AI is to match the developer experience you might get from OpenAI, but with open-source models.</p><p>There are other open-source inference providers out there like <a href=\"https://azure.microsoft.com/en-us/solutions/ai\">Azure</a> or <a href=\"https://aws.amazon.com/bedrock/\">Bedrock</a>, but most of them are focused on serving inference and the underlying infrastructure, rather than being a developer toolkit. While there are external libraries and frameworks like AI SDK that help developers build quickly with simple abstractions, they rely on upstream providers to do the actual inference. With <a href=\"https://developers.cloudflare.com/workers-ai/\">Workers AI</a>, it’s the best of both worlds – we offer open-source model inference and a killer developer experience out of the box.</p><p>With the release of embedded function calling and ai-utils today, we’ve advanced how we do inference for function calling and improved the developer experience by making it dead simple for developers to start building AI experiences.</p>\n          <div class=\"flex anchor relative\">\n            <h2 id=\"how-does-traditional-function-calling-work\">How does traditional function calling work?</h2>\n            <a href=\"#how-does-traditional-function-calling-work\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>Traditional LLM function calling allows customers to specify a set of function names and required arguments along with a prompt when running inference on an LLM. The LLM returns the names and arguments for the functions that the customer can then make to perform actions. These actions give LLMs the ability to do things like fetch fresh data not present in the training dataset and &quot;perform actions&quot; based on user intent.</p>\n            <figure class=\"kg-card kg-image-card kg-width-wide\">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2vZ1PHwC5e6RUkxQRKfBW0/1812907a22283b5eef02e92c747e8a73/image3-15.png\" alt=\"\" class=\"kg-image\" width=\"1786\" height=\"990\" loading=\"lazy\"/>\n            \n            </figure><p>Traditional function calling requires multiple back-and-forth requests passing through the network in order to get to the final output. This includes requests to your origin server, an inference provider, and external APIs. As a developer, you have to orchestrate all the back-and-forths and handle all the requests and responses. If you were building complex agents with multi-tool calls or recursive tool calls, it gets infinitely harder. Fortunately, this doesn’t have to be the case, and we’ve solved it for you.</p>\n          <div class=\"flex anchor relative\">\n            <h2 id=\"embedded-function-calling\">Embedded function calling</h2>\n            <a href=\"#embedded-function-calling\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>With Workers AI, our inference runtime is the Workers platform, and the Workers platform can be seen as a global compute network of distributed functions (RPCs). With this model, we can run inference using Workers AI, and supply not only the function names and arguments, but also the runtime function code to be executed. Rather than performing multiple round-trips across networks, the LLM inference and function can run in the same execution environment, cutting out all the unnecessary requests.</p>\n            <figure class=\"kg-card kg-image-card kg-width-wide\">\n            \n            <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/15yHmiG9OmRj9KkuLHteRm/2c50ad90b4736fbc7496a8495d58e1fe/image1-23.png\" alt=\"\" class=\"kg-image\" width=\"1996\" height=\"690\" loading=\"lazy\"/>\n            \n            </figure><p>Cloudflare is one of the few inference providers that is able to do this because we offer more than just inference – our developer platform has compute, storage, inference, and more, all within the same Workers runtime.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"we-made-it-easy-for-you-with-a-new-ai-utils-package\">We made it easy for you with a new ai-utils package</h3>\n            <a href=\"#we-made-it-easy-for-you-with-a-new-ai-utils-package\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        <p>And to make it as simple as possible, we created a <a href=\"https://www.npmjs.com/package/@cloudflare/ai-utils\"><code>@cloudflare/ai-utils</code></a> package that you can use to get started. These powerful abstractions cut down on the logic you have to implement to do function calling – it just works out of the box.</p>\n          <div class=\"flex anchor relative\">\n            <h3 id=\"runwithtools\">runWithTools</h3>\n            <a href=\"#runwithtools\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        <p><code>runWithTool</code>s is our method that you use to do embedded function calling. You pass in your AI binding (env.AI), model, prompt messages, and tools. The tools array includes the description of the function, similar to traditional function calling, but you also pass in the function code that needs to be executed. This method makes the inference calls and executes the function code in one single step. <code>runWithTools</code> is also able to handle multiple function calls, recursive tool calls, validation for model responses, streaming for the final response, and other features.</p><p>Another feature to call out is a helper method called <code>autoTrimTools</code> that automatically selects the relevant tools and trims the tools array based on the names and descriptions. We do this by adding an initial LLM inference call to intelligently trim the tools array before the actual function-calling inference call is made. We found that <code>autoTrimTools</code> helped decrease the number of total tokens used in the entire process (especially when there’s a large number of tools provided) because there’s significantly fewer input tokens used when generating the arguments list. You can choose to use <code>autoTrimTools</code> by setting it as a parameter in the <code>runWithTools</code> method.</p>\n            <pre class=\"language-javascript\"><code class=\"language-javascript\">const response = await runWithTools(env.AI,&quot;@hf/nousresearch/hermes-2-pro-mistral-7b&quot;,\n  {\n    messages: [{ role: &quot;user&quot;, content: &quot;What&#039;s the weather in Austin, Texas?&quot;}],\n    tools: [\n      {\n        name: &quot;getWeather&quot;,\n        description: &quot;Return the weather for a latitude and longitude&quot;,\n        parameters: {\n          type: &quot;object&quot;,\n          properties: {\n            latitude: {\n              type: &quot;string&quot;,\n              description: &quot;The latitude for the given location&quot;\n            },\n            longitude: {\n              type: &quot;string&quot;,\n              description: &quot;The longitude for the given location&quot;\n            }\n          },\n          required: [&quot;latitude&quot;, &quot;longitude&quot;]\n        },\n\t // function code to be executed after tool call\n        function: async ({ latitude, longitude }) =&gt; {\n          const url = `https://api.weatherapi.com/v1/current.json?key=${env.WEATHERAPI_TOKEN}&amp;q=${latitude},${longitude}`\n          const res = await fetch(url).then((res) =&gt; res.json())\n\n          return JSON.stringify(res)\n        }\n      }\n    ]\n  },\n  {\n    streamFinalResponse: true,\n    maxRecursiveToolRuns: 5,\n    trimFunction: autoTrimTools,\n    verbose: true,\n    strictValidation: true\n  }\n)</pre></code>\n            \n          <div class=\"flex anchor relative\">\n            <h3 id=\"createtoolsfromopenapispec\">createToolsFromOpenAPISpec</h3>\n            <a href=\"#createtoolsfromopenapispec\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n        <p>For many use cases, users will need to make a request to an external API call during function calling to get the output needed. Instead of having to hardcode the exact API endpoints in your tools array, we made a helper function that takes in an OpenAPI spec and dynamically generates the corresponding tool schemas and API endpoints you’ll need for the function call. You call <code>createToolsFromOpenAPISpec</code> from within runWithTools and it’ll dynamically populate everything for you.</p>\n            <pre class=\"language-javascript\"><code class=\"language-javascript\">const response = await runWithTools(env.AI, &quot;@hf/nousresearch/hermes-2-pro-mistral-7b&quot;, {\n  messages: [{ role: &quot;user&quot;,content: &quot;Can you name me 5 repos created by Cloudflare&quot;}],\n  tools: [\n    ...(await createToolsFromOpenAPISpec(  &quot;https://raw.githubusercontent.com/github/rest-api-description/main/descriptions-next/api.github.com/api.github.com.json&quot;\n    ))\n  ]\n})</pre></code>\n            \n          <div class=\"flex anchor relative\">\n            <h2 id=\"putting-it-all-together\">Putting it all together</h2>\n            <a href=\"#putting-it-all-together\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n              <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n            </a>\n          </div>\n          <p>When you make a function calling inference request with <code>runWithTools</code> and <code>createToolsFromOpenAPISpec</code>, the only thing you need is the prompts – the rest is automatically handled. The LLM will choose the correct tool based on the prompt, the runtime will execute the function needed, and you’ll get a fast, intelligent response from the model. By leveraging our Workers runtime’s bindings and RPC calls along with our global network, we can execute everything from a single location close to the user, enabling developers to easily write complex agentic chains with fewer lines of code.</p><p>We’re super excited to help people build intelligent AI systems with our new embedded function calling and powerful tools. Check out our <a href=\"https://developers.cloudflare.com/workers-ai/function-calling/\">developer docs</a> on how to get started, and let us know what you think on <a href=\"https://discord.cloudflare.com\">Discord</a>.</p>",
		"id": "28DvCOWrN5gKA9IBZqrdc3",
		"localeList": {
			"name": "Embedded function calling in Workers AI: easier, smarter, faster Config",
			"enUS": "English for Locale",
			"zhCN": "No Page for Locale",
			"zhHansCN": "No Page for Locale",
			"zhTW": "No Page for Locale",
			"frFR": "No Page for Locale",
			"deDE": "No Page for Locale",
			"itIT": "No Page for Locale",
			"jaJP": "No Page for Locale",
			"koKR": "No Page for Locale",
			"ptBR": "No Page for Locale",
			"esLA": "No Page for Locale",
			"esES": "No Page for Locale",
			"enAU": "No Page for Locale",
			"enCA": "No Page for Locale",
			"enIN": "No Page for Locale",
			"enGB": "No Page for Locale",
			"idID": "No Page for Locale",
			"ruRU": "No Page for Locale",
			"svSE": "No Page for Locale",
			"viVN": "No Page for Locale",
			"plPL": "No Page for Locale",
			"arAR": "No Page for Locale",
			"nlNL": "No Page for Locale",
			"thTH": "No Page for Locale",
			"trTR": "No Page for Locale",
			"heIL": "No Page for Locale",
			"lvLV": "No Page for Locale",
			"etEE": "No Page for Locale",
			"ltLT": "No Page for Locale"
		},
		"meta_description": "Introducing a new way to do function calling in Workers AI by running function code alongside your inference. Plus, a new @cloudflare/ai-utils package to make getting started as simple as possible. ",
		"metadata": {
			"title": "Embedded function calling in Workers AI: easier, smarter, faster",
			"description": "Introducing a new way to do function calling in Workers AI by running function code alongside your inference. Plus, a new @cloudflare/ai-utils package to make getting started as simple as possible. ",
			"imgPreview": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4tVuF3kgHm6aJj0RaSFG6T/5949d6172c8429fede2ab1e9d66c9001/embedded-function-calling-w4f2f7.png"
		},
		"primary_author": {},
		"published_at": "2024-06-27T18:00:09.000+01:00",
		"slug": "embedded-function-calling",
		"tags": [
			{
				"id": "6QktrXeEFcl4e2dZUTZVGl",
				"name": "Product News",
				"slug": "product-news"
			},
			{
				"id": "1Wf1Dpb2AFicG44jpRT29y",
				"name": "Workers AI",
				"slug": "workers-ai"
			},
			{
				"id": "3JAY3z7p7An94s6ScuSQPf",
				"name": "Developer Platform",
				"slug": "developer-platform"
			},
			{
				"id": "4HIPcb68qM0e26fIxyfzwQ",
				"name": "Developers",
				"slug": "developers"
			},
			{
				"id": "3txfsA7N73yBL9g3VPBLL0",
				"name": "Open Source",
				"slug": "open-source"
			},
			{
				"id": "6Foe3R8of95cWVnQwe5Toi",
				"name": "AI",
				"slug": "ai"
			},
			{
				"id": "3vILtHLIQU7d8BaWzXAPv4",
				"name": "Internship Experience",
				"slug": "internship-experience"
			}
		],
		"title": "Embedded function calling in Workers AI: easier, smarter, faster",
		"updated_at": "2024-10-09T23:28:32.524Z",
		"url": "https://blog.cloudflare.com/embedded-function-calling"
	},
	"translations": {
		"posts.by": "By",
		"footer.gdpr": "GDPR",
		"lang_blurb1": "This post is also available in {lang1}.",
		"lang_blurb2": "This post is also available in {lang1} and {lang2}.",
		"lang_blurb3": "This post is also available in {lang1}, {lang2} and {lang3}.",
		"footer.press": "Press",
		"header.title": "The Cloudflare Blog",
		"search.clear": "Clear",
		"search.filter": "Filter",
		"search.source": "Source",
		"footer.careers": "Careers",
		"footer.company": "Company",
		"footer.support": "Support",
		"footer.the_net": "theNet",
		"search.filters": "Filters",
		"footer.our_team": "Our team",
		"footer.webinars": "Webinars",
		"page.more_posts": "More posts",
		"posts.time_read": "{time} min read",
		"search.language": "Language",
		"footer.community": "Community",
		"footer.resources": "Resources",
		"footer.solutions": "Solutions",
		"footer.trademark": "Trademark",
		"header.subscribe": "Subscribe",
		"footer.compliance": "Compliance",
		"footer.free_plans": "Free plans",
		"footer.impact_ESG": "Impact/ESG",
		"posts.follow_on_X": "Follow on X",
		"footer.help_center": "Help center",
		"footer.network_map": "Network Map",
		"header.please_wait": "Please Wait",
		"page.related_posts": "Related posts",
		"search.result_stat": "Results <strong>{search_range}</strong> of <strong>{search_total}</strong> for <strong>{search_keyword}</strong>",
		"footer.case_studies": "Case Studies",
		"footer.connect_2024": "Connect 2024",
		"footer.terms_of_use": "Terms of Use",
		"footer.white_papers": "White Papers",
		"footer.cloudflare_tv": "Cloudflare TV",
		"footer.community_hub": "Community Hub",
		"footer.compare_plans": "Compare plans",
		"footer.contact_sales": "Contact Sales",
		"header.contact_sales": "Contact Sales",
		"header.email_address": "Email Address",
		"page.error.not_found": "Page not found",
		"footer.developer_docs": "Developer docs",
		"footer.privacy_policy": "Privacy Policy",
		"footer.request_a_demo": "Request a demo",
		"page.continue_reading": "Continue reading",
		"footer.analysts_report": "Analyst reports",
		"footer.for_enterprises": "For enterprises",
		"footer.getting_started": "Getting Started",
		"footer.learning_center": "Learning Center",
		"footer.project_galileo": "Project Galileo",
		"pagination.newer_posts": "Newer Posts",
		"pagination.older_posts": "Older Posts",
		"posts.social_buttons.x": "Discuss on X",
		"search.source_location": "Source/Location",
		"footer.about_cloudflare": "About Cloudflare",
		"footer.athenian_project": "Athenian Project",
		"footer.become_a_partner": "Become a partner",
		"footer.cloudflare_radar": "Cloudflare Radar",
		"footer.network_services": "Network services",
		"footer.trust_and_safety": "Trust & Safety",
		"header.get_started_free": "Get Started Free",
		"page.search.placeholder": "Search Cloudflare",
		"footer.cloudflare_status": "Cloudflare Status",
		"footer.cookie_preference": "Cookie Preferences",
		"header.valid_email_error": "Must be valid email.",
		"footer.connectivity_cloud": "Connectivity cloud",
		"footer.developer_services": "Developer services",
		"footer.investor_relations": "Investor relations",
		"page.not_found.error_code": "Error Code: 404",
		"footer.logos_and_press_kit": "Logos & press kit",
		"footer.application_services": "Application services",
		"footer.get_a_recommendation": "Get a recommendation",
		"posts.social_buttons.reddit": "Discuss on Reddit",
		"footer.sse_and_sase_services": "SSE and SASE services",
		"page.not_found.outdated_link": "You may have used an outdated link, or you may have typed the address incorrectly.",
		"footer.report_security_issues": "Report Security Issues",
		"page.error.error_message_page": "Sorry, we can't find the page you are looking for.",
		"header.subscribe_notifications": "Subscribe to receive notifications of new posts:",
		"footer.cloudflare_for_campaigns": "Cloudflare for Campaigns",
		"header.subscription_confimation": "Subscription confirmed. Thank you for subscribing!",
		"posts.social_buttons.hackernews": "Discuss on Hacker News",
		"footer.diversity_equity_inclusion": "Diversity, equity & inclusion",
		"footer.critical_infrastructure_defense_project": "Critical Infrastructure Defense Project"
	}
}