<div class="mb2 gray5">8 min read</div>
<div class="post-content lh-copy gray1">
	<!--kg-card-begin: markdown-->
	<p><em><small>This post is also available in <a href="https://blog.cloudflare.com/zh-cn/network-performance-update-developer-week-zh-cn">简体中文</a>, <a href="https://blog.cloudflare.com/ja-jp/network-performance-update-developer-week-ja-jp">日本語</a> and <a href="https://blog.cloudflare.com/es-es/network-performance-update-developer-week-es-es">Español</a>.</small></em></p>
	<!--kg-card-end: markdown-->
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/image6-9.png" class="kg-image" alt="Network Performance Update: Developer Week 2022" loading="lazy"></figure>
	<p>Cloudflare is building the fastest network in the world. But we don’t want you to just take our word for it. To demonstrate it, we are continuously testing ourselves versus everyone else to make sure we’re the fastest. Since it’s Developer Week, we wanted to provide an update on how our Workers products perform against the competition, as well as our overall network performance.</p>
	<p>Earlier this year, we compared ourselves to Fastly’s Compute@Edge and overall we were faster. This time, not only did we repeat the tests, but we also added AWS Lambda@Edge to help show how we stack up against more and more competitors. The summary: we offer the fastest developer platform on the market. Let’s talk about how we build our network to help make you faster, and then we’ll get into how that translates to our developer platform.</p>
	<h3 id="latest-update-on-network-performance">Latest update on network performance</h3>
	<p>We have two updates on data: a general network performance update, and then data on how Workers compares with Compute@Edge and Lambda@Edge.</p>
	<p>To quantify global network performance, we have to get enough data from around the world, across all manner of different networks, comparing ourselves with other providers. We used Real User Measurements (RUM) to fetch a 100kB file from different providers. Users around the world report the performance of different providers. The more users who report the data, the higher fidelity the signal is. The goal is to provide an accurate picture of where different providers are faster, and more importantly, where Cloudflare can improve. You can read more about the methodology in the original Speed Week blog post <a href="https://blog.cloudflare.com/benchmarking-edge-network-performance">here</a>.</p>
	<p>During Cloudflare One Week (June 2022), we shared that we were faster in more of the most reported networks than our competitors. Out of the top 3,000 networks in the world (by number of IPv4 addresses advertised), here’s a breakdown of the number of networks where each provider is number one in p95 TCP Connection Time, which represents the time it takes for a user on a given network to connect to the provider. This data is from Cloudflare One Week (June 2022):</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/image7-5.png" class="kg-image" alt="" loading="lazy"></figure>
	<p>Here is what the distribution looks like for the top 3,000 networks for Developer Week (November 2022):</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/image8-3.png" class="kg-image" alt="" loading="lazy"></figure>
	<p>In addition to being the fastest across popular networks, Cloudflare is also committed to being the fastest provider in every country.</p>
	<p>Using data on the top 3,000 networks from Cloudflare One Week (June 2022), here’s what the world map looks like (Cloudflare is in orange):</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/image3-42.png" class="kg-image" alt="" loading="lazy"></figure>
	<p>And here’s what the world looks like while looking at the top 3,000 networks for Developer Week (November 2022):</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/image4-29.png" class="kg-image" alt="" loading="lazy"></figure>
	<p>Cloudflare became #1 in more countries in Europe and Asia, specifically Russia, Ukraine, Kazakhstan, India, and China, further delivering on our mission to be the fastest network in the world. So let’s talk about how that network helps power the Supercloud to be the fastest developer platform around.</p>
	<h3 id="how-we-re-comparing-developer-platforms">How we’re comparing developer platforms</h3>
	<p>It’s been six months since we published our initial tests, but here’s a quick refresher. We make comparisons by measuring time to connect to the network, time spent completing requests, and overall time to respond. We call these numbers connect, wait, and response. We’ve chosen these numbers because they are critical components of a request that need to be as fast as possible in order for users to see a good experience. We can reduce the connect times by peering as close as possible to the users. We can reduce the wait times by optimizing code execution to be as fast as possible. If we optimize those two processes, we’ve optimized the response, which represents the end-to-end latency of a request.</p>
	<h3 id="test-methodology">Test methodology</h3>
	<p>To measure connect, wait, and response, we perform three tests against each provider: a simple no-op JavaScript function, a complex JavaScript function, and a complex Rust function. &nbsp;We don’t do a simple Rust function because we expect it to take almost no time at all, and we already have a baseline for end-to-end functionality in the no-op JavaScript function since many providers will often compile both down to WebAssembly.</p>
	<p>Here are the functions for each of them:</p>
	<p>JavaScript no-op:</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">async function getErrorResponse(event, message, status) {
  return new Response(message, {status: status, headers: {'Content-Type': 'text/plain'}});
}
</code></pre>
	<!--kg-card-end: markdown-->
	<p>JavaScript hard function:</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">function testHardBusyLoop() {
  let value = 0;
  let offset = Date.now();

  for (let n = 0; n &lt; 15000; n++) {
    value += Math.floor(Math.abs(Math.sin(offset + n)) * 10);
  }

  return value;
}
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Rust hard function:</p><!--kg-card-begin: markdown-->
	<pre><code class="language-rust">fn test_hard_busy_loop() -&gt; i32 {
  let mut value = 0;
  let offset = Date::now().as_millis();

  for n in 0..15000 {
    value += (((offset + n) as f64).sin().abs() * 10.0) as i32;
  }

  value
}
</code></pre>
	<!--kg-card-end: markdown-->
	<p>We’re trying to test how good each platform is at optimizing compute in addition to evaluating how close each platform is to end-users. However, for this test, we did not run a Rust test on Lambda@Edge because it did not natively support our Rust function without uploading a WASM binary that you compile yourself. Since Lambda@Edge does not have a true first-class developer platform and tooling to run Rust, we decided to exclude the Rust scenarios for Lambda@Edge. So when we compare numbers for Lambda@Edge, it will only be for the JavaScript simple and JavaScript hard tests.</p>
	<h3 id="measuring-workers-performance-from-real-users">Measuring Workers performance from real users</h3>
	<p>To collect data, we use two different methods: one from a third party service called Catchpoint, and a second from our own network performance benchmarking tests. First, we used Catchpoint to gather a set of data from synthetic probes. Catchpoint is an industry standard “synthetic” testing tool, and measurements collected from real users distributed around the world. Catchpoint is a monitoring platform that has around 2,000 total endpoints distributed around the world that can be configured to fetch specific resources and time for each test. Catchpoint is useful for network providers like us as it provides a consistent, repeatable way to measure end-to-end performance of a workload, and delivers a best-effort approximation for what a user sees.</p>
	<p>Catchpoint has backbone nodes that are embedded in ISPs around the world. That means that these nodes are plugged into ISP routers just like you are, and the traffic goes through the ISP network to each endpoint they are monitoring. These can approximate a real user, but they will never truly replicate a real user. For example, the bandwidth for these nodes is 100% dedicated for platform monitoring, as opposed to your home Internet connection, where your Internet experience will be a mixed bag of different use cases, some of which won’t talk to Workers applications at all.</p>
	<p>For this new test, we chose 300 backbone nodes that are embedded in last mile ISPs around the world. We filtered out nodes in cloud providers, or in metro areas with multiple transit options, trying to remove duplicate paths as much as possible.</p>
	<p>We cross-checked these tests with our own data set, which is collected from users connecting to free websites when they are served 1xxx error pages, just like how we collect data for global network performance. When a user sees this error page, that page that will execute these tests as a part of rendering and upload performance metrics on these calls to Cloudflare.</p>
	<p>We also changed our test methodology to use paid accounts for Fastly, Cloudflare, and AWS.</p>
	<h3 id="workers-vs-compute-edge-vs-lambda-edge">Workers vs Compute@Edge vs Lambda@Edge</h3>
	<p>This time, let’s start off with the response times to show how we’re doing end-to-end:</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/1-6.png" class="kg-image" alt="" loading="lazy"></figure><!--kg-card-begin: html-->
	<table>
		<thead>
			<tr>
				<th>Test</th>
				<th>95th percentile response (ms)</th>
			</tr>
		</thead>
		<tbody>
			<tr>
				<td>Cloudflare JavaScript no-op</td>
				<td>479</td>
			</tr>
			<tr>
				<td>Fastly JavaScript no-op</td>
				<td>634</td>
			</tr>
			<tr>
				<td>AWS JavaScript no-op</td>
				<td>1,400</td>
			</tr>
			<tr>
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td>Cloudflare JavaScript hard</td>
				<td>471</td>
			</tr>
			<tr>
				<td>Fastly JavaScript hard</td>
				<td>683</td>
			</tr>
			<tr>
				<td>AWS JavaScript hard</td>
				<td>1,411</td>
			</tr>
			<tr>
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td>Cloudflare Rust hard</td>
				<td>472</td>
			</tr>
			<tr>
				<td>Fastly Rust hard</td>
				<td>638</td>
			</tr>
		</tbody>
	</table><!--kg-card-end: html-->
	<p>We’re fastest in all cases. Now let’s look at connect times, which show us how fast users connect to the compute platform before doing any actual compute:</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/2-1.png" class="kg-image" alt="" loading="lazy"></figure><!--kg-card-begin: html-->
	<table>
		<thead>
			<tr>
				<th>Test</th>
				<th>95th percentile connect (ms)</th>
			</tr>
		</thead>
		<tbody>
			<tr>
				<td>Cloudflare JavaScript no-op</td>
				<td>82</td>
			</tr>
			<tr>
				<td>Fastly JavaScript no-op</td>
				<td>94</td>
			</tr>
			<tr>
				<td>AWS JavaScript no-op</td>
				<td>295</td>
			</tr>
			<tr>
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td>Cloudflare JavaScript hard</td>
				<td>82</td>
			</tr>
			<tr>
				<td>Fastly JavaScript hard</td>
				<td>94</td>
			</tr>
			<tr>
				<td>AWS JavaScript hard</td>
				<td>297</td>
			</tr>
			<tr>
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td>Cloudflare Rust hard</td>
				<td>79</td>
			</tr>
			<tr>
				<td>Fastly Rust hard</td>
				<td>94</td>
			</tr>
		</tbody>
	</table><!--kg-card-end: html-->
	<p>Note that we don’t expect these times to differ based on the code being run, but we extract them from the same set of tests, so we’ve broken them out here.</p>
	<p>But what about wait times? Remember, wait times represent time spent <em>computing</em> the request, so who has optimized their platform best? Again, it’s Cloudflare, although Fastly still has a slight edge on the hard Rust test (which we plan to beat by further optimization):</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/3-1.png" class="kg-image" alt="" loading="lazy"></figure><!--kg-card-begin: html-->
	<table>
		<thead>
			<tr>
				<th>Test</th>
				<th>95th percentile wait (ms)</th>
			</tr>
		</thead>
		<tbody>
			<tr>
				<td>Cloudflare JavaScript no-op</td>
				<td>110</td>
			</tr>
			<tr>
				<td>Fastly JavaScript no-op</td>
				<td>122</td>
			</tr>
			<tr>
				<td>AWS JavaScript no-op</td>
				<td>362</td>
			</tr>
			<tr>
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td>Cloudflare JavaScript hard</td>
				<td>115</td>
			</tr>
			<tr>
				<td>Fastly JavaScript hard</td>
				<td>178</td>
			</tr>
			<tr>
				<td>AWS JavaScript hard</td>
				<td>367</td>
			</tr>
			<tr>
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td>Cloudflare Rust hard</td>
				<td>125</td>
			</tr>
			<tr>
				<td>Fastly Rust hard</td>
				<td>122</td>
			</tr>
		</tbody>
	</table><!--kg-card-end: html-->
	<p>To verify these results, we compared the Catchpoint results to our own data set. Here is the p95 TTFB for the JavaScript and Rust hard loops for Fastly, AWS, and Cloudflare from our data:</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/11/4-1.png" class="kg-image" alt="" loading="lazy"></figure>
	<p>Cloudflare is faster on JavaScript and Rust calls. These numbers also back up the slight compute advantage for Fastly on Rust calls.</p>
	<p>The big takeaway from this is that in addition to Cloudflare being faster for the time spent processing requests in nearly every test, Cloudflare’s network and performance optimizations as a whole set us apart and make our Workers platform even faster for everything. And, of course, we plan to keep it that way.</p>
	<h3 id="your-application-but-faster">Your application, but faster</h3>
	<p>Latency is an important component of the user experience, and for developers, being able to ensure their users can do things as fast as possible is critical for the success of an application. Whether you’re building applications in Workers, D1, and R2, hosting your documentation in Pages, or even leveraging Workers as part of your SaaS platform, having your code run in the SuperCloud that is our global network will ensure that your users see the best experience they possibly can.</p>
	<p>Our network is hyper-optimized to make your code as fast as possible. By using Cloudflare’s network to run your applications, you can focus on making the best possible application possible and rest easy knowing that Cloudflare is providing you the best user experience possible. This is because Cloudflare’s developer platform is built on top of the <a href="https://blog.cloudflare.com/network-performance-update-cloudflare-one-week-june-2022">world’s fastest network</a>. So go out and build your dreams, and know that we’ll make your dreams as fast as they can possibly be.</p>
</div>