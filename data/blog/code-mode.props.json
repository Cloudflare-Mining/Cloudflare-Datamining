{
	"footerBlurb": "Cloudflare's connectivity cloud protects <a target='_blank' href='https://www.cloudflare.com/network-services/' rel='noreferrer'>entire corporate networks</a>, helps customers build <a target='_blank' href='https://workers.cloudflare.com/' rel='noreferrer'>Internet-scale applications efficiently</a>, accelerates any <a target='_blank' href='https://www.cloudflare.com/performance/accelerate-internet-applications/' rel='noreferrer'>website or Internet application</a>, <a target='_blank' href='https://www.cloudflare.com/ddos/' rel='noreferrer'>wards off DDoS attacks</a>, keeps <a target='_blank' href='https://www.cloudflare.com/application-security/' rel='noreferrer'>hackers at bay</a>, and can help you on <a target='_blank' href='https://www.cloudflare.com/products/zero-trust/' rel='noreferrer'>your journey to Zero Trust</a>.<br/><br/>Visit <a target='_blank' href='https://one.one.one.one/' rel='noreferrer'>1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.<br/><br/>To learn more about our mission to help build a better Internet, <a target='_blank' href='https://www.cloudflare.com/learning/what-is-cloudflare/' rel='noreferrer'>start here</a>. If you&apos;re looking for a new career direction, check out <a target='_blank' href='http://www.cloudflare.com/careers' rel='noreferrer'>our open positions</a>.",
	"initialReadingTime": "9",
	"locale": "en-us",
	"localesAvailable": [],
	"post": {
		"authors": [
			{
				"name": "Kenton Varda",
				"slug": "kenton-varda",
				"bio": null,
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1FFs4T2j1RyvxasKOkkdtP/e7bd05ce89c560a545853000a25da9bc/kenton-varda.jpg",
				"location": null,
				"website": null,
				"twitter": "@kentonvarda",
				"facebook": null,
				"publiclyIndex": true
			},
			{
				"name": "Sunil Pai",
				"slug": "sunil",
				"bio": "JavaScript and Les Pauls.  Worked at Cloudflare once, left and created PartyKit, came back wiser.",
				"profile_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2xnINigwFaBtTwOffppE85/596c43dfef6205e9c5b71c2caff4bea9/Sunil_Pai.png",
				"location": "London",
				"website": null,
				"twitter": "@threepointone",
				"facebook": null,
				"publiclyIndex": true
			}
		],
		"excerpt": "It turns out we've all been using MCP wrong. Most agents today use MCP by exposing the \"tools\" directly to the LLM.",
		"feature_image": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6XsnzCDczGdIKX6ddLVYLT/1cad4424f9b90001286b682c7caad683/image1.png",
		"featured": false,
		"html": "<p>It turns out we&#39;ve all been using MCP wrong.</p><p>Most agents today use MCP by directly exposing the &quot;tools&quot; to the <a href=\"https://www.cloudflare.com/learning/ai/what-is-large-language-model/\"><u>LLM</u></a>.</p><p>We tried something different: Convert the MCP tools into a TypeScript API, and then ask an LLM to write code that calls that API.</p><p>The results are striking:</p><ol><li><p>We found agents are able to handle many more tools, and more complex tools, when those tools are presented as a TypeScript API rather than directly. Perhaps this is because LLMs have an enormous amount of real-world TypeScript in their training set, but only a small set of contrived examples of tool calls.</p></li><li><p>The approach really shines when an agent needs to string together multiple calls. With the traditional approach, the output of each tool call must feed into the LLM&#39;s neural network, just to be copied over to the inputs of the next call, wasting time, energy, and tokens. When the LLM can write code, it can skip all that, and only read back the final results it needs.</p></li></ol><p>In short, LLMs are better at writing code to call MCP, than at calling MCP directly.</p>\n    <div class=\"flex anchor relative\">\n      <h2 id=\"whats-mcp\">What&#39;s MCP?</h2>\n      <a href=\"#whats-mcp\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>For those that aren&#39;t familiar: <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\"><u>Model Context Protocol</u></a> is a standard protocol for giving AI agents access to external tools, so that they can directly perform work, rather than just chat with you.</p><p>Seen another way, MCP is a uniform way to:</p><ul><li><p>expose an API for doing something,</p></li><li><p>along with documentation needed for an LLM to understand it,</p></li><li><p>with authorization handled out-of-band.</p></li></ul><p>MCP has been making waves throughout 2025 as it has suddenly greatly expanded the capabilities of AI agents.</p><p>The &quot;API&quot; exposed by an MCP server is expressed as a set of &quot;tools&quot;. Each tool is essentially a remote procedure call (RPC) function – it is called with some parameters and returns a response. Most modern LLMs have <a href=\"https://developers.cloudflare.com/workers-ai/features/function-calling/\"><u>the capability to use &quot;tools&quot; (sometimes called &quot;function calling&quot;)</u></a>, meaning they are trained to output text in a certain format when they want to invoke a tool. The program invoking the LLM sees this format and invokes the tool as specified, then feeds the results back into the LLM as input.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"anatomy-of-a-tool-call\">Anatomy of a tool call</h3>\n      <a href=\"#anatomy-of-a-tool-call\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Under the hood, an LLM generates a stream of &quot;tokens&quot; representing its output. A token might represent a word, a syllable, some sort of punctuation, or some other component of text.</p><p>A tool call, though, involves a token that does <i>not</i> have any textual equivalent. The LLM is trained (or, more often, fine-tuned) to understand a special token that it can output that means &quot;the following should be interpreted as a tool call,&quot; and another special token that means &quot;this is the end of the tool call.&quot; Between these two tokens, the LLM will typically write tokens corresponding to some sort of JSON message that describes the call.</p><p>For instance, imagine you have connected an agent to an MCP server that provides weather info, and you then ask the agent what the weather is like in Austin, TX. Under the hood, the LLM might generate output like the following. Note that here we&#39;ve used words in <code>&lt;|</code> and <code>|&gt;</code> to represent our special tokens, but in fact, these tokens do not represent text at all; this is just for illustration.</p><p>I will use the Weather MCP server to find out the weather in Austin, TX.</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">I will use the Weather MCP server to find out the weather in Austin, TX.\n\n&lt;|tool_call|&gt;\n{\n  &quot;name&quot;: &quot;get_current_weather&quot;,\n  &quot;arguments&quot;: {\n    &quot;location&quot;: &quot;Austin, TX, USA&quot;\n  }\n}\n&lt;|end_tool_call|&gt;</pre></code>\n            <p>Upon seeing these special tokens in the output, the LLM&#39;s harness will interpret the sequence as a tool call. After seeing the end token, the harness pauses execution of the LLM. It parses the JSON message and returns it as a separate component of the structured API result. The agent calling the LLM API sees the tool call, invokes the relevant MCP server, and then sends the results back to the LLM API. The LLM&#39;s harness will then use another set of special tokens to feed the result back into the LLM:</p>\n            <pre class=\"language-Rust\"><code class=\"language-Rust\">&lt;|tool_result|&gt;\n{\n  &quot;location&quot;: &quot;Austin, TX, USA&quot;,\n  &quot;temperature&quot;: 93,\n  &quot;unit&quot;: &quot;fahrenheit&quot;,\n  &quot;conditions&quot;: &quot;sunny&quot;\n}\n&lt;|end_tool_result|&gt;</pre></code>\n            <p>The LLM reads these tokens in exactly the same way it would read input from the user – except that the user cannot produce these special tokens, so the LLM knows it is the result of the tool call. The LLM then continues generating output like normal.</p><p>Different LLMs may use different formats for tool calling, but this is the basic idea.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"whats-wrong-with-this\">What&#39;s wrong with this?</h3>\n      <a href=\"#whats-wrong-with-this\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>The special tokens used in tool calls are things LLMs have never seen in the wild. They must be specially trained to use tools, based on synthetic training data. They aren&#39;t always that good at it. If you present an LLM with too many tools, or overly complex tools, it may struggle to choose the right one or to use it correctly. As a result, MCP server designers are encouraged to present greatly simplified APIs as compared to the more traditional API they might expose to developers.</p><p>Meanwhile, LLMs are getting really good at writing code. In fact, LLMs asked to write code against the full, complex APIs normally exposed to developers don&#39;t seem to have too much trouble with it. Why, then, do MCP interfaces have to &quot;dumb it down&quot;? Writing code and calling tools are almost the same thing, but it seems like LLMs can do one much better than the other?</p><p>The answer is simple: LLMs have seen a lot of code. They have not seen a lot of &quot;tool calls&quot;. In fact, the tool calls they have seen are probably limited to a contrived training set constructed by the LLM&#39;s own developers, in order to try to train it. Whereas they have seen real-world code from millions of open source projects.</p><p><b><i>Making an LLM perform tasks with tool calling is like putting Shakespeare through a month-long class in Mandarin and then asking him to write a play in it. It&#39;s just not going to be his best work.</i></b></p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"but-mcp-is-still-useful-because-it-is-uniform\">But MCP is still useful, because it is uniform</h3>\n      <a href=\"#but-mcp-is-still-useful-because-it-is-uniform\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>MCP is designed for tool-calling, but it doesn&#39;t actually <i>have to</i> be used that way.</p><p>The &quot;tools&quot; that an MCP server exposes are really just an RPC interface with attached documentation. We don&#39;t really <i>have to</i> present them as tools. We can take the tools, and turn them into a programming language API instead.</p><p>But why would we do that, when the programming language APIs already exist independently? Almost every MCP server is just a wrapper around an existing traditional API – why not expose those APIs?</p><p>Well, it turns out MCP does something else that&#39;s really useful: <b>It provides a uniform way to connect to and learn about an API.</b></p><p>An AI agent can use an MCP server even if the agent&#39;s developers never heard of the particular MCP server, and the MCP server&#39;s developers never heard of the particular agent. This has rarely been true of traditional APIs in the past. Usually, the client developer always knows exactly what API they are coding for. As a result, every API is able to do things like basic connectivity, authorization, and documentation a little bit differently.</p><p>This uniformity is useful even when the AI agent is writing code. We&#39;d like the AI agent to run in a sandbox such that it can only access the tools we give it. MCP makes it possible for the agentic framework to implement this, by handling connectivity and authorization in a standard way, independent of the AI code. We also don&#39;t want the AI to have to search the Internet for documentation; MCP provides it directly in the protocol.</p>\n    <div class=\"flex anchor relative\">\n      <h2 id=\"ok-how-does-it-work\">OK, how does it work?</h2>\n      <a href=\"#ok-how-does-it-work\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>We have already extended the <a href=\"https://developers.cloudflare.com/agents/\"><u>Cloudflare Agents SDK</u></a> to support this new model!</p><p>For example, say you have an app built with ai-sdk that looks like this:</p>\n            <pre class=\"language-Typescript\"><code class=\"language-Typescript\">const stream = streamText({\n  model: openai(&quot;gpt-5&quot;),\n  system: &quot;You are a helpful assistant&quot;,\n  messages: [\n    { role: &quot;user&quot;, content: &quot;Write a function that adds two numbers&quot; }\n  ],\n  tools: {\n    // tool definitions \n  }\n})</pre></code>\n            <p>You can wrap the tools and prompt with the codemode helper, and use them in your app: </p>\n            <pre class=\"language-Typescript\"><code class=\"language-Typescript\">import { codemode } from &quot;agents/codemode/ai&quot;;\n\nconst {system, tools} = codemode({\n  system: &quot;You are a helpful assistant&quot;,\n  tools: {\n    // tool definitions \n  },\n  // ...config\n})\n\nconst stream = streamText({\n  model: openai(&quot;gpt-5&quot;),\n  system,\n  tools,\n  messages: [\n    { role: &quot;user&quot;, content: &quot;Write a function that adds two numbers&quot; }\n  ]\n})</pre></code>\n            <p>With this change, your app will now start generating and running code that itself will make calls to the tools you defined, MCP servers included. We will introduce variants for other libraries in the very near future. <a href=\"https://github.com/cloudflare/agents/blob/main/docs/codemode.md\"><u>Read the docs</u></a> for more details and examples. </p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"converting-mcp-to-typescript\">Converting MCP to TypeScript</h3>\n      <a href=\"#converting-mcp-to-typescript\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>When you connect to an MCP server in &quot;code mode&quot;, the Agents SDK will fetch the MCP server&#39;s schema, and then convert it into a TypeScript API, complete with doc comments based on the schema.</p><p>For example, connecting to the MCP server at <a href=\"https://gitmcp.io/cloudflare/agents\"><u>https://gitmcp.io/cloudflare/agents</u></a>, will generate a TypeScript definition like this:</p>\n            <pre class=\"language-Typescript\"><code class=\"language-Typescript\">interface FetchAgentsDocumentationInput {\n  [k: string]: unknown;\n}\ninterface FetchAgentsDocumentationOutput {\n  [key: string]: any;\n}\n\ninterface SearchAgentsDocumentationInput {\n  /**\n   * The search query to find relevant documentation\n   */\n  query: string;\n}\ninterface SearchAgentsDocumentationOutput {\n  [key: string]: any;\n}\n\ninterface SearchAgentsCodeInput {\n  /**\n   * The search query to find relevant code files\n   */\n  query: string;\n  /**\n   * Page number to retrieve (starting from 1). Each page contains 30\n   * results.\n   */\n  page?: number;\n}\ninterface SearchAgentsCodeOutput {\n  [key: string]: any;\n}\n\ninterface FetchGenericUrlContentInput {\n  /**\n   * The URL of the document or page to fetch\n   */\n  url: string;\n}\ninterface FetchGenericUrlContentOutput {\n  [key: string]: any;\n}\n\ndeclare const codemode: {\n  /**\n   * Fetch entire documentation file from GitHub repository:\n   * cloudflare/agents. Useful for general questions. Always call\n   * this tool first if asked about cloudflare/agents.\n   */\n  fetch_agents_documentation: (\n    input: FetchAgentsDocumentationInput\n  ) =&gt; Promise&lt;FetchAgentsDocumentationOutput&gt;;\n\n  /**\n   * Semantically search within the fetched documentation from\n   * GitHub repository: cloudflare/agents. Useful for specific queries.\n   */\n  search_agents_documentation: (\n    input: SearchAgentsDocumentationInput\n  ) =&gt; Promise&lt;SearchAgentsDocumentationOutput&gt;;\n\n  /**\n   * Search for code within the GitHub repository: &quot;cloudflare/agents&quot;\n   * using the GitHub Search API (exact match). Returns matching files\n   * for you to query further if relevant.\n   */\n  search_agents_code: (\n    input: SearchAgentsCodeInput\n  ) =&gt; Promise&lt;SearchAgentsCodeOutput&gt;;\n\n  /**\n   * Generic tool to fetch content from any absolute URL, respecting\n   * robots.txt rules. Use this to retrieve referenced urls (absolute\n   * urls) that were mentioned in previously fetched documentation.\n   */\n  fetch_generic_url_content: (\n    input: FetchGenericUrlContentInput\n  ) =&gt; Promise&lt;FetchGenericUrlContentOutput&gt;;\n};</pre></code>\n            <p>This TypeScript is then loaded into the agent&#39;s context. Currently, the entire API is loaded, but future improvements could allow an agent to search and browse the API more dynamically – much like an agentic coding assistant would.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"running-code-in-a-sandbox\">Running code in a sandbox</h3>\n      <a href=\"#running-code-in-a-sandbox\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Instead of being presented with all the tools of all the connected MCP servers, our agent is presented with just one tool, which simply executes some TypeScript code.</p><p>The code is then executed in a secure sandbox. The sandbox is totally isolated from the Internet. Its only access to the outside world is through the TypeScript APIs representing its connected MCP servers.</p><p>These APIs are backed by RPC invocation which calls back to the agent loop. There, the Agents SDK dispatches the call to the appropriate MCP server.</p><p>The sandboxed code returns results to the agent in the obvious way: by invoking <code>console.log()</code>. When the script finishes, all the output logs are passed back to the agent.</p>\n          <figure class=\"kg-card kg-image-card\">\n          <Image src=\"https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6DRERHP138FSj3GG0QYj3M/99e8c09b352560b7d4547ca299482c27/image2.png\" alt=\"\" class=\"kg-image\" width=\"1999\" height=\"1967\" loading=\"lazy\"/>\n          </figure>\n    <div class=\"flex anchor relative\">\n      <h2 id=\"dynamic-worker-loading-no-containers-here\">Dynamic Worker loading: no containers here</h2>\n      <a href=\"#dynamic-worker-loading-no-containers-here\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>This new approach requires access to a secure sandbox where arbitrary code can run. So where do we find one? Do we have to run containers? Is that expensive?</p><p>No. There are no containers. We have something much better: isolates.</p><p>The Cloudflare Workers platform has always been based on V8 isolates, that is, isolated JavaScript runtimes powered by the <a href=\"https://v8.dev/\"><u>V8 JavaScript engine</u></a>.</p><p><b>Isolates are far more lightweight than containers.</b> An isolate can start in a handful of milliseconds using only a few megabytes of memory.</p><p>Isolates are so fast that we can just create a new one for every piece of code the agent runs. There&#39;s no need to reuse them. There&#39;s no need to prewarm them. Just create it, on demand, run the code, and throw it away. It all happens so fast that the overhead is negligible; it&#39;s almost as if you were just eval()ing the code directly. But with security.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"the-worker-loader-api\">The Worker Loader API</h3>\n      <a href=\"#the-worker-loader-api\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Until now, though, there was no way for a Worker to directly load an isolate containing arbitrary code. All Worker code instead had to be uploaded via the Cloudflare API, which would then deploy it globally, so that it could run anywhere. That&#39;s not what we want for Agents! We want the code to just run right where the agent is.</p><p>To that end, we&#39;ve added a new API to the Workers platform: the <a href=\"https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader/\"><u>Worker Loader API</u></a>. With it, you can load Worker code on-demand. Here&#39;s what it looks like:</p>\n            <pre class=\"language-JavaScript\"><code class=\"language-JavaScript\">// Gets the Worker with the given ID, creating it if no such Worker exists yet.\nlet worker = env.LOADER.get(id, async () =&gt; {\n  // If the Worker does not already exist, this callback is invoked to fetch\n  // its code.\n\n  return {\n    compatibilityDate: &quot;2025-06-01&quot;,\n\n    // Specify the worker&#039;s code (module files).\n    mainModule: &quot;foo.js&quot;,\n    modules: {\n      &quot;foo.js&quot;:\n        &quot;export default {\\n&quot; +\n        &quot;  fetch(req, env, ctx) { return new Response(&#039;Hello&#039;); }\\n&quot; +\n        &quot;}\\n&quot;,\n    },\n\n    // Specify the dynamic Worker&#039;s environment (`env`).\n    env: {\n      // It can contain basic serializable data types...\n      SOME_NUMBER: 123,\n\n      // ... and bindings back to the parent worker&#039;s exported RPC\n      // interfaces, using the new `ctx.exports` loopback bindings API.\n      SOME_RPC_BINDING: ctx.exports.MyBindingImpl({props})\n    },\n\n    // Redirect the Worker&#039;s `fetch()` and `connect()` to proxy through\n    // the parent worker, to monitor or filter all Internet access. You\n    // can also block Internet access completely by passing `null`.\n    globalOutbound: ctx.exports.OutboundProxy({props}),\n  };\n});\n\n// Now you can get the Worker&#039;s entrypoint and send requests to it.\nlet defaultEntrypoint = worker.getEntrypoint();\nawait defaultEntrypoint.fetch(&quot;http://example.com&quot;);\n\n// You can get non-default entrypoints as well, and specify the\n// `ctx.props` value to be delivered to the entrypoint.\nlet someEntrypoint = worker.getEntrypoint(&quot;SomeEntrypointClass&quot;, {\n  props: {someProp: 123}\n});</pre></code>\n            <p>You can start playing with this API right now when running <code>workerd</code> locally with Wrangler (<a href=\"https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader/\"><u>check out the docs</u></a>), and you can <a href=\"https://forms.gle/MoeDxE9wNiqdf8ri9\"><u>sign up for beta access</u></a> to use it in production.</p>\n    <div class=\"flex anchor relative\">\n      <h2 id=\"workers-are-better-sandboxes\">Workers are better sandboxes</h2>\n      <a href=\"#workers-are-better-sandboxes\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>The design of Workers makes it unusually good at sandboxing, especially for this use case, for a few reasons:</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"faster-cheaper-disposable-sandboxes\">Faster, cheaper, disposable sandboxes</h3>\n      <a href=\"#faster-cheaper-disposable-sandboxes\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p><a href=\"https://developers.cloudflare.com/workers/reference/how-workers-works/\"><u>The Workers platform uses isolates instead of containers.</u></a> Isolates are much lighter-weight and faster to start up. It takes mere milliseconds to start a fresh isolate, and it&#39;s so cheap we can just create a new one for every single code snippet the agent generates. There&#39;s no need to worry about pooling isolates for reuse, prewarming, etc.</p><p>We have not yet finalized pricing for the Worker Loader API, but because it is based on isolates, we will be able to offer it at a significantly lower cost than container-based solutions.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"isolated-by-default-but-connected-with-bindings\">Isolated by default, but connected with bindings</h3>\n      <a href=\"#isolated-by-default-but-connected-with-bindings\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>Workers are just better at handling isolation.</p><p>In Code Mode, we prohibit the sandboxed worker from talking to the Internet. The global <code>fetch()</code> and <code>connect()</code> functions throw errors.</p><p>But on most platforms, this would be a problem. On most platforms, the way you get access to private resources is, you <i>start</i> with general network access. Then, using that network access, you send requests to specific services, passing them some sort of API key to authorize private access.</p><p>But Workers has always had a better answer. In Workers, the &quot;environment&quot; (<code>env</code> object) doesn&#39;t just contain strings, <a href=\"https://blog.cloudflare.com/workers-environment-live-object-bindings/\"><u>it contains live objects</u></a>, also known as &quot;bindings&quot;. These objects can provide direct access to private resources without involving generic network requests.</p><p>In Code Mode, we give the sandbox access to bindings representing the MCP servers it is connected to. Thus, the agent can specifically access those MCP servers <i>without</i> having network access in general.</p><p>Limiting access via bindings is much cleaner than doing it via, say, network-level filtering or HTTP proxies. Filtering is hard on both the LLM and the supervisor, because the boundaries are often unclear: the supervisor may have a hard time identifying exactly what traffic is legitimately necessary to talk to an API. Meanwhile, the LLM may have difficulty guessing what kinds of requests will be blocked. With the bindings approach, it&#39;s well-defined: the binding provides a JavaScript interface, and that interface is allowed to be used. It&#39;s just better this way.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"no-api-keys-to-leak\">No API keys to leak</h3>\n      <a href=\"#no-api-keys-to-leak\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>An additional benefit of bindings is that they hide API keys. The binding itself provides an already-authorized client interface to the MCP server. All calls made on it go to the agent supervisor first, which holds the access tokens and adds them into requests sent on to MCP.</p><p>This means that the AI cannot possibly write code that leaks any keys, solving a common security problem seen in AI-authored code today.</p>\n    <div class=\"flex anchor relative\">\n      <h2 id=\"try-it-now\">Try it now!</h2>\n      <a href=\"#try-it-now\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    \n    <div class=\"flex anchor relative\">\n      <h3 id=\"sign-up-for-the-production-beta\">Sign up for the production beta</h3>\n      <a href=\"#sign-up-for-the-production-beta\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>The Dynamic Worker Loader API is in closed beta. To use it in production, <a href=\"https://forms.gle/MoeDxE9wNiqdf8ri9\"><u>sign up today</u></a>.</p>\n    <div class=\"flex anchor relative\">\n      <h3 id=\"or-try-it-locally\">Or try it locally</h3>\n      <a href=\"#or-try-it-locally\" aria-hidden=\"true\" class=\"relative sm:absolute sm:-left-5\">\n        <svg width=\"16\" height=\"16\" viewBox=\"0 0 24 24\"><path fill=\"currentcolor\" d=\"m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\"></path></svg>\n      </a>\n    </div>\n    <p>If you just want to play around, though, Dynamic Worker Loading is fully available today when developing locally with Wrangler and <code>workerd</code> – check out the docs for <a href=\"https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader/\"><u>Dynamic Worker Loading</u></a> and <a href=\"https://github.com/cloudflare/agents/blob/main/docs/codemode.md\"><u>code mode in the Agents SDK</u></a> to get started.</p>",
		"id": "61nEdL3TSdS4diA4x21O5e",
		"localeList": {
			"name": "blog-english-only",
			"enUS": "English for Locale",
			"zhCN": "No Page for Locale",
			"zhHansCN": "No Page for Locale",
			"zhTW": "No Page for Locale",
			"frFR": "No Page for Locale",
			"deDE": "No Page for Locale",
			"itIT": "No Page for Locale",
			"jaJP": "No Page for Locale",
			"koKR": "No Page for Locale",
			"ptBR": "No Page for Locale",
			"esLA": "No Page for Locale",
			"esES": "No Page for Locale",
			"enAU": "No Page for Locale",
			"enCA": "No Page for Locale",
			"enIN": "No Page for Locale",
			"enGB": "No Page for Locale",
			"idID": "No Page for Locale",
			"ruRU": "No Page for Locale",
			"svSE": "No Page for Locale",
			"viVN": "No Page for Locale",
			"plPL": "No Page for Locale",
			"arAR": "No Page for Locale",
			"nlNL": "No Page for Locale",
			"thTH": "No Page for Locale",
			"trTR": "No Page for Locale",
			"heIL": "No Page for Locale",
			"lvLV": "No Page for Locale",
			"etEE": "No Page for Locale",
			"ltLT": "No Page for Locale"
		},
		"meta_description": "It turns out we've all been using MCP wrong. Most agents today use MCP by exposing the \"tools\" directly to the LLM. We tried something different: Convert the MCP tools into a TypeScript API, and then ask an LLM to write code that calls that API. The results are striking.",
		"metadata": {
			"title": "Code Mode: the better way to use MCP",
			"description": "It turns out we've all been using MCP wrong. Most agents today use MCP by exposing the \"tools\" directly to the LLM. We tried something different: Convert the MCP tools into a TypeScript API, and then ask an LLM to write code that calls that API. The results are striking.",
			"imgPreview": "https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5er6sAYufbQGtVF6vEgEJP/0f6490172e34e775da6beb346832c44c/Code_Mode-_the_better_way_to_use_MCP-OG.png"
		},
		"primary_author": {},
		"publicly_index": true,
		"published_at": "2025-09-26T14:00+01:00",
		"slug": "code-mode",
		"tags": [
			{
				"id": "6Foe3R8of95cWVnQwe5Toi",
				"name": "AI",
				"slug": "ai"
			},
			{
				"id": "1Cv5JjXzKWKEA10JdYbXu1",
				"name": "Birthday Week",
				"slug": "birthday-week"
			},
			{
				"id": "6hbkItfupogJP3aRDAq6v8",
				"name": "Cloudflare Workers",
				"slug": "workers"
			},
			{
				"id": "22RkiaggH3NV4u6qyMmC42",
				"name": "Agents",
				"slug": "agents"
			},
			{
				"id": "6Lfy7VaNvl5G8gOYMKFiux",
				"name": "MCP",
				"slug": "mcp"
			}
		],
		"title": "Code Mode: the better way to use MCP",
		"updated_at": "2025-09-26T15:09:24.604Z",
		"url": "https://blog.cloudflare.com/code-mode"
	},
	"translations": {
		"posts.by": "By",
		"footer.gdpr": "GDPR",
		"lang_blurb1": "This post is also available in {lang1}.",
		"lang_blurb2": "This post is also available in {lang1} and {lang2}.",
		"lang_blurb3": "This post is also available in {lang1}, {lang2} and {lang3}.",
		"footer.press": "Press",
		"header.title": "The Cloudflare Blog",
		"search.clear": "Clear",
		"search.filter": "Filter",
		"search.source": "Source",
		"footer.careers": "Careers",
		"footer.company": "Company",
		"footer.support": "Support",
		"footer.the_net": "theNet",
		"search.filters": "Filters",
		"footer.our_team": "Our team",
		"footer.webinars": "Webinars",
		"page.more_posts": "More posts",
		"posts.time_read": "{time} min read",
		"search.language": "Language",
		"footer.community": "Community",
		"footer.resources": "Resources",
		"footer.solutions": "Solutions",
		"footer.trademark": "Trademark",
		"header.subscribe": "Subscribe",
		"footer.compliance": "Compliance",
		"footer.free_plans": "Free plans",
		"footer.impact_ESG": "Impact/ESG",
		"posts.follow_on_X": "Follow on X",
		"footer.help_center": "Help center",
		"footer.network_map": "Network Map",
		"header.please_wait": "Please Wait",
		"page.related_posts": "Related posts",
		"search.result_stat": "Results <strong>{search_range}</strong> of <strong>{search_total}</strong> for <strong>{search_keyword}</strong>",
		"footer.case_studies": "Case Studies",
		"footer.connect_2024": "Connect 2024",
		"footer.terms_of_use": "Terms of Use",
		"footer.white_papers": "White Papers",
		"footer.cloudflare_tv": "Cloudflare TV",
		"footer.community_hub": "Community Hub",
		"footer.compare_plans": "Compare plans",
		"footer.contact_sales": "Contact Sales",
		"header.contact_sales": "Contact Sales",
		"header.email_address": "Email Address",
		"page.error.not_found": "Page not found",
		"footer.developer_docs": "Developer docs",
		"footer.privacy_policy": "Privacy Policy",
		"footer.request_a_demo": "Request a demo",
		"page.continue_reading": "Continue reading",
		"footer.analysts_report": "Analyst reports",
		"footer.for_enterprises": "For enterprises",
		"footer.getting_started": "Getting Started",
		"footer.learning_center": "Learning Center",
		"footer.project_galileo": "Project Galileo",
		"pagination.newer_posts": "Newer Posts",
		"pagination.older_posts": "Older Posts",
		"posts.social_buttons.x": "Discuss on X",
		"search.icon_aria_label": "Search",
		"search.source_location": "Source/Location",
		"footer.about_cloudflare": "About Cloudflare",
		"footer.athenian_project": "Athenian Project",
		"footer.become_a_partner": "Become a partner",
		"footer.cloudflare_radar": "Cloudflare Radar",
		"footer.network_services": "Network services",
		"footer.trust_and_safety": "Trust & Safety",
		"header.get_started_free": "Get Started Free",
		"page.search.placeholder": "Search Cloudflare",
		"footer.cloudflare_status": "Cloudflare Status",
		"footer.cookie_preference": "Cookie Preferences",
		"header.valid_email_error": "Must be valid email.",
		"search.result_stat_empty": "Results <strong>{search_range}</strong> of <strong>{search_total}</strong>",
		"footer.connectivity_cloud": "Connectivity cloud",
		"footer.developer_services": "Developer services",
		"footer.investor_relations": "Investor relations",
		"page.not_found.error_code": "Error Code: 404",
		"search.autocomplete_title": "Insert a query. Press enter to send",
		"footer.logos_and_press_kit": "Logos & press kit",
		"footer.application_services": "Application services",
		"footer.get_a_recommendation": "Get a recommendation",
		"posts.social_buttons.reddit": "Discuss on Reddit",
		"footer.sse_and_sase_services": "SSE and SASE services",
		"page.not_found.outdated_link": "You may have used an outdated link, or you may have typed the address incorrectly.",
		"footer.report_security_issues": "Report Security Issues",
		"page.error.error_message_page": "Sorry, we can't find the page you are looking for.",
		"header.subscribe_notifications": "Subscribe to receive notifications of new posts:",
		"footer.cloudflare_for_campaigns": "Cloudflare for Campaigns",
		"header.subscription_confimation": "Subscription confirmed. Thank you for subscribing!",
		"posts.social_buttons.hackernews": "Discuss on Hacker News",
		"footer.diversity_equity_inclusion": "Diversity, equity & inclusion",
		"footer.critical_infrastructure_defense_project": "Critical Infrastructure Defense Project"
	}
}