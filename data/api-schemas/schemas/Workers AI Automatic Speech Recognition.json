{
	"GET /accounts/{account_id}/ai/run/@cf/deepgram/flux": {
		"operationId": "workers-ai-post-websocket-run-cf-deepgram-flux",
		"parameters": [
			{
				"in": "path",
				"name": "account_id",
				"required": true,
				"schema": {
					"example": "023e105f4ecef8ad9ca31a8372d0c353",
					"type": "string",
					"x-auditable": true
				}
			}
		],
		"responses": {
			"101": {
				"description": "Returns a websocket connection"
			},
			"400": {
				"content": {
					"application/json": {
						"schema": {
							"properties": {
								"errors": {
									"items": {
										"properties": {
											"message": {
												"type": "string"
											}
										},
										"required": [
											"message"
										],
										"type": "object"
									},
									"type": "array"
								},
								"result": {
									"type": "object"
								},
								"success": {
									"example": false,
									"type": "boolean"
								}
							},
							"required": [
								"result",
								"success",
								"errors"
							],
							"type": "object"
						}
					}
				},
				"description": "Bad Request"
			}
		},
		"security": [
			{
				"api_token": []
			},
			{
				"api_email": [],
				"api_key": []
			}
		],
		"summary": "Open Websocket connection with @cf/deepgram/flux model.",
		"tags": [
			"Workers AI Automatic Speech Recognition"
		],
		"x-cfPermissionsRequired": {
			"enum": [
				"com.cloudflare.api.account.ai"
			]
		},
		"x-cfPlanAvailability": {
			"business": true,
			"enterprise": true,
			"free": true,
			"pro": true
		}
	},
	"GET /accounts/{account_id}/ai/run/@cf/deepgram/nova-3": {
		"operationId": "workers-ai-post-websocket-run-cf-deepgram-nova-3",
		"parameters": [
			{
				"in": "path",
				"name": "account_id",
				"required": true,
				"schema": {
					"example": "023e105f4ecef8ad9ca31a8372d0c353",
					"type": "string",
					"x-auditable": true
				}
			}
		],
		"responses": {
			"101": {
				"description": "Returns a websocket connection"
			},
			"400": {
				"content": {
					"application/json": {
						"schema": {
							"properties": {
								"errors": {
									"items": {
										"properties": {
											"message": {
												"type": "string"
											}
										},
										"required": [
											"message"
										],
										"type": "object"
									},
									"type": "array"
								},
								"result": {
									"type": "object"
								},
								"success": {
									"example": false,
									"type": "boolean"
								}
							},
							"required": [
								"result",
								"success",
								"errors"
							],
							"type": "object"
						}
					}
				},
				"description": "Bad Request"
			}
		},
		"security": [
			{
				"api_token": []
			},
			{
				"api_email": [],
				"api_key": []
			}
		],
		"summary": "Open Websocket connection with @cf/deepgram/nova-3 model.",
		"tags": [
			"Workers AI Automatic Speech Recognition"
		],
		"x-cfPermissionsRequired": {
			"enum": [
				"com.cloudflare.api.account.ai"
			]
		},
		"x-cfPlanAvailability": {
			"business": true,
			"enterprise": true,
			"free": true,
			"pro": true
		}
	},
	"GET /accounts/{account_id}/ai/run/@cf/deepgram/nova-3-internal": {
		"operationId": "workers-ai-post-websocket-run-cf-deepgram-nova-3-internal",
		"parameters": [
			{
				"in": "path",
				"name": "account_id",
				"required": true,
				"schema": {
					"example": "023e105f4ecef8ad9ca31a8372d0c353",
					"type": "string",
					"x-auditable": true
				}
			}
		],
		"responses": {
			"101": {
				"description": "Returns a websocket connection"
			},
			"400": {
				"content": {
					"application/json": {
						"schema": {
							"properties": {
								"errors": {
									"items": {
										"properties": {
											"message": {
												"type": "string"
											}
										},
										"required": [
											"message"
										],
										"type": "object"
									},
									"type": "array"
								},
								"result": {
									"type": "object"
								},
								"success": {
									"example": false,
									"type": "boolean"
								}
							},
							"required": [
								"result",
								"success",
								"errors"
							],
							"type": "object"
						}
					}
				},
				"description": "Bad Request"
			}
		},
		"security": [
			{
				"api_token": []
			},
			{
				"api_email": [],
				"api_key": []
			}
		],
		"summary": "Open Websocket connection with @cf/deepgram/nova-3-internal model.",
		"tags": [
			"Workers AI Automatic Speech Recognition"
		],
		"x-cfPermissionsRequired": {
			"enum": [
				"com.cloudflare.api.account.ai"
			]
		},
		"x-cfPlanAvailability": {
			"business": true,
			"enterprise": true,
			"free": true,
			"pro": true
		}
	},
	"POST /accounts/{account_id}/ai/run/@cf/deepgram/flux": {
		"operationId": "workers-ai-post-run-cf-deepgram-flux",
		"parameters": [
			{
				"in": "path",
				"name": "account_id",
				"required": true,
				"schema": {
					"example": "023e105f4ecef8ad9ca31a8372d0c353",
					"type": "string",
					"x-auditable": true
				}
			},
			{
				"in": "query",
				"name": "queueRequest",
				"schema": {
					"example": "true",
					"type": "string",
					"x-auditable": true
				}
			}
		],
		"requestBody": {
			"content": {
				"application/json": {
					"schema": {
						"properties": {
							"eager_eot_threshold": {
								"description": "End-of-turn confidence required to fire an eager end-of-turn event. When set, enables EagerEndOfTurn and TurnResumed events. Valid Values 0.3 - 0.9.",
								"type": "string"
							},
							"encoding": {
								"description": "Encoding of the audio stream. Currently only supports raw signed little-endian 16-bit PCM.",
								"enum": [
									"linear16"
								],
								"type": "string"
							},
							"eot_threshold": {
								"default": "0.7",
								"description": "End-of-turn confidence required to finish a turn. Valid Values 0.5 - 0.9.",
								"type": "string"
							},
							"eot_timeout_ms": {
								"default": "5000",
								"description": "A turn will be finished when this much time has passed after speech, regardless of EOT confidence.",
								"pattern": "^[0-9]+$",
								"type": "string"
							},
							"keyterm": {
								"description": "Keyterm prompting can improve recognition of specialized terminology. Pass multiple keyterm query parameters to boost multiple keyterms.",
								"type": "string"
							},
							"mip_opt_out": {
								"default": "false",
								"description": "Opts out requests from the Deepgram Model Improvement Program. Refer to Deepgram Docs for pricing impacts before setting this to true. https://dpgr.am/deepgram-mip",
								"enum": [
									"true",
									"false"
								],
								"type": "string"
							},
							"sample_rate": {
								"description": "Sample rate of the audio stream in Hz.",
								"pattern": "^[0-9]+$",
								"type": "string"
							},
							"tag": {
								"description": "Label your requests for the purpose of identification during usage reporting",
								"type": "string"
							}
						},
						"required": [
							"sample_rate",
							"encoding"
						],
						"type": "object"
					}
				}
			}
		},
		"responses": {
			"200": {
				"content": {
					"application/json": {
						"schema": {
							"type": "object"
						}
					}
				},
				"description": "Object with user data."
			},
			"400": {
				"content": {
					"application/json": {
						"schema": {
							"properties": {
								"errors": {
									"items": {
										"properties": {
											"code": {
												"type": "string"
											},
											"message": {
												"type": "string"
											}
										},
										"required": [
											"code",
											"message"
										],
										"type": "object"
									},
									"type": "array"
								},
								"result": {
									"type": "object"
								},
								"success": {
									"type": "boolean"
								}
							},
							"required": [
								"errors",
								"success",
								"result"
							],
							"type": "object"
						}
					}
				},
				"description": "Bad request"
			}
		},
		"security": [
			{
				"api_token": []
			},
			{
				"api_email": [],
				"api_key": []
			}
		],
		"summary": "Execute @cf/deepgram/flux model.",
		"tags": [
			"Workers AI Automatic Speech Recognition"
		],
		"x-api-token-group": [
			"Workers AI Write",
			"Workers AI Read"
		],
		"x-cfPermissionsRequired": {
			"enum": [
				"com.cloudflare.api.account.ai"
			]
		},
		"x-cfPlanAvailability": {
			"business": true,
			"enterprise": true,
			"free": true,
			"pro": true
		}
	},
	"POST /accounts/{account_id}/ai/run/@cf/deepgram/nova-3": {
		"operationId": "workers-ai-post-run-cf-deepgram-nova-3",
		"parameters": [
			{
				"in": "path",
				"name": "account_id",
				"required": true,
				"schema": {
					"example": "023e105f4ecef8ad9ca31a8372d0c353",
					"type": "string",
					"x-auditable": true
				}
			},
			{
				"in": "query",
				"name": "queueRequest",
				"schema": {
					"example": "true",
					"type": "string",
					"x-auditable": true
				}
			}
		],
		"requestBody": {
			"content": {
				"application/json": {
					"schema": {
						"properties": {
							"audio": {
								"properties": {
									"body": {
										"type": "object"
									},
									"contentType": {
										"type": "string"
									}
								},
								"required": [
									"body",
									"contentType"
								],
								"type": "object"
							},
							"channels": {
								"description": "The number of channels in the submitted audio",
								"type": "number"
							},
							"custom_intent": {
								"description": "Custom intents you want the model to detect within your input audio if present",
								"type": "string"
							},
							"custom_intent_mode": {
								"description": "Sets how the model will interpret intents submitted to the custom_intent param. When strict, the model will only return intents submitted using the custom_intent param. When extended, the model will return its own detected intents in addition those submitted using the custom_intents param",
								"enum": [
									"extended",
									"strict"
								],
								"type": "string"
							},
							"custom_topic": {
								"description": "Custom topics you want the model to detect within your input audio or text if present Submit up to 100",
								"type": "string"
							},
							"custom_topic_mode": {
								"description": "Sets how the model will interpret strings submitted to the custom_topic param. When strict, the model will only return topics submitted using the custom_topic param. When extended, the model will return its own detected topics in addition to those submitted using the custom_topic param.",
								"enum": [
									"extended",
									"strict"
								],
								"type": "string"
							},
							"detect_entities": {
								"description": "Identifies and extracts key entities from content in submitted audio",
								"type": "boolean"
							},
							"detect_language": {
								"description": "Identifies the dominant language spoken in submitted audio",
								"type": "boolean"
							},
							"diarize": {
								"description": "Recognize speaker changes. Each word in the transcript will be assigned a speaker number starting at 0",
								"type": "boolean"
							},
							"dictation": {
								"description": "Identify and extract key entities from content in submitted audio",
								"type": "boolean"
							},
							"encoding": {
								"description": "Specify the expected encoding of your submitted audio",
								"enum": [
									"linear16",
									"flac",
									"mulaw",
									"amr-nb",
									"amr-wb",
									"opus",
									"speex",
									"g729"
								],
								"type": "string"
							},
							"endpointing": {
								"description": "Indicates how long model will wait to detect whether a speaker has finished speaking or pauses for a significant period of time. When set to a value, the streaming endpoint immediately finalizes the transcription for the processed time range and returns the transcript with a speech_final parameter set to true. Can also be set to false to disable endpointing",
								"type": "string"
							},
							"extra": {
								"description": "Arbitrary key-value pairs that are attached to the API response for usage in downstream processing",
								"type": "string"
							},
							"filler_words": {
								"description": "Filler Words can help transcribe interruptions in your audio, like 'uh' and 'um'",
								"type": "boolean"
							},
							"interim_results": {
								"description": "Specifies whether the streaming endpoint should provide ongoing transcription updates as more audio is received. When set to true, the endpoint sends continuous updates, meaning transcription results may evolve over time. Note: Supported only for webosockets.",
								"type": "boolean"
							},
							"keyterm": {
								"description": "Key term prompting can boost or suppress specialized terminology and brands.",
								"type": "string"
							},
							"keywords": {
								"description": "Keywords can boost or suppress specialized terminology and brands.",
								"type": "string"
							},
							"language": {
								"description": "The BCP-47 language tag that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available.",
								"type": "string"
							},
							"measurements": {
								"description": "Spoken measurements will be converted to their corresponding abbreviations.",
								"type": "boolean"
							},
							"mip_opt_out": {
								"description": "Opts out requests from the Deepgram Model Improvement Program. Refer to our Docs for pricing impacts before setting this to true. https://dpgr.am/deepgram-mip.",
								"type": "boolean"
							},
							"mode": {
								"description": "Mode of operation for the model representing broad area of topic that will be talked about in the supplied audio",
								"enum": [
									"general",
									"medical",
									"finance"
								],
								"type": "string"
							},
							"multichannel": {
								"description": "Transcribe each audio channel independently.",
								"type": "boolean"
							},
							"numerals": {
								"description": "Numerals converts numbers from written format to numerical format.",
								"type": "boolean"
							},
							"paragraphs": {
								"description": "Splits audio into paragraphs to improve transcript readability.",
								"type": "boolean"
							},
							"profanity_filter": {
								"description": "Profanity Filter looks for recognized profanity and converts it to the nearest recognized non-profane word or removes it from the transcript completely.",
								"type": "boolean"
							},
							"punctuate": {
								"description": "Add punctuation and capitalization to the transcript.",
								"type": "boolean"
							},
							"redact": {
								"description": "Redaction removes sensitive information from your transcripts.",
								"type": "string"
							},
							"replace": {
								"description": "Search for terms or phrases in submitted audio and replaces them.",
								"type": "string"
							},
							"search": {
								"description": "Search for terms or phrases in submitted audio.",
								"type": "string"
							},
							"sentiment": {
								"description": "Recognizes the sentiment throughout a transcript or text.",
								"type": "boolean"
							},
							"smart_format": {
								"description": "Apply formatting to transcript output. When set to true, additional formatting will be applied to transcripts to improve readability.",
								"type": "boolean"
							},
							"topics": {
								"description": "Detect topics throughout a transcript or text.",
								"type": "boolean"
							},
							"utt_split": {
								"description": "Seconds to wait before detecting a pause between words in submitted audio.",
								"type": "number"
							},
							"utterance_end_ms": {
								"description": "Indicates how long model will wait to send an UtteranceEnd message after a word has been transcribed. Use with interim_results. Note: Supported only for webosockets.",
								"type": "boolean"
							},
							"utterances": {
								"description": "Segments speech into meaningful semantic units.",
								"type": "boolean"
							},
							"vad_events": {
								"description": "Indicates that speech has started. You'll begin receiving Speech Started messages upon speech starting. Note: Supported only for webosockets.",
								"type": "boolean"
							}
						},
						"required": [
							"audio"
						],
						"type": "object"
					}
				}
			}
		},
		"responses": {
			"200": {
				"content": {
					"application/json": {
						"schema": {
							"type": "object"
						}
					}
				},
				"description": "Object with user data."
			},
			"400": {
				"content": {
					"application/json": {
						"schema": {
							"properties": {
								"errors": {
									"items": {
										"properties": {
											"code": {
												"type": "string"
											},
											"message": {
												"type": "string"
											}
										},
										"required": [
											"code",
											"message"
										],
										"type": "object"
									},
									"type": "array"
								},
								"result": {
									"type": "object"
								},
								"success": {
									"type": "boolean"
								}
							},
							"required": [
								"errors",
								"success",
								"result"
							],
							"type": "object"
						}
					}
				},
				"description": "Bad request"
			}
		},
		"security": [
			{
				"api_token": []
			},
			{
				"api_email": [],
				"api_key": []
			}
		],
		"summary": "Execute @cf/deepgram/nova-3 model.",
		"tags": [
			"Workers AI Automatic Speech Recognition"
		],
		"x-api-token-group": [
			"Workers AI Write",
			"Workers AI Read"
		],
		"x-cfPermissionsRequired": {
			"enum": [
				"com.cloudflare.api.account.ai"
			]
		},
		"x-cfPlanAvailability": {
			"business": true,
			"enterprise": true,
			"free": true,
			"pro": true
		}
	},
	"POST /accounts/{account_id}/ai/run/@cf/openai/whisper": {
		"operationId": "workers-ai-post-run-cf-openai-whisper",
		"parameters": [
			{
				"in": "path",
				"name": "account_id",
				"required": true,
				"schema": {
					"example": "023e105f4ecef8ad9ca31a8372d0c353",
					"type": "string",
					"x-auditable": true
				}
			},
			{
				"in": "query",
				"name": "queueRequest",
				"schema": {
					"example": "true",
					"type": "string",
					"x-auditable": true
				}
			}
		],
		"requestBody": {
			"content": {
				"application/octet-stream": {
					"schema": {
						"format": "binary",
						"type": "string"
					}
				}
			}
		},
		"responses": {
			"200": {
				"content": {
					"application/json": {
						"schema": {
							"type": "object"
						}
					}
				},
				"description": "Object with user data."
			},
			"400": {
				"content": {
					"application/json": {
						"schema": {
							"properties": {
								"errors": {
									"items": {
										"properties": {
											"code": {
												"type": "string"
											},
											"message": {
												"type": "string"
											}
										},
										"required": [
											"code",
											"message"
										],
										"type": "object"
									},
									"type": "array"
								},
								"result": {
									"type": "object"
								},
								"success": {
									"type": "boolean"
								}
							},
							"required": [
								"errors",
								"success",
								"result"
							],
							"type": "object"
						}
					}
				},
				"description": "Bad request"
			}
		},
		"security": [
			{
				"api_token": []
			},
			{
				"api_email": [],
				"api_key": []
			}
		],
		"summary": "Execute @cf/openai/whisper model.",
		"tags": [
			"Workers AI Automatic Speech Recognition"
		],
		"x-api-token-group": [
			"Workers AI Write",
			"Workers AI Read"
		],
		"x-cfPermissionsRequired": {
			"enum": [
				"com.cloudflare.api.account.ai"
			]
		},
		"x-cfPlanAvailability": {
			"business": true,
			"enterprise": true,
			"free": true,
			"pro": true
		}
	},
	"POST /accounts/{account_id}/ai/run/@cf/openai/whisper-large-v3-turbo": {
		"operationId": "workers-ai-post-run-cf-openai-whisper-large-v3-turbo",
		"parameters": [
			{
				"in": "path",
				"name": "account_id",
				"required": true,
				"schema": {
					"example": "023e105f4ecef8ad9ca31a8372d0c353",
					"type": "string",
					"x-auditable": true
				}
			},
			{
				"in": "query",
				"name": "queueRequest",
				"schema": {
					"example": "true",
					"type": "string",
					"x-auditable": true
				}
			}
		],
		"requestBody": {
			"content": {
				"application/json": {
					"schema": {
						"properties": {
							"audio": {
								"description": "Base64 encoded value of the audio data.",
								"type": "string"
							},
							"initial_prompt": {
								"description": "A text prompt to help provide context to the model on the contents of the audio.",
								"type": "string"
							},
							"language": {
								"description": "The language of the audio being transcribed or translated.",
								"type": "string"
							},
							"prefix": {
								"description": "The prefix it appended the the beginning of the output of the transcription and can guide the transcription result.",
								"type": "string"
							},
							"task": {
								"default": "transcribe",
								"description": "Supported tasks are 'translate' or 'transcribe'.",
								"type": "string"
							},
							"vad_filter": {
								"default": false,
								"description": "Preprocess the audio with a voice activity detection model.",
								"type": "boolean"
							}
						},
						"required": [
							"audio"
						],
						"type": "object"
					}
				}
			}
		},
		"responses": {
			"200": {
				"content": {
					"application/json": {
						"schema": {
							"type": "object"
						}
					}
				},
				"description": "Object with user data."
			},
			"400": {
				"content": {
					"application/json": {
						"schema": {
							"properties": {
								"errors": {
									"items": {
										"properties": {
											"code": {
												"type": "string"
											},
											"message": {
												"type": "string"
											}
										},
										"required": [
											"code",
											"message"
										],
										"type": "object"
									},
									"type": "array"
								},
								"result": {
									"type": "object"
								},
								"success": {
									"type": "boolean"
								}
							},
							"required": [
								"errors",
								"success",
								"result"
							],
							"type": "object"
						}
					}
				},
				"description": "Bad request"
			}
		},
		"security": [
			{
				"api_token": []
			},
			{
				"api_email": [],
				"api_key": []
			}
		],
		"summary": "Execute @cf/openai/whisper-large-v3-turbo model.",
		"tags": [
			"Workers AI Automatic Speech Recognition"
		],
		"x-api-token-group": [
			"Workers AI Write",
			"Workers AI Read"
		],
		"x-cfPermissionsRequired": {
			"enum": [
				"com.cloudflare.api.account.ai"
			]
		},
		"x-cfPlanAvailability": {
			"business": true,
			"enterprise": true,
			"free": true,
			"pro": true
		}
	},
	"POST /accounts/{account_id}/ai/run/@cf/openai/whisper-tiny-en": {
		"operationId": "workers-ai-post-run-cf-openai-whisper-tiny-en",
		"parameters": [
			{
				"in": "path",
				"name": "account_id",
				"required": true,
				"schema": {
					"example": "023e105f4ecef8ad9ca31a8372d0c353",
					"type": "string",
					"x-auditable": true
				}
			},
			{
				"in": "query",
				"name": "queueRequest",
				"schema": {
					"example": "true",
					"type": "string",
					"x-auditable": true
				}
			}
		],
		"requestBody": {
			"content": {
				"application/octet-stream": {
					"schema": {
						"format": "binary",
						"type": "string"
					}
				}
			}
		},
		"responses": {
			"200": {
				"content": {
					"application/json": {
						"schema": {
							"type": "object"
						}
					}
				},
				"description": "Object with user data."
			},
			"400": {
				"content": {
					"application/json": {
						"schema": {
							"properties": {
								"errors": {
									"items": {
										"properties": {
											"code": {
												"type": "string"
											},
											"message": {
												"type": "string"
											}
										},
										"required": [
											"code",
											"message"
										],
										"type": "object"
									},
									"type": "array"
								},
								"result": {
									"type": "object"
								},
								"success": {
									"type": "boolean"
								}
							},
							"required": [
								"errors",
								"success",
								"result"
							],
							"type": "object"
						}
					}
				},
				"description": "Bad request"
			}
		},
		"security": [
			{
				"api_token": []
			},
			{
				"api_email": [],
				"api_key": []
			}
		],
		"summary": "Execute @cf/openai/whisper-tiny-en model.",
		"tags": [
			"Workers AI Automatic Speech Recognition"
		],
		"x-api-token-group": [
			"Workers AI Write",
			"Workers AI Read"
		],
		"x-cfPermissionsRequired": {
			"enum": [
				"com.cloudflare.api.account.ai"
			]
		},
		"x-cfPlanAvailability": {
			"business": true,
			"enterprise": true,
			"free": true,
			"pro": true
		}
	}
}