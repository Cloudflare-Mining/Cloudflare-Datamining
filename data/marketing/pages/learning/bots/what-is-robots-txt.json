{
	"componentChunkName": "component---src-components-learning-center-templates-learning-center-article-template-tsx",
	"path": "/learning/bots/what-is-robots-txt/",
	"result": {
		"data": {
			"learningCenterArticle": {
				"contentTypeId": "learningCenterArticle",
				"contentfulId": "2dDx8UKBLlrJSRUt7h3CJA",
				"urlSlug": "bots/what-is-robots-txt",
				"metaTags": {
					"metaTitle": "What is robots.txt? | Robots.txt file guide",
					"metaDescription": "Robots.txt file instructions guide crawler bots on which pages they should crawl. Learn what robots.txt is, how it works, and explore best practices.",
					"twitterCustomImage": null,
					"metaImage": {
						"file": {
							"publicURL": "https://cf-assets.www.cloudflare.com/slt3lc6tev37/2PbUOkg2YQO376yeOuiau1/52a590890360da7933b33e2d375f6c30/bots-lc.png"
						},
						"description": "Learning Center Bots OG Image"
					},
					"facebookCustomImage": null
				},
				"metaTitle": "What Is Robots.txt? | How a Robots.txt File Works",
				"metaDescription": "A robots.txt file contains instructions for bots on which pages they can and cannot access. See a robots.txt example and learn how robots.txt files work.",
				"learningCenterArticleSubHeader": {
					"contentTypeId": "learningCenterArticleSubHeader",
					"contentfulId": "6odYxFMPF3avZtlz80l12X",
					"learningCenterName": "bots",
					"links": [
						{
							"contentTypeId": "learningCenterArticleLink",
							"contentfulId": "1GSDQIDit6fjVIjcU5dM5t",
							"displayText": "What is a bot?",
							"url": "/learning/bots/what-is-a-bot/"
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "52sCrA6CA1UL0IZgj9Skw6",
							"name": "Bots Header: Bot Attacks",
							"displayText": "Bot attacks",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "5DcKuqotV8LsLtO0wQopp5",
									"displayText": "What is a bot attack?",
									"url": "/learning/bots/what-is-a-bot-attack/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "lGKcPZMP9E7aA7liTRYOP",
									"displayText": "Credential stuffing",
									"url": "/learning/bots/what-is-credential-stuffing/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6EaGRusveI0L4MaAFbVJKi",
									"displayText": "Content scraping",
									"url": "/learning/bots/what-is-content-scraping/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3qtyEvMRV1D1uXjmlnWZb8",
									"displayText": "Data scraping",
									"url": "/learning/bots/what-is-data-scraping/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "4Iu9iZ8JoQuMdcLsZeMa1g",
									"displayText": "Brute force attack",
									"url": "/learning/bots/brute-force-attack/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1AtE9FlVfE5vYUaLCt98SB",
									"displayText": "Click fraud",
									"url": "/learning/bots/what-is-click-fraud/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "khF2wD0p2WQwU4BygMi1Z",
									"displayText": "What is ad fraud?",
									"url": "/learning/bots/what-is-ad-fraud/"
								}
							]
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "5P3y4Cs9e0tUqGHbSzgd0U",
							"name": "Bot Header: Bot Management",
							"displayText": "Bot management",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1p5yVGMlR7uAX8Y6PlnIi5",
									"displayText": "What is bot management?",
									"url": "/learning/bots/what-is-bot-management/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1kC7EdNV1yJe2WGWt4h7yf",
									"displayText": "How CAPTCHAs work",
									"url": "/learning/bots/how-captchas-work/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6zUsw3wyoBqtsDX8JNwzWM",
									"displayText": "What is robots.txt?",
									"url": "/learning/bots/what-is-robots-txt/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "gNPEqPZACbssadcO1JPZZ",
									"displayText": "Manage good bots",
									"url": "/learning/bots/how-to-manage-good-bots/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "7cZRetU3A2uXn7r3UVNwgv",
									"displayText": "What is rate limiting?",
									"url": "/learning/bots/what-is-rate-limiting/"
								}
							]
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "CtozK5YVpXnALZl9gi1hI",
							"name": "Bots Header: Types of Bots",
							"displayText": "Types of bots",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2LI3XSp4gRBbuDKFVBUsoD",
									"displayText": "Spam bots",
									"url": "/learning/bots/what-is-a-spambot/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "lPnhhxwLhjTEC8rurRhbS",
									"displayText": "Web crawler",
									"url": "/learning/bots/what-is-a-web-crawler/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6CYbccQqJ6WDSGhUiGRvGG",
									"displayText": "Chatbots",
									"url": "/learning/bots/what-is-a-chatbot/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3ZtJr8K5XTM5q9hxCgo4Vc",
									"displayText": "Bot traffic",
									"url": "/learning/bots/what-is-bot-traffic/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3M7cnKpYwmspkeqDx4UFPC",
									"displayText": "What is a social media bot?",
									"url": "/learning/bots/what-is-a-social-media-bot/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2CZ3X4nLSsHN4VBtnEdVYJ",
									"displayText": "How are bots made?",
									"url": "/learning/bots/how-is-an-internet-bot-constructed/"
								}
							]
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "66ZhoXggMCPDEl5JcjR5dQ",
							"name": "Bots header: theNET",
							"displayText": "theNET",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "7nYhsmOt8j2TMfIi6t2pOG",
									"displayText": "The future of web application security",
									"url": "https://www.cloudflare.com/insights-future-web-security/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2Op2roWYABZSvyMX321o1I",
									"displayText": "API growth parallels attacks",
									"url": "learning/insights-waap-api-security"
								}
							]
						}
					]
				},
				"learningCenterArticleFooter": {
					"contentTypeId": "learningCenterArticleFooter",
					"contentfulId": "3dHDEodSXkBWoocRmVi43W",
					"learningCenterName": "bots",
					"column1Title": "About Bots",
					"column1": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "y82XzW9k8VbYtvHPqeF8O",
						"name": "Bots Footer - About Bots",
						"displayText": "About bots",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1GSDQIDit6fjVIjcU5dM5t",
								"displayText": "What is a bot?",
								"url": "/learning/bots/what-is-a-bot/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1YVZH07pYUZBjFQ4VHroE1",
								"displayText": "What is bot traffic?",
								"url": "/learning/bots/what-is-bot-traffic/"
							}
						]
					},
					"column2Title": "Bot Attacks",
					"column2": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "6aUCBgtSY7NPwWi9z5PAKI",
						"name": "Bot Footer - Attacks",
						"displayText": "Bot attacks",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "5DcKuqotV8LsLtO0wQopp5",
								"displayText": "What is a bot attack?",
								"url": "/learning/bots/what-is-a-bot-attack/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6EaGRusveI0L4MaAFbVJKi",
								"displayText": "Content scraping",
								"url": "/learning/bots/what-is-content-scraping/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "3qtyEvMRV1D1uXjmlnWZb8",
								"displayText": "Data scraping",
								"url": "/learning/bots/what-is-data-scraping/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "lGKcPZMP9E7aA7liTRYOP",
								"displayText": "Credential stuffing",
								"url": "/learning/bots/what-is-credential-stuffing/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1AtE9FlVfE5vYUaLCt98SB",
								"displayText": "Click fraud",
								"url": "/learning/bots/what-is-click-fraud/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "khF2wD0p2WQwU4BygMi1Z",
								"displayText": "What is ad fraud?",
								"url": "/learning/bots/what-is-ad-fraud/"
							}
						]
					},
					"column3Title": "Bot Management",
					"column3": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "6Kz1zkc6RZUn2UmpgC2jwh",
						"name": "Bots Footer - Bot Management",
						"displayText": "Bot management",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1p5yVGMlR7uAX8Y6PlnIi5",
								"displayText": "What is bot management?",
								"url": "/learning/bots/what-is-bot-management/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "gNPEqPZACbssadcO1JPZZ",
								"displayText": "Manage good bots",
								"url": "/learning/bots/how-to-manage-good-bots/"
							}
						]
					},
					"column4Title": "Glossary",
					"column4": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "6JQB8Mu4qlxImbcxMv3s1C",
						"name": "Bots Footer - Glossary",
						"displayText": "Glossary",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "4Iu9iZ8JoQuMdcLsZeMa1g",
								"displayText": "Brute force attack",
								"url": "/learning/bots/brute-force-attack/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "2LI3XSp4gRBbuDKFVBUsoD",
								"displayText": "Spam bots",
								"url": "/learning/bots/what-is-a-spambot/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "lPnhhxwLhjTEC8rurRhbS",
								"displayText": "Web crawler",
								"url": "/learning/bots/what-is-a-web-crawler/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6CYbccQqJ6WDSGhUiGRvGG",
								"displayText": "Chatbots",
								"url": "/learning/bots/what-is-a-chatbot/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1kC7EdNV1yJe2WGWt4h7yf",
								"displayText": "How CAPTCHAs work",
								"url": "/learning/bots/how-captchas-work/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6zUsw3wyoBqtsDX8JNwzWM",
								"displayText": "What is robots.txt?",
								"url": "/learning/bots/what-is-robots-txt/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "3M7cnKpYwmspkeqDx4UFPC",
								"displayText": "What is a social media bot?",
								"url": "/learning/bots/what-is-a-social-media-bot/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7cZRetU3A2uXn7r3UVNwgv",
								"displayText": "What is rate limiting?",
								"url": "/learning/bots/what-is-rate-limiting/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "2CZ3X4nLSsHN4VBtnEdVYJ",
								"displayText": "How are bots made?",
								"url": "/learning/bots/how-is-an-internet-bot-constructed/"
							}
						]
					},
					"column5Title": "Learning Center Nav",
					"column5": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "4lgIzgLOUuXdl1OVbsTSzW",
						"name": "Bots Footer - Learning Center Nav",
						"displayText": "Learning Center Navigation",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "2hdSVoYA5asSIG0U2ae20c",
								"displayText": "Learning Center Home",
								"url": "/learning/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "56Y6OytBNgNoNDWQL2ezlf",
								"displayText": "DDoS Learning Center",
								"url": "/learning/ddos/what-is-a-ddos-attack/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6DGcnYIMM0eCGwqAKu2ECO",
								"displayText": "CDN Learning Center",
								"url": "/learning/cdn/what-is-a-cdn/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "4Ra0qmFJ1uewk2MYscW8KI",
								"displayText": "DNS Learning Center",
								"url": "/learning/dns/what-is-dns/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "52V7iI9YriJ0En2SGmEXz5",
								"displayText": "SSL Learning Center",
								"url": "/learning/ssl/what-is-ssl/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "Q67XLnKqKhfmDJR4q9hJT",
								"displayText": "Performance Learning Center",
								"url": "/learning/performance/why-site-speed-matters/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1yItw6W6SsM2Y0Wuq6Y2c6",
								"displayText": "Security Learning Center",
								"url": "/learning/security/what-is-web-application-security/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1z3UC9tP1Kjk85BX5zSGPY",
								"displayText": "Serverless Learning Center",
								"url": "/learning/serverless/what-is-serverless/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7jgqDUFFzaLuKrsaBTLdV0",
								"displayText": "Cloud Learning Center",
								"url": "/learning/cloud/what-is-the-cloud/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6PdBQjiFs98K6RQuG5TYNd",
								"displayText": "Access Management Learning Center",
								"url": "/learning/access-management/what-is-identity-and-access-management/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "3jjEMuuLrCwhRidjG5kglM",
								"displayText": "Network Layer Learning Center",
								"url": "/learning/network-layer/what-is-the-network-layer/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6RvS0l0m86G1VISDrEvlJb",
								"displayText": "Privacy Learning Center",
								"url": "/learning/privacy/what-is-data-privacy/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "MytksT5WU5mh863BQYEkj",
								"displayText": "Video Streaming Learning Center",
								"url": "/learning/video/what-is-streaming/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "5ysNN6LRvlvlFj4ekk2xq4",
								"displayText": "Email Security Learning Center",
								"url": "/learning/email-security/what-is-email-security/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7CoqFqlHQVmsyV0mxgXUs2",
								"displayText": "AI Learning Center",
								"url": "/learning/ai/what-is-artificial-intelligence/"
							}
						]
					}
				},
				"header": "What is robots.txt? | How a robots.txt file works",
				"blurbSubHeader": "A robots.txt file lists a website's preferences for bot behavior. It tells bots which webpages they should and should not access. Robots.txt files are most relevant for web crawlers.",
				"objectivesHeader": "Robots.txt",
				"objectivesList": [
					"Learn what a robots.txt file is",
					"Understand how bots interact with a robots.txt file",
					"Explore the protocols used in a robots.txt file, including the Robots Exclusion Protocol and Sitemaps"
				],
				"relatedContentLinkText": "Related Content",
				"relatedContent": [
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "3JBCmesUfxbIiXX5MDTifD",
						"displayText": "Bot management",
						"url": "/learning/bots/what-is-bot-management/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "7gkkKUjgviqfhxzcZ64YNO",
						"displayText": "Good bots vs. bad bots",
						"url": "/learning/bots/how-to-manage-good-bots/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "gNPEqPZACbssadcO1JPZZ",
						"displayText": "Manage good bots",
						"url": "/learning/bots/how-to-manage-good-bots/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "2LI3XSp4gRBbuDKFVBUsoD",
						"displayText": "Spam bots",
						"url": "/learning/bots/what-is-a-spambot/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "1GSDQIDit6fjVIjcU5dM5t",
						"displayText": "What is a bot?",
						"url": "/learning/bots/what-is-a-bot/"
					}
				],
				"enablementBlade": {
					"contentTypeId": "bladeEnablement",
					"contentfulId": "3WRRo5n8dwVM3PJJxGuzI4",
					"title": "Defend against bot attacks like credential stuffing and content scraping with Cloudflare",
					"titleSize": "medium",
					"backgroundColor": "image-background",
					"buttonText": null,
					"buttonUrl": null,
					"buttonText2": null,
					"buttonModalId2": null,
					"buttonUrl2": null,
					"bladeSizeType": "large",
					"htmlId": null,
					"bladeBorder": "none",
					"buttonOne": {
						"buttonAssetFile": null,
						"buttonTextLoggedIn": null,
						"contentTypeId": "button",
						"contentfulId": "ahXXNzCi3YFv90DUBSSXO",
						"elementName": "Start stopping bad bots",
						"standardText": null,
						"text": "Start stopping bad bots",
						"url": "https://www.cloudflare.com/lp/pg-security-lc",
						"loggedInUrl": null,
						"buttonModal": null,
						"openInNewTab": false,
						"locale": "en-US"
					},
					"buttonTwo": null,
					"sectionPadding": null,
					"eyebrow": null
				},
				"desktopMainContent": "<h2 class=\"learning-content-h2 learning-content-h2--margin-top-16px\" itemprop=\"headline\">What is robots.txt?</h2>\n\n<img src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/4lebdo4WgUFyTBkAWEMc0V/57cae35b0d24baf7c7f99c8fc0184bb7/what-is-robots-txt.svg\" class=\"responsive-image--50-pct-center\" alt=\"The OSI Model\" itemprop=\"image\"/>\n\n<p>A robots.txt file is a set of guidelines for <a href='/learning/bots/what-is-a-bot/'>bots</a>. This file is included in the source files of most websites. Robots.txt files are intended for managing the activities of bots like <a href='/learning/bots/what-is-a-web-crawler/'>web crawlers</a>, although not all bots will follow the instructions.</p>\n\n<p>Think of a robots.txt file as being like a \"Code of Conduct\" sign posted on the wall at a gym, a bar, or a community center: The sign itself has no power to enforce the listed rules, but \"good\" patrons will follow the rules, while \"bad\" ones are likely to break them and get themselves banned.</p>\n\n<p>A bot is an automated computer program that interacts with websites and applications. One type of bot is called a web crawler bot. These bots \"crawl\" webpages and index the content so that it can show up in search engine results. A robots.txt file helps manage the activities of these web crawlers so that they don't overtax the web server hosting the website, or index pages that aren't meant for public view. A robots.txt file can also help manage the activities of <a href='/learning/ai/what-is-artificial-intelligence/'>AI</a> crawler bots, which can sometimes place far more of a demand on web servers than traditional web crawler bots.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">How does a robots.txt file work?</h2>\n\n<p>A robots.txt file is just a text file with no HTML markup code (hence the .txt extension). The robots.txt file is hosted on the web server just like any other file on the website. In fact, the robots.txt file for any given website can typically be viewed by typing the full URL for the homepage and then adding /robots.txt, like <a href='https://www.cloudflare.com/robots.txt' target='_blank'>https://www.cloudflare.com/robots.txt</a>. The file isn't linked to anywhere else on the site, so users aren't likely to stumble upon it, but most web crawler bots will look for this file first before crawling the rest of the site.</p>\n\n<p>While a robots.txt file provides instructions for bots, it can't actually enforce the instructions. Some bots, such as web crawler or news feed bots, may attempt to visit the robots.txt file first before viewing any other pages on a domain, and may follow the instructions. Other bots will either ignore the robots.txt file or will process it in order to find the webpages that are forbidden.</p>\n\n<p>A web crawler bot that complies with robots.txt will follow the most specific set of instructions in the robots.txt file. If there are contradictory commands in the file, the bot will follow the more granular command.</p>\n\n<p>One important thing to note is that all subdomains need their own robots.txt file. For instance, while www.cloudflare.com has its own file, all the Cloudflare subdomains (blog.cloudflare.com, community.cloudflare.com, etc.) need their own as well.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What protocols are used in a robots.txt file?</h2>\n\n<p>In networking, a <a href='/learning/network-layer/what-is-a-protocol/'>protocol</a> is a format for providing instructions or commands. Robots.txt files use a couple of different protocols. The main protocol is called the Robots Exclusion Protocol. This is a way to tell bots which webpages and resources to avoid. Instructions formatted for this protocol are included in the robots.txt file.</p>\n\n<p>The other protocol used for robots.txt files is the Sitemaps protocol. This can be considered a robots inclusion protocol. Sitemaps show a web crawler which pages they can crawl. This helps ensure that a crawler bot won't miss any important pages.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">Example of a robots.txt file</h2>\n\n<p>Here's an old version of the robots.txt file for www.cloudflare.com:</p>\n\n<img src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/3Ywvq2PWJh61tcLdjerzsf/e9285f6cb42c1ece060d2e4aa29bf6b2/robots-txt-example.png\" class=\"responsive-image\" alt=\"robots.txt file example\" itemprop=\"image\"/>\n\n<p>Below we break down what this all means.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What is a user agent? What does 'User-agent: *' mean?</h2>\n\n<p>Any person or program active on the Internet will have a \"user agent,\" or an assigned name. For human users, this includes information like the browser type and the operating system version but no personal information; it helps websites show content that's compatible with the user's system. For bots, the user agent (theoretically) helps website administrators know what kind of bots are crawling the site.</p>\n\n<p>In a robots.txt file, website administrators are able to provide specific instructions for specific bots by writing different instructions for bot user agents. For instance, if an administrator wants a certain page to show up in Google search results but not Bing searches, they could include two sets of commands in the robots.txt file: one set preceded by \"User-agent: Bingbot\" and one set preceded by \"User-agent: Googlebot\".</p>\n\n<p>In the example above, Cloudflare included \"User-agent: *\" in the robots.txt file. The asterisk represents a \"wild card\" user agent, and it means the instructions apply to every bot, not any specific bot.</p>\n\n<p>Common search engine bot user agent names include:</p>\n\n<p><strong>Google:</strong></p>\n\n<ul class=\"learning-list\">\n  <li>Googlebot</li>\n  <li>Googlebot-Image (for images)</li>\n  <li>Googlebot-News (for news)</li>\n  <li>Googlebot-Video (for video)</li>\n</ul>\n\n<p><strong>Bing</strong></p>\n\n<ul class=\"learning-list\">\n  <li>Bingbot</li>\n  <li>MSNBot-Media (for images and video)</li>\n</ul>\n\n<p><strong>Baidu</strong></p>\n\n<ul class=\"learning-list\">\n  <li>Baiduspider</li>\n</ul>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">How do 'Disallow' commands work in a robots.txt file?</h2>\n\n<p>The Disallow command is the most common in the robots exclusion protocol. It tells bots not to access the webpage or set of webpages that come after the command. Disallowed pages aren't necessarily \"hidden\" — they just are not useful for the average Google or Bing user, so they aren't shown to them. Most of the time, a user on the website can still navigate to these pages if they know where to find them.</p>\n\n<p>The Disallow command can be used in a number of ways, several of which are displayed in the example above.</p>\n\n<h4 class=\"learning-content-h4\">Block one file (in other words, one particular webpage)</h4>\n\n<p>As an example, if Cloudflare wished to block bots from crawling our \"<a href='/learning/bots/what-is-a-bot/'>What is a bot?</a>\" article, such a command would be written as follows:</p>\n\n<pre><code>Disallow: /learning/bots/what-is-a-bot/</code></pre>\n\n<p>After the \"disallow\" command, the part of the URL of the webpage that comes after the homepage – in this case, \"www.cloudflare.com\" – is included. With this command in place, bots that comply with robots.txt instructions won't access https://www.cloudflare.com/learning/bots/what-is-a-bot/, and the page therefore probably will not show up in traditional search engine results.</p>\n\n<h4 class=\"learning-content-h4\">Block one directory</h4>\n\n<p>Sometimes it's more efficient to block several pages at once, instead of listing them all individually. If they are all in the same section of the website, a robots.txt file can just block the directory that contains them.</p>\n\n<p>An example from above is:</p>\n\n<pre><code>Disallow: /__mesa/</code></pre>\n\n<p>This means that all pages contained within the __mesa directory shouldn't be crawled.</p>\n\n<h4 class=\"learning-content-h4\">Allow full access</h4>\n\n<p>Such a command would look as follows:</p>\n\n<pre><code>Disallow:</code></pre>\n\n<p>This tells bots that they can browse the entire website, because nothing is disallowed.</p>\n\n<h4 class=\"learning-content-h4\">Hide the entire website from bots</h4>\n\n<pre><code>Disallow: /</code></pre>\n\n<p>The \"/\" here represents the \"root\" in a website's hierarchy, or the page that all the other pages branch out from, so it includes the homepage and all the pages linked from it. With this command, search engine bots may not crawl the website at all.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What other commands are part of the Robots Exclusion Protocol?</h2>\n\n<p><strong>Allow:</strong> Just as one might expect, the \"Allow\" command tells bots they are allowed to access a certain webpage or directory. This command indicates the website's preference to allow bots to reach one particular webpage, while disallowing the rest of the webpages in the file. Not all search engines recognize this command.</p>\n\n<p><strong>Crawl-delay:</strong> The crawl delay command is meant to stop search engine spider bots from overtaxing a server. It allows administrators to specify how long the bot should wait between each request, in milliseconds. Here's an example of a Crawl-delay command to wait 8 milliseconds:</p>\n\n<pre><code>Crawl-delay: 8</code></pre>\n\n<p>Google does not recognize this command, although other search engines often do. For Google, administrators can change crawl frequency for their website in Google Search Console.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What is the Sitemaps protocol? Why is it included in robots.txt?</h2>\n\n<p>The Sitemaps protocol helps bots know what to include in their crawling of a website.</p>\n\n<p>A sitemap is an XML file that looks like this:</p>\n\n<img src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/55ZlRHspOLayKpPlr6kmaO/e4f0964c2831d18774037cf1f6557eb0/sitemap-example.png\" class=\"responsive-image\" alt=\"Sitemap example\" itemprop=\"image\"/>\n\n<p>It's a machine-readable list of all the pages on a website. Via the Sitemaps protocol, links to these sitemaps can be included in the robots.txt file. The format is: \"Sitemaps:\" followed by the web address of the XML file. You can see several examples in the Cloudflare robots.txt file above.</p>\n\n<p>While the Sitemaps protocol helps ensure that web spider bots don't miss anything as they crawl a website, the bots will still follow their typical crawling process. Sitemaps don't force crawler bots to prioritize webpages differently.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">How does robots.txt relate to bot management?</h2>\n\n<p><a href='/learning/bots/what-is-bot-management/'>Managing bots</a> is essential for keeping a website or application up and running, because even good bot activity can overtax an origin server, slowing down or taking down a web property. A well-constructed robots.txt file keeps a website optimized for <a href='/learning/performance/how-website-speed-boosts-seo/'>SEO</a> and keeps well-behaved bot activity under control. A robots.txt file will not do much for managing malicious bot traffic.</p>\n\n<p>Despite the importance of robots.txt, in 2025 Cloudflare found that only 37% of its top 10,000 websites even had a robots.txt file. This means a large percentage, perhaps a majority, of websites are not using this tool. To help these websites, especially those that may not want their original content used for AI training, Cloudflare offers \"managed robots.txt.\" This is a service that creates or updates the robots.txt file on a website's behalf with their desired settings. Learn more about <a href='https://blog.cloudflare.com/control-content-use-for-ai-training/' target='_blank'>managed robots.txt</a>.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">Robots.txt Easter eggs</h2>\n\n<p>Occasionally a robots.txt file will contain Easter eggs – humorous messages that the developers included because they know these files are rarely seen by users. For example, the <a href='https://www.youtube.com/robots.txt' target='_blank'>YouTube robots.txt file</a> reads, \"Created in the distant future (the year 2000) after the robotic uprising of the mid 90's which wiped out all humans.\" The <a href='/robots.txt' target='_blank'>Cloudflare robots.txt file</a> asks, \"Dear robot, be nice.\"</p>\n\n<pre><code>\n#    .__________________________.\n#    | .___________________. |==|\n#    | | ................. | |  |\n#    | | ::[ Dear robot ]: | |  |\n#    | | ::::[ be nice ]:: | |  |\n#    | | ::::::::::::::::: | |  |\n#    | | ::::::::::::::::: | |  |\n#    | | ::::::::::::::::: | |  |\n#    | | ::::::::::::::::: | | ,|\n#    | !___________________! |(c|\n#    !_______________________!__!\n#   /                            \\\n#  /  [][][][][][][][][][][][][]  \\\n# /  [][][][][][][][][][][][][][]  \\\n#(  [][][][][____________][][][][]  )\n# \\ ------------------------------ /\n#  \\______________________________/\n</code></pre>\n\n<p>Google also has a \"humans.txt\" file at: <a href='https://www.google.com/humans.txt' target='_blank'>https://www.google.com/humans.txt</a></p>\n\n<h2>FAQs</h2>\n\n<h4>What is a robots.txt file?</h4>\n<p>A robots.txt file is a list of a website's preferences for bot behavior located in a website's source files. It provides guidance to good bots, like search engine web crawlers, on which parts of a website they are allowed to access and which they should avoid, helping to manage traffic and control indexing. It can also list rules for AI crawlers.</p>\n\n<h4>What is a web crawler?</h4>\n<p>A web crawler is an automated bot that visits and indexes webpages for search engines, helping users find content through search results.</p>\n\n<h4>What is the Robots Exclusion Protocol?</h4>\n<p>The Robots Exclusion Protocol is the format for instructions in a robots.txt file. The protocol tells web crawlers which webpages or resources they should not access or crawl on a website.</p>\n\n<h4>What does 'User-agent' mean in a robots.txt file?</h4>\n<p>\"User-agent\" specifies which bot or group of bots a set of instructions applies to in a robots.txt file. \"User-agent: *\" means the rule applies to all bots.</p>\n\n<h4>What is the Disallow command in robots.txt?</h4>\n<p>The Disallow command tells bots not to crawl specific pages or directories on a website. For example, \"Disallow: /private/\" tells bots not to access the \"private\" directory.</p>\n\n<h4>What is the Sitemaps protocol in robots.txt?</h4>\n<p>The Sitemaps protocol allows website owners to include links to their sitemap XML files in robots.txt, helping bots discover which pages should be crawled.</p>\n\n<h4>What's the difference between good bots and bad bots?</h4>\n<p>Good bots are more likely to follow robots.txt instructions; they also perform helpful services. Search engine web crawlers, for instance, typically honor robots.txt rules as they index content for search. Bad bots often ignore robots.txt and may scrape content, attack websites, or send excessive requests that drive up costs for the website.</p>\n\n<h4>What does the Crawl-delay command do in robots.txt?</h4>\n<p>The Crawl-delay command tells bots how long to wait between requests to avoid overloading a server. Not all bots respect this command: Googlebot, for instance, does not, although Google allows website administrators to set a similar rule through Google Search Console.</p>\n\n<h4>How does robots.txt impact SEO optimization?</h4>\n<p>A well-constructed robots.txt file can improve SEO by telling search engine crawler bots which pages to index, which should help prevent non-essential or duplicate content from being indexed. Additionally, robots.txt can help web crawlers find all the pages they should index via Sitemaps.</p>\n\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What is a robots.txt file?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"A robots.txt file is a set of instructions for bots located in a website's source files. It instructs good bots, like search engine web crawlers, on which parts of a website they are allowed to access and which they should avoid, helping to manage traffic and control indexing. It can also provide instructions to AI crawlers.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What is a web crawler?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"A web crawler is an automated bot that visits and indexes webpages for search engines, helping users find content through search results.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What is the Robots Exclusion Protocol?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"The Robots Exclusion Protocol is the format for instructions in a robots.txt file. The protocol tells web crawlers which webpages or resources they should not access or crawl on a website.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What does 'User-agent' mean in a robots.txt file?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"\\\"User-agent\\\" specifies which bot or group of bots a set of instructions applies to in a robots.txt file. \\\"User-agent: *\\\" means the rule applies to all bots.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What is the Disallow command in robots.txt?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"The Disallow command tells bots not to crawl specific pages or directories on a website. For example, \\\"Disallow: /private/\\\" blocks access to the \\\"private\\\" directory.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What is the Sitemaps protocol in robots.txt?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"The Sitemaps protocol allows website owners to include links to their sitemap XML files in robots.txt, helping bots discover which pages should be crawled.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What's the difference between good bots and bad bots?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Good bots follow robots.txt instructions and perform helpful services. Search engine web crawlers, for instance, typically honor robots.txt rules as they index content for search. Bad bots often ignore robots.txt and may scrape content, attack websites, or send excessive requests that drive up costs for the website.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What does the Crawl-delay command do in robots.txt?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"The Crawl-delay command tells bots how long to wait between requests to avoid overloading a server. Not all bots respect this command: Googlebot, for instance, does not, although Google allows website administrators to set a similar rule through Google Search Console.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"How does robots.txt impact SEO optimization?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"A well-constructed robots.txt file can improve SEO by controlling which pages are indexed by search engines, preventing non-essential or duplicate content from being indexed. Additionally, robots.txt can help web crawlers find all the pages they should index via Sitemaps.\"\n      }\n    }\n  ]\n}\n</script>",
				"availableLocales": null,
				"localized": true,
				"localeList": {
					"enUS": "English for Locale",
					"zhCN": "Translated for Locale",
					"zhTW": "Translated for Locale",
					"frFR": "Translated for Locale",
					"deDE": "Translated for Locale",
					"itIT": "Translated for Locale",
					"jaJP": "Translated for Locale",
					"koKR": "Translated for Locale",
					"ptBR": "Translated for Locale",
					"esES": "Translated for Locale",
					"esLA": "Translated for Locale",
					"enAU": "English for Locale",
					"enCA": "English for Locale",
					"enIN": "English for Locale",
					"enGB": "English for Locale",
					"nlNL": "English for Locale",
					"idID": "English for Locale",
					"thTH": "English for Locale",
					"ruRU": "English for Locale",
					"svSE": "English for Locale",
					"viVN": "English for Locale",
					"trTR": "English for Locale",
					"zhHansCN": "Translated for Locale",
					"plPL": "English for Locale"
				},
				"proactivePopup": {
					"contentTypeId": "proactivePopup",
					"contentfulId": "4g1Pt1sKrA9BOPdZsrimQK",
					"headerText": "Subscribe to theNET",
					"subHeadingText": "Receive a monthly recap of the most popular Internet insights!",
					"hasMarketoForm": true,
					"marketoForm": {
						"contentTypeId": "marketoEmbeddedForm",
						"contentfulId": "3soF5uZQQ3FUQig9wvpk69",
						"bladeName": "theNET - Trending Stories - Form: Proactive Pop-up - Subscribe (Learning Center version)",
						"backgroundColor": "white",
						"marketoFormId": 2459,
						"marketoFormLeadSource": "Inbound - Blog Subscriber",
						"marketoFormLeadSourceDetail": "[BRD] Q4'24 WEB - GBL - Learning Center Subscription",
						"marketoFormHeaderText": "Receive a monthly recap of the most popular Internet insights!",
						"marketoFormDefaultComment": null,
						"showCommentBox": false,
						"marketoFormThankYouText": null,
						"marketoFormCustomSuccessMessage": "We're looking forward to sharing content with you.",
						"marketoFormPdfDownload": null,
						"marketoFormPdfDownloadI18n": [],
						"marketoFormAssetDownloadButtonText": null,
						"marketoFormSuccessRedirectUrl": null,
						"sendAdRoll": null,
						"meta_adRollCustomSegment": null,
						"enableSandbox": null,
						"marketoFormSubmitButtonText": "Subscribe",
						"marketoFormSubmitButtonColor": "orange",
						"enableEmailVerification": null,
						"disableEnterpriseEmailNotification": null,
						"enableRingout": null
					},
					"timeDelay": 1500,
					"ctaButton": null
				},
				"sidebarForm": {
					"contentTypeId": "learningCenterArticleSidebarForm",
					"contentfulId": "4ad3l3edBzH8KRefyi225g",
					"heading": "Want to keep learning?",
					"postSubmissionHeading": "Thank you for subscribing",
					"description": "Subscribe to theNET, Cloudflare's monthly recap of the Internet's most popular insights!",
					"postSubmissionDescription": "We're looking forward to sharing content with you.",
					"marketoForm": {
						"contentTypeId": "marketoEmbeddedForm",
						"contentfulId": "4N6NOUDQwA5AAjxuGTnCMu",
						"bladeName": "Form-Marketo Single Inline - Learning Center Newsletter Form",
						"backgroundColor": "blue",
						"marketoFormId": 2459,
						"marketoFormLeadSource": "Inbound - Blog Subscriber",
						"marketoFormLeadSourceDetail": "[BRD] Q4'24 WEB - GBL - Learning Center Subscription",
						"marketoFormHeaderText": null,
						"marketoFormDefaultComment": null,
						"showCommentBox": null,
						"marketoFormThankYouText": "Thank you for subscribing!",
						"marketoFormCustomSuccessMessage": "We're looking forward to sharing content with you.",
						"marketoFormPdfDownload": null,
						"marketoFormPdfDownloadI18n": [],
						"marketoFormAssetDownloadButtonText": null,
						"marketoFormSuccessRedirectUrl": null,
						"sendAdRoll": null,
						"meta_adRollCustomSegment": null,
						"enableSandbox": null,
						"marketoFormSubmitButtonText": "Subscribe  to theNET",
						"marketoFormSubmitButtonColor": null,
						"enableEmailVerification": null,
						"disableEnterpriseEmailNotification": null,
						"enableRingout": null
					}
				}
			}
		},
		"pageContext": {
			"locale": "en-US",
			"contentfulId": "2dDx8UKBLlrJSRUt7h3CJA",
			"pathname": "/learning/bots/what-is-robots-txt/",
			"baseURL": "https://www.cloudflare.com",
			"allowedHrefLangs": [
				"en-US",
				"zh-CN",
				"zh-TW",
				"fr-FR",
				"de-DE",
				"it-IT",
				"ja-JP",
				"ko-KR",
				"pt-BR",
				"es-ES",
				"es-LA",
				"zh-Hans-CN"
			]
		}
	}
}