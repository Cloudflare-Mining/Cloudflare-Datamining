{
	"componentChunkName": "component---src-components-learning-center-templates-learning-center-article-template-tsx",
	"path": "/learning/bots/what-is-robots-txt/",
	"result": {
		"data": {
			"learningCenterArticle": {
				"contentTypeId": "learningCenterArticle",
				"contentfulId": "2dDx8UKBLlrJSRUt7h3CJA",
				"urlSlug": "bots/what-is-robots-txt",
				"metaTags": {
					"metaTitle": "What is robots.txt? | Robots.txt file guide",
					"metaDescription": "Robots.txt file instructions guide search engine bots on which pages to crawl. Learn what robots.txt is, how it works, and explore best practices.",
					"twitterCustomImage": null,
					"metaImage": {
						"file": {
							"publicURL": "https://cf-assets.www.cloudflare.com/slt3lc6tev37/2PbUOkg2YQO376yeOuiau1/52a590890360da7933b33e2d375f6c30/bots-lc.png"
						},
						"description": "Learning Center Bots OG Image"
					},
					"facebookCustomImage": null
				},
				"metaTitle": "What Is Robots.txt? | How a Robots.txt File Works",
				"metaDescription": "A robots.txt file contains instructions for bots on which pages they can and cannot access. See a robots.txt example and learn how robots.txt files work.",
				"learningCenterArticleSubHeader": {
					"contentTypeId": "learningCenterArticleSubHeader",
					"contentfulId": "6odYxFMPF3avZtlz80l12X",
					"learningCenterName": "bots",
					"links": [
						{
							"contentTypeId": "learningCenterArticleLink",
							"contentfulId": "1GSDQIDit6fjVIjcU5dM5t",
							"displayText": "What is a bot?",
							"url": "/learning/bots/what-is-a-bot/"
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "52sCrA6CA1UL0IZgj9Skw6",
							"name": "Bots Header: Bot Attacks",
							"displayText": "Bot attacks",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "5DcKuqotV8LsLtO0wQopp5",
									"displayText": "What is a bot attack?",
									"url": "/learning/bots/what-is-a-bot-attack/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "lGKcPZMP9E7aA7liTRYOP",
									"displayText": "Credential stuffing",
									"url": "/learning/bots/what-is-credential-stuffing/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6EaGRusveI0L4MaAFbVJKi",
									"displayText": "Content scraping",
									"url": "/learning/bots/what-is-content-scraping/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3qtyEvMRV1D1uXjmlnWZb8",
									"displayText": "Data scraping",
									"url": "/learning/bots/what-is-data-scraping/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "4Iu9iZ8JoQuMdcLsZeMa1g",
									"displayText": "Brute force attack",
									"url": "/learning/bots/brute-force-attack/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1AtE9FlVfE5vYUaLCt98SB",
									"displayText": "Click fraud",
									"url": "/learning/bots/what-is-click-fraud/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "khF2wD0p2WQwU4BygMi1Z",
									"displayText": "What is ad fraud?",
									"url": "/learning/bots/what-is-ad-fraud/"
								}
							]
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "5P3y4Cs9e0tUqGHbSzgd0U",
							"name": "Bot Header: Bot Management",
							"displayText": "Bot management",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6zUsw3wyoBqtsDX8JNwzWM",
									"displayText": "What is robots.txt?",
									"url": "/learning/bots/what-is-robots-txt/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "gNPEqPZACbssadcO1JPZZ",
									"displayText": "Manage good bots",
									"url": "/learning/bots/how-to-manage-good-bots/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "7cZRetU3A2uXn7r3UVNwgv",
									"displayText": "What is rate limiting?",
									"url": "/learning/bots/what-is-rate-limiting/"
								}
							]
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "CtozK5YVpXnALZl9gi1hI",
							"name": "Bots Header: Types of Bots",
							"displayText": "Types of bots",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2LI3XSp4gRBbuDKFVBUsoD",
									"displayText": "Spam bots",
									"url": "/learning/bots/what-is-a-spambot/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "lPnhhxwLhjTEC8rurRhbS",
									"displayText": "Web crawler",
									"url": "/learning/bots/what-is-a-web-crawler/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6CYbccQqJ6WDSGhUiGRvGG",
									"displayText": "Chatbots",
									"url": "/learning/bots/what-is-a-chatbot/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3ZtJr8K5XTM5q9hxCgo4Vc",
									"displayText": "Bot traffic",
									"url": "/learning/bots/what-is-bot-traffic/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3M7cnKpYwmspkeqDx4UFPC",
									"displayText": "What is a social media bot?",
									"url": "/learning/bots/what-is-a-social-media-bot/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2CZ3X4nLSsHN4VBtnEdVYJ",
									"displayText": "How are bots made?",
									"url": "/learning/bots/how-is-an-internet-bot-constructed/"
								}
							]
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "66ZhoXggMCPDEl5JcjR5dQ",
							"name": "Bots header: theNET",
							"displayText": "theNET",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "7nYhsmOt8j2TMfIi6t2pOG",
									"displayText": "The future of web application security",
									"url": "https://www.cloudflare.com/insights-future-web-security/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2Op2roWYABZSvyMX321o1I",
									"displayText": "API growth parallels attacks",
									"url": "learning/insights-waap-api-security"
								}
							]
						}
					]
				},
				"learningCenterArticleFooter": null,
				"header": "What is robots.txt? | How a robots.txt file works",
				"blurbSubHeader": "A robots.txt file contains instructions for bots that tell them which webpages they can and cannot access. Robots.txt files are most relevant for web crawlers from search engines like Google.",
				"objectivesHeader": "Robots.txt",
				"objectivesList": [
					"Learn what a robots.txt file is and what it does",
					"Understand how bots interact with a robots.txt file",
					"Explore the protocols used in a robots.txt file, including the Robots Exclusion Protocol and Sitemaps"
				],
				"relatedContentLinkText": "Related Content",
				"relatedContent": [
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "3JBCmesUfxbIiXX5MDTifD",
						"displayText": "Bot management",
						"url": "/learning/bots/what-is-bot-management/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "7gkkKUjgviqfhxzcZ64YNO",
						"displayText": "Good bots vs. bad bots",
						"url": "/learning/bots/how-to-manage-good-bots/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "gNPEqPZACbssadcO1JPZZ",
						"displayText": "Manage good bots",
						"url": "/learning/bots/how-to-manage-good-bots/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "2LI3XSp4gRBbuDKFVBUsoD",
						"displayText": "Spam bots",
						"url": "/learning/bots/what-is-a-spambot/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "1GSDQIDit6fjVIjcU5dM5t",
						"displayText": "What is a bot?",
						"url": "/learning/bots/what-is-a-bot/"
					}
				],
				"enablementBlade": {
					"contentTypeId": "bladeEnablement",
					"contentfulId": "3WRRo5n8dwVM3PJJxGuzI4",
					"title": "Defend against bot attacks like credential stuffing and content scraping with Cloudflare",
					"titleSize": "medium",
					"backgroundColor": "image-background",
					"buttonText": null,
					"buttonUrl": null,
					"buttonText2": null,
					"buttonModalId2": null,
					"buttonUrl2": null,
					"bladeSizeType": "large",
					"htmlId": null,
					"bladeBorder": "none",
					"buttonOne": {
						"buttonAssetFile": null,
						"buttonTextLoggedIn": null,
						"contentTypeId": "button",
						"contentfulId": "ahXXNzCi3YFv90DUBSSXO",
						"elementName": "Start stopping bad bots",
						"standardText": null,
						"text": "Start stopping bad bots",
						"url": "https://www.cloudflare.com/lp/pg-security-lc",
						"loggedInUrl": null,
						"buttonModal": null,
						"openInNewTab": false,
						"locale": "en-US"
					},
					"buttonTwo": null,
					"sectionPadding": null,
					"eyebrow": null
				},
				"desktopMainContent": "<h2 class=\"learning-content-h2 learning-content-h2--margin-top-16px\" itemprop=\"headline\">What is robots.txt?</h2>\n\n<img src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/4lebdo4WgUFyTBkAWEMc0V/57cae35b0d24baf7c7f99c8fc0184bb7/what-is-robots-txt.svg\" class=\"responsive-image--50-pct-center\" alt=\"The OSI Model\" itemprop=\"image\"/>\n\n<p>A robots.txt file is a set of instructions for <a href='/learning/bots/what-is-a-bot/'>bots</a>. This file is included in the source files of most websites. Robots.txt files are mostly intended for managing the activities of good bots like <a href='/learning/bots/what-is-a-web-crawler/'>web crawlers</a>, since bad bots aren't likely to follow the instructions.</p>\n\n<p>Think of a robots.txt file as being like a \"Code of Conduct\" sign posted on the wall at a gym, a bar, or a community center: The sign itself has no power to enforce the listed rules, but \"good\" patrons will follow the rules, while \"bad\" ones are likely to break them and get themselves banned.</p>\n\n<p>A bot is an automated computer program that interacts with websites and applications. There are <a href='/learning/bots/how-to-manage-good-bots/'>good bots and bad bots</a>, and one type of good bot is called a web crawler bot. These bots \"crawl\" webpages and index the content so that it can show up in search engine results. A robots.txt file helps manage the activities of these web crawlers so that they don't overtax the web server hosting the website, or index pages that aren't meant for public view.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">How does a robots.txt file work?</h2>\n\n<p>A robots.txt file is just a text file with no HTML markup code (hence the .txt extension). The robots.txt file is hosted on the web server just like any other file on the website. In fact, the robots.txt file for any given website can typically be viewed by typing the full URL for the homepage and then adding /robots.txt, like <a href='https://www.cloudflare.com/robots.txt' target='_blank'>https://www.cloudflare.com/robots.txt</a>. The file isn't linked to anywhere else on the site, so users aren't likely to stumble upon it, but most web crawler bots will look for this file first before crawling the rest of the site.</p>\n\n<p>While a robots.txt file provides instructions for bots, it can't actually enforce the instructions. A good bot, such as a web crawler or a news feed bot, will attempt to visit the robots.txt file first before viewing any other pages on a domain, and will follow the instructions. A bad bot will either ignore the robots.txt file or will process it in order to find the webpages that are forbidden.</p>\n\n<p>A web crawler bot will follow the most specific set of instructions in the robots.txt file. If there are contradictory commands in the file, the bot will follow the more granular command.</p>\n\n<p>One important thing to note is that all subdomains need their own robots.txt file. For instance, while www.cloudflare.com has its own file, all the Cloudflare subdomains (blog.cloudflare.com, community.cloudflare.com, etc.) need their own as well.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What protocols are used in a robots.txt file?</h2>\n\n<p>In networking, a <a href='/learning/network-layer/what-is-a-protocol/'>protocol</a> is a format for providing instructions or commands. Robots.txt files use a couple of different protocols. The main protocol is called the Robots Exclusion Protocol. This is a way to tell bots which webpages and resources to avoid. Instructions formatted for this protocol are included in the robots.txt file.</p>\n\n<p>The other protocol used for robots.txt files is the Sitemaps protocol. This can be considered a robots inclusion protocol. Sitemaps show a web crawler which pages they can crawl. This helps ensure that a crawler bot won't miss any important pages.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">Example of a robots.txt file</h2>\n\n<p>Here's the robots.txt file for www.cloudflare.com:</p>\n\n<img src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/3Ywvq2PWJh61tcLdjerzsf/e9285f6cb42c1ece060d2e4aa29bf6b2/robots-txt-example.png\" class=\"responsive-image\" alt=\"The OSI Model\" itemprop=\"image\"/>\n\n<p>Below we break down what this all means.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What is a user agent? What does 'User-agent: *' mean?</h2>\n\n<p>Any person or program active on the Internet will have a \"user agent,\" or an assigned name. For human users, this includes information like the browser type and the operating system version but no personal information; it helps websites show content that's compatible with the user's system. For bots, the user agent (theoretically) helps website administrators know what kind of bots are crawling the site.</p>\n\n<p>In a robots.txt file, website administrators are able to provide specific instructions for specific bots by writing different instructions for bot user agents. For instance, if an administrator wants a certain page to show up in Google search results but not Bing searches, they could include two sets of commands in the robots.txt file: one set preceded by \"User-agent: Bingbot\" and one set preceded by \"User-agent: Googlebot\".</p>\n\n<p>In the example above, Cloudflare has included \"User-agent: *\" in the robots.txt file. The asterisk represents a \"wild card\" user agent, and it means the instructions apply to every bot, not any specific bot.</p>\n\n<p>Common search engine bot user agent names include:</p>\n\n<p><strong>Google:</strong></p>\n\n<ul class=\"learning-list\">\n  <li>Googlebot</li>\n  <li>Googlebot-Image (for images)</li>\n  <li>Googlebot-News (for news)</li>\n  <li>Googlebot-Video (for video)</li>\n</ul>\n\n<p><strong>Bing</strong></p>\n\n<ul class=\"learning-list\">\n  <li>Bingbot</li>\n  <li>MSNBot-Media (for images and video)</li>\n</ul>\n\n<p><strong>Baidu</strong></p>\n\n<ul class=\"learning-list\">\n  <li>Baiduspider</li>\n</ul>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">How do 'Disallow' commands work in a robots.txt file?</h2>\n\n<p>The Disallow command is the most common in the robots exclusion protocol. It tells bots not to access the webpage or set of webpages that come after the command. Disallowed pages aren't necessarily \"hidden\" – they just aren't useful for the average Google or Bing user, so they aren't shown to them. Most of the time, a user on the website can still navigate to these pages if they know where to find them.</p>\n\n<p>The Disallow command can be used in a number of ways, several of which are displayed in the example above.</p>\n\n<h4 class=\"learning-content-h4\">Block one file (in other words, one particular webpage)</h4>\n\n<p>As an example, if Cloudflare wished to block bots from crawling our \"<a href='/learning/bots/what-is-a-bot/'>What is a bot?</a>\" article, such a command would be written as follows:</p>\n\n<pre><code>Disallow: /learning/bots/what-is-a-bot/</code></pre>\n\n<p>After the \"disallow\" command, the part of the URL of the webpage that comes after the homepage – in this case, \"www.cloudflare.com\" – is included. With this command in place, good bots won't access https://www.cloudflare.com/learning/bots/what-is-a-bot/, and the page won't show up in search engine results.</p>\n\n<h4 class=\"learning-content-h4\">Block one directory</h4>\n\n<p>Sometimes it's more efficient to block several pages at once, instead of listing them all individually. If they are all in the same section of the website, a robots.txt file can just block the directory that contains them.</p>\n\n<p>An example from above is:</p>\n\n<pre><code>Disallow: /__mesa/</code></pre>\n\n<p>This means that all pages contained within the __mesa directory shouldn't be crawled.</p>\n\n<h4 class=\"learning-content-h4\">Allow full access</h4>\n\n<p>Such a command would look as follows:</p>\n\n<pre><code>Disallow:</code></pre>\n\n<p>This tells bots that they can browse the entire website, because nothing is disallowed.</p>\n\n<h4 class=\"learning-content-h4\">Hide the entire website from bots</h4>\n\n<pre><code>Disallow: /</code></pre>\n\n<p>The \"/\" here represents the \"root\" in a website's hierarchy, or the page that all the other pages branch out from, so it includes the homepage and all the pages linked from it. With this command, search engine bots can't crawl the website at all.</p>\n\n<p>In other words, a single slash can eliminate a whole website from the searchable Internet!</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What other commands are part of the Robots Exclusion Protocol?</h2>\n\n<p><strong>Allow:</strong> Just as one might expect, the \"Allow\" command tells bots they are allowed to access a certain webpage or directory. This command makes it possible to allow bots to reach one particular webpage, while disallowing the rest of the webpages in the file. Not all search engines recognize this command.</p>\n\n<p><strong>Crawl-delay:</strong> The crawl delay command is meant to stop search engine spider bots from overtaxing a server. It allows administrators to specify how long the bot should wait between each request, in milliseconds. Here's an example of a Crawl-delay command to wait 8 milliseconds:</p>\n\n<pre><code>Crawl-delay: 8</code></pre>\n\n<p>Google does not recognize this command, although other search engines do. For Google, administrators can change crawl frequency for their website in Google Search Console.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What is the Sitemaps protocol? Why is it included in robots.txt?</h2>\n\n<p>The Sitemaps protocol helps bots know what to include in their crawling of a website.</p>\n\n<p>A sitemap is an XML file that looks like this:</p>\n\n<img src=\"https://cf-assets.www.cloudflare.com/slt3lc6tev37/55ZlRHspOLayKpPlr6kmaO/e4f0964c2831d18774037cf1f6557eb0/sitemap-example.png\" class=\"responsive-image\" alt=\"Sitemap example\" itemprop=\"image\"/>\n\n<p>It's a machine-readable list of all the pages on a website. Via the Sitemaps protocol, links to these sitemaps can be included in the robots.txt file. The format is: \"Sitemaps:\" followed by the web address of the XML file. You can see several examples in the Cloudflare robots.txt file above.</p>\n\n<p>While the Sitemaps protocol helps ensure that web spider bots don't miss anything as they crawl a website, the bots will still follow their typical crawling process. Sitemaps don't force crawler bots to prioritize webpages differently.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">How does robots.txt relate to bot management?</h2>\n\n<p><a href='/learning/bots/what-is-bot-management/'>Managing bots</a> is essential for keeping a website or application up and running, because even good bot activity can overtax an origin server, slowing down or taking down a web property. A well-constructed robots.txt file keeps a website optimized for <a href='/learning/performance/how-website-speed-boosts-seo/'>SEO</a> and keeps good bot activity under control.</p>\n\n<p>However, a robots.txt file won't do much for managing malicious <a href='/learning/bots/what-is-bot-traffic/'>bot traffic</a>. A bot management solution such as <a href='https://www.cloudflare.com/application-services/products/bot-management/'>Cloudflare Bot Management</a> or <a href=\"https://www.cloudflare.com/pg-lp/bot-mitigation-fight-mode?utm_campaign=pgg221s-pl-super-bot-fight-lc\">Super Bot Fight Mode</a> can help curb malicious bot activity without impacting essential bots like web crawlers.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">Robots.txt Easter eggs</h2>\n\n<p>Occasionally a robots.txt file will contain Easter eggs – humorous messages that the developers included because they know these files are rarely seen by users. For example, the <a href='https://www.youtube.com/robots.txt' target='_blank'>YouTube robots.txt file</a> reads, \"Created in the distant future (the year 2000) after the robotic uprising of the mid 90's which wiped out all humans.\" The <a href='/robots.txt' target='_blank'>Cloudflare robots.txt file</a> asks, \"Dear robot, be nice.\"</p>\n\n<pre><code>\n#    .__________________________.\n#    | .___________________. |==|\n#    | | ................. | |  |\n#    | | ::[ Dear robot ]: | |  |\n#    | | ::::[ be nice ]:: | |  |\n#    | | ::::::::::::::::: | |  |\n#    | | ::::::::::::::::: | |  |\n#    | | ::::::::::::::::: | |  |\n#    | | ::::::::::::::::: | | ,|\n#    | !___________________! |(c|\n#    !_______________________!__!\n#   /                            \\\n#  /  [][][][][][][][][][][][][]  \\\n# /  [][][][][][][][][][][][][][]  \\\n#(  [][][][][____________][][][][]  )\n# \\ ------------------------------ /\n#  \\______________________________/\n</code></pre>\n\n<p>Google also has a \"humans.txt\" file at: <a href='https://www.google.com/humans.txt' target='_blank'>https://www.google.com/humans.txt</a></p>\n",
				"availableLocales": null,
				"localized": true,
				"localeList": {
					"enUS": "English for Locale",
					"zhCN": "Translated for Locale",
					"zhTW": "Translated for Locale",
					"frFR": "Translated for Locale",
					"deDE": "Translated for Locale",
					"itIT": "Translated for Locale",
					"jaJP": "Translated for Locale",
					"koKR": "Translated for Locale",
					"ptBR": "Translated for Locale",
					"esES": "Translated for Locale",
					"esLA": "Translated for Locale",
					"enAU": "English for Locale",
					"enCA": "English for Locale",
					"enIN": "English for Locale",
					"enGB": "English for Locale",
					"nlNL": "English for Locale",
					"idID": "English for Locale",
					"thTH": "English for Locale",
					"ruRU": "English for Locale",
					"svSE": "English for Locale",
					"viVN": "English for Locale",
					"trTR": "English for Locale",
					"zhHansCN": "Translated for Locale",
					"plPL": "English for Locale"
				},
				"proactivePopup": {
					"contentTypeId": "proactivePopup",
					"contentfulId": "4g1Pt1sKrA9BOPdZsrimQK",
					"headerText": "Subscribe to theNET",
					"subHeadingText": "Receive a monthly recap of the most popular Internet insights!",
					"hasMarketoForm": true,
					"marketoForm": {
						"contentTypeId": "marketoEmbeddedForm",
						"contentfulId": "3soF5uZQQ3FUQig9wvpk69",
						"bladeName": "theNET - Trending Stories - Form: Proactive Pop-up - Subscribe (Learning Center version)",
						"backgroundColor": "white",
						"marketoFormId": 2459,
						"marketoFormLeadSource": "Inbound - Blog Subscriber",
						"marketoFormLeadSourceDetail": "[BRD] Q4'24 WEB - GBL - Learning Center Subscription",
						"marketoFormHeaderText": "Receive a monthly recap of the most popular Internet insights!",
						"marketoFormDefaultComment": null,
						"showCommentBox": false,
						"marketoFormThankYouText": null,
						"marketoFormCustomSuccessMessage": "We're looking forward to sharing content with you.",
						"marketoFormPdfDownload": null,
						"marketoFormPdfDownloadI18n": [],
						"marketoFormAssetDownloadButtonText": null,
						"marketoFormSuccessRedirectUrl": null,
						"sendAdRoll": null,
						"meta_adRollCustomSegment": null,
						"enableSandbox": null,
						"marketoFormSubmitButtonText": "Subscribe",
						"marketoFormSubmitButtonColor": "orange",
						"enableEmailVerification": null,
						"disableEnterpriseEmailNotification": null,
						"enableRingout": null
					},
					"timeDelay": 1500,
					"ctaButton": null
				},
				"sidebarForm": {
					"contentTypeId": "learningCenterArticleSidebarForm",
					"contentfulId": "4ad3l3edBzH8KRefyi225g",
					"heading": "Want to keep learning?",
					"postSubmissionHeading": "Thank you for subscribing",
					"description": "Subscribe to theNET, Cloudflare's monthly recap of the Internet's most popular insights!",
					"postSubmissionDescription": "We're looking forward to sharing content with you.",
					"marketoForm": {
						"contentTypeId": "marketoEmbeddedForm",
						"contentfulId": "4N6NOUDQwA5AAjxuGTnCMu",
						"bladeName": "Form-Marketo Single Inline - Learning Center Newsletter Form",
						"backgroundColor": "blue",
						"marketoFormId": 2459,
						"marketoFormLeadSource": "Inbound - Blog Subscriber",
						"marketoFormLeadSourceDetail": "[BRD] Q4'24 WEB - GBL - Learning Center Subscription",
						"marketoFormHeaderText": null,
						"marketoFormDefaultComment": null,
						"showCommentBox": null,
						"marketoFormThankYouText": "Thank you for subscribing!",
						"marketoFormCustomSuccessMessage": "We're looking forward to sharing content with you.",
						"marketoFormPdfDownload": null,
						"marketoFormPdfDownloadI18n": [],
						"marketoFormAssetDownloadButtonText": null,
						"marketoFormSuccessRedirectUrl": null,
						"sendAdRoll": null,
						"meta_adRollCustomSegment": null,
						"enableSandbox": null,
						"marketoFormSubmitButtonText": "Subscribe  to theNET",
						"marketoFormSubmitButtonColor": null,
						"enableEmailVerification": null,
						"disableEnterpriseEmailNotification": null,
						"enableRingout": null
					}
				}
			}
		},
		"pageContext": {
			"locale": "en-US",
			"contentfulId": "2dDx8UKBLlrJSRUt7h3CJA",
			"pathname": "/learning/bots/what-is-robots-txt/",
			"baseURL": "https://www.cloudflare.com",
			"allowedHrefLangs": [
				"en-US",
				"zh-CN",
				"zh-TW",
				"fr-FR",
				"de-DE",
				"it-IT",
				"ja-JP",
				"ko-KR",
				"pt-BR",
				"es-ES",
				"es-LA",
				"zh-Hans-CN"
			]
		}
	}
}