{
	"componentChunkName": "component---src-components-learning-center-templates-learning-center-article-template-tsx",
	"path": "/learning/ai/what-is-shadow-ai/",
	"result": {
		"data": {
			"learningCenterArticle": {
				"contentTypeId": "learningCenterArticle",
				"contentfulId": "6PwAimyQPxSH1FIt89O7Ay",
				"urlSlug": "ai/what-is-shadow-ai",
				"metaTags": {
					"metaTitle": "What is shadow AI?",
					"metaDescription": "Shadow AI is the unauthorized and untracked use of AI tools within an organization's business processes or apps. Learn how to detect shadow AI.",
					"twitterCustomImage": null,
					"metaImage": {
						"file": {
							"publicURL": "https://cf-assets.www.cloudflare.com/slt3lc6tev37/53qCYhQbir5WtIU0VDWESo/954a48bfb17f429acf469e5f14345d83/unnamed-3.png"
						},
						"description": "DO NOT REMOVE, THIS IS CLOUDFLARE'S GLOBAL OG META ASSET"
					},
					"facebookCustomImage": {
						"file": {
							"publicURL": "https://cf-assets.www.cloudflare.com/slt3lc6tev37/53qCYhQbir5WtIU0VDWESo/954a48bfb17f429acf469e5f14345d83/unnamed-3.png"
						},
						"description": "DO NOT REMOVE, THIS IS CLOUDFLARE'S GLOBAL OG META ASSET"
					}
				},
				"metaTitle": null,
				"metaDescription": null,
				"learningCenterArticleSubHeader": {
					"contentTypeId": "learningCenterArticleSubHeader",
					"contentfulId": "5JjQb2yV1d1T7WTVZQkNEW",
					"learningCenterName": "artificialintelligence",
					"links": [
						{
							"contentTypeId": "learningCenterArticleLink",
							"contentfulId": "7HZD3CNwacCcZXLQxHtX8k",
							"displayText": "What is artificial intelligence (AI)?",
							"url": "/learning/ai/what-is-artificial-intelligence/"
						},
						{
							"contentTypeId": "learningCenterArticleLink",
							"contentfulId": "7lSEVfyAjPWCZDHNj1v27k",
							"displayText": "What is a large language model (LLM)?",
							"url": "/learning/ai/what-is-large-language-model/"
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "41JHcwdZJopZYPQOHjdkkE",
							"name": "Machine learning",
							"displayText": "Machine learning",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3KWX7josW5KFyGkx9WGxmj",
									"displayText": "What is machine learning?",
									"url": "/learning/ai/what-is-machine-learning/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "4Hus7gX2HZjDAzrIDfhz7Y",
									"displayText": "What is deep learning?",
									"url": "/learning/ai/what-is-deep-learning/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "5uKuVMtEUTbsmkjOh86Dsl",
									"displayText": "Neural networks",
									"url": "/learning/ai/what-is-neural-network/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6COFjJFWkujpQraRJD2KHy",
									"displayText": "What is generative AI?",
									"url": "/learning/ai/what-is-generative-ai/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1O4EuQ4MK3qvTaXomAfNzQ",
									"displayText": "Predictive AI",
									"url": "/learning/ai/what-is-predictive-ai/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2rqSZGk3Uk8E4RbUBTXhuV",
									"displayText": "AI image generation",
									"url": "/learning/ai/ai-image-generation/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "7x6FotqqlG1hJShGntgbVC",
									"displayText": "What is big data?",
									"url": "/learning/ai/big-data/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1MP0vEt5FzyhNppPMZqEHp",
									"displayText": "What is agentic AI?",
									"url": "/learning/ai/what-is-agentic-ai/"
								}
							]
						},
						{
							"contentTypeId": "learningCenterArticleLinkedList",
							"contentfulId": "2WaoB1uAGPdfW9vr56U72B",
							"name": "Glossary - AI subheader",
							"displayText": "Glossary",
							"links": [
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6oEjFOQyE5WSiuDLmNgmOu",
									"displayText": "What are embeddings?",
									"url": "/learning/ai/what-are-embeddings/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1rU1Ipdjz9cDWMUQYOjsCe",
									"displayText": "Vector database",
									"url": "/learning/ai/what-is-vector-database/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "12RjN72z2wlElvMBzyICp9",
									"displayText": "AI inference vs. training",
									"url": "/learning/ai/inference-vs-training/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2pLwK8cnRhtcrFR53cRAME",
									"displayText": "What is natural language processing (NLP)?",
									"url": "/learning/ai/natural-language-processing-nlp/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "4bUf7y8NP577uqtWUkgSwW",
									"displayText": "Low-rank adaptation (LoRA)",
									"url": "/learning/ai/what-is-lora/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "4T93P1Kxs7ZeP2eTLMiFs9",
									"displayText": "AI hallucinations",
									"url": "/learning/ai/what-are-ai-hallucinations/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "4xeYgczMnCqQ0wO8ORIbVY",
									"displayText": "AI quantization",
									"url": "/learning/ai/what-is-quantization/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3QYEJFeqaOx0hUjaQCkI4v",
									"displayText": "OWASP Top 10 for LLMs",
									"url": "/learning/ai/owasp-top-10-risks-for-llms/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "28O79uvws5OhhzxUUPMr8z",
									"displayText": "AI data poisoning",
									"url": "/learning/ai/data-poisoning/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "7uV0UxfanyoFf3Xrjnp2fk",
									"displayText": "Retrieval augmented generation (RAG)",
									"url": "/learning/ai/retrieval-augmented-generation-rag/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "13XGjbidrGmhw6y7WyyG4F",
									"displayText": "Model Context Protocol (MCP)",
									"url": "/learning/ai/what-is-model-context-protocol-mcp/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "7kvDdMXof90koTqWiUdRX5",
									"displayText": "History of AI",
									"url": "/learning/ai/history-of-ai/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "pjgC00TeWrxtIOybBfUbh",
									"displayText": "What is vibe coding?",
									"url": "/learning/ai/ai-vibe-coding/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1lT8d5JbDfSf5rPbTWrrRZ",
									"displayText": "How to start vibe coding",
									"url": "/learning/ai/how-to-get-started-with-vibe-coding/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1MZdfQqWrwJ7KJel7rp6d2",
									"displayText": "Third wave of AI",
									"url": "/learning/ai/evolution-of-ai/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "4nT7mPavmYUtr9EtXw1kVT",
									"displayText": "AI for cybersecurity",
									"url": "/learning/ai/ai-for-cybersecurity/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "20yFv0dqwOoxfKslhoIhWT",
									"displayText": "How to build RAG pipelines",
									"url": "/learning/ai/how-to-build-rag-pipelines/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2wIHY9CfGidc5XlcH2pzXd",
									"displayText": "How to manage AI agents",
									"url": "/learning/ai/how-to-manage-ai-agents-for-businesses/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "1KBcXvOgvGeMVpRGJQb03j",
									"displayText": "How to block AI crawlers",
									"url": "/learning/ai/how-to-block-ai-crawlers/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "Y9Tc8MMXjnajQIbDnrg74",
									"displayText": "How to prevent scraping",
									"url": "/learning/ai/how-to-prevent-web-scraping/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "5KGGCoBgenwdvUomxu9p34",
									"displayText": "How to secure AI systems",
									"url": "/learning/ai/how-to-secure-ai-systems/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6EYLgrBEjKBwQRbu7qpAxu",
									"displayText": "How to secure AI training data",
									"url": "/learning/ai/how-to-secure-training-data-against-ai-data-leaks/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "2MQDOpshVTC5lqGfPJckFU",
									"displayText": "ChatGPT plugins",
									"url": "/learning/ai/chatgpt-plugins/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "qwHqeq4VedN29rZ0SP2dw",
									"displayText": "Security for AI",
									"url": "/learning/ai/what-is-ai-security/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "3K1kMMUXxDtJq3yQJyNs7b",
									"displayText": "Shadow AI",
									"url": "/learning/ai/what-is-shadow-ai/"
								},
								{
									"contentTypeId": "learningCenterArticleLink",
									"contentfulId": "6xy4UeqPN2cEgZ5ALiqvTs",
									"displayText": "Prompt injection",
									"url": "/learning/ai/prompt-injection/"
								}
							]
						}
					]
				},
				"learningCenterArticleFooter": {
					"contentTypeId": "learningCenterArticleFooter",
					"contentfulId": "4fHZ91razv1xm1g6m2sAcT",
					"learningCenterName": "artificialintelligence",
					"column1Title": "Artificial intelligence",
					"column1": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "504wIqF2RxToUI652YFAHo",
						"name": "AI Footer - Artificial intelligence",
						"displayText": "Artificial intelligence",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7HZD3CNwacCcZXLQxHtX8k",
								"displayText": "What is artificial intelligence (AI)?",
								"url": "/learning/ai/what-is-artificial-intelligence/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "12RjN72z2wlElvMBzyICp9",
								"displayText": "AI inference vs. training",
								"url": "/learning/ai/inference-vs-training/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7kvDdMXof90koTqWiUdRX5",
								"displayText": "History of AI",
								"url": "/learning/ai/history-of-ai/"
							}
						]
					},
					"column2Title": "Machine learning",
					"column2": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "4WbETih2OgXGNXGsvb7kMZ",
						"name": "AI footer - Machine Learning",
						"displayText": "Machine learning",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "3KWX7josW5KFyGkx9WGxmj",
								"displayText": "What is machine learning?",
								"url": "/learning/ai/what-is-machine-learning/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "4Hus7gX2HZjDAzrIDfhz7Y",
								"displayText": "What is deep learning?",
								"url": "/learning/ai/what-is-deep-learning/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7lSEVfyAjPWCZDHNj1v27k",
								"displayText": "What is a large language model (LLM)?",
								"url": "/learning/ai/what-is-large-language-model/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "4bUf7y8NP577uqtWUkgSwW",
								"displayText": "Low-rank adaptation (LoRA)",
								"url": "/learning/ai/what-is-lora/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "2rqSZGk3Uk8E4RbUBTXhuV",
								"displayText": "AI image generation",
								"url": "/learning/ai/ai-image-generation/"
							}
						]
					},
					"column3Title": "Big data",
					"column3": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "3q3KTRPkBi7rS3aDeQoMNn",
						"name": "AI footer - Big Data",
						"displayText": "Big data",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6oEjFOQyE5WSiuDLmNgmOu",
								"displayText": "What are embeddings?",
								"url": "/learning/ai/what-are-embeddings/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7x6FotqqlG1hJShGntgbVC",
								"displayText": "What is big data?",
								"url": "/learning/ai/big-data/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "20yFv0dqwOoxfKslhoIhWT",
								"displayText": "How to build RAG pipelines",
								"url": "/learning/ai/how-to-build-rag-pipelines/"
							}
						]
					},
					"column4Title": "Glossary",
					"column4": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "1UCfw4v8J5rpL4BsVNlgVC",
						"name": "AI footer - Glossary",
						"displayText": "AI glossary",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "3gN1wRRmKbWagWGkgxTIuH",
								"displayText": "What is AI security?",
								"url": "/learning/ai/what-is-ai-security/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1rU1Ipdjz9cDWMUQYOjsCe",
								"displayText": "Vector database",
								"url": "/learning/ai/what-is-vector-database/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1O4EuQ4MK3qvTaXomAfNzQ",
								"displayText": "Predictive AI",
								"url": "/learning/ai/what-is-predictive-ai/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "2MQDOpshVTC5lqGfPJckFU",
								"displayText": "ChatGPT plugins",
								"url": "/learning/ai/chatgpt-plugins/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "5uKuVMtEUTbsmkjOh86Dsl",
								"displayText": "Neural networks",
								"url": "/learning/ai/what-is-neural-network/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6COFjJFWkujpQraRJD2KHy",
								"displayText": "What is generative AI?",
								"url": "/learning/ai/what-is-generative-ai/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "2pLwK8cnRhtcrFR53cRAME",
								"displayText": "What is natural language processing (NLP)?",
								"url": "/learning/ai/natural-language-processing-nlp/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "4T93P1Kxs7ZeP2eTLMiFs9",
								"displayText": "AI hallucinations",
								"url": "/learning/ai/what-are-ai-hallucinations/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "4xeYgczMnCqQ0wO8ORIbVY",
								"displayText": "AI quantization",
								"url": "/learning/ai/what-is-quantization/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "3QYEJFeqaOx0hUjaQCkI4v",
								"displayText": "OWASP Top 10 for LLMs",
								"url": "/learning/ai/owasp-top-10-risks-for-llms/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "28O79uvws5OhhzxUUPMr8z",
								"displayText": "AI data poisoning",
								"url": "/learning/ai/data-poisoning/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7uV0UxfanyoFf3Xrjnp2fk",
								"displayText": "Retrieval augmented generation (RAG)",
								"url": "/learning/ai/retrieval-augmented-generation-rag/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1MP0vEt5FzyhNppPMZqEHp",
								"displayText": "What is agentic AI?",
								"url": "/learning/ai/what-is-agentic-ai/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1MZdfQqWrwJ7KJel7rp6d2",
								"displayText": "Third wave of AI",
								"url": "/learning/ai/evolution-of-ai/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "pjgC00TeWrxtIOybBfUbh",
								"displayText": "What is vibe coding?",
								"url": "/learning/ai/ai-vibe-coding/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "13XGjbidrGmhw6y7WyyG4F",
								"displayText": "Model Context Protocol (MCP)",
								"url": "/learning/ai/what-is-model-context-protocol-mcp/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "4nT7mPavmYUtr9EtXw1kVT",
								"displayText": "AI for cybersecurity",
								"url": "/learning/ai/ai-for-cybersecurity/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1lT8d5JbDfSf5rPbTWrrRZ",
								"displayText": "How to start vibe coding",
								"url": "/learning/ai/how-to-get-started-with-vibe-coding/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "2wIHY9CfGidc5XlcH2pzXd",
								"displayText": "How to manage AI agents",
								"url": "/learning/ai/how-to-manage-ai-agents-for-businesses/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1KBcXvOgvGeMVpRGJQb03j",
								"displayText": "How to block AI crawlers",
								"url": "/learning/ai/how-to-block-ai-crawlers/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "Y9Tc8MMXjnajQIbDnrg74",
								"displayText": "How to prevent scraping",
								"url": "/learning/ai/how-to-prevent-web-scraping/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "5KGGCoBgenwdvUomxu9p34",
								"displayText": "How to secure AI systems",
								"url": "/learning/ai/how-to-secure-ai-systems/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6EYLgrBEjKBwQRbu7qpAxu",
								"displayText": "How to secure AI training data",
								"url": "/learning/ai/how-to-secure-training-data-against-ai-data-leaks/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "3K1kMMUXxDtJq3yQJyNs7b",
								"displayText": "Shadow AI",
								"url": "/learning/ai/what-is-shadow-ai/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6xy4UeqPN2cEgZ5ALiqvTs",
								"displayText": "Prompt injection",
								"url": "/learning/ai/prompt-injection/"
							}
						]
					},
					"column5Title": "Learning Center",
					"column5": {
						"contentTypeId": "learningCenterArticleLinkedList",
						"contentfulId": "5kj4ISBExxQfI9CaYifpU9",
						"name": "AI Learning Center footer",
						"displayText": "Learning Center Navigation",
						"links": [
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1yItw6W6SsM2Y0Wuq6Y2c6",
								"displayText": "Security Learning Center",
								"url": "/learning/security/what-is-web-application-security/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6DGcnYIMM0eCGwqAKu2ECO",
								"displayText": "CDN Learning Center",
								"url": "/learning/cdn/what-is-a-cdn/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "56Y6OytBNgNoNDWQL2ezlf",
								"displayText": "DDoS Learning Center",
								"url": "/learning/ddos/what-is-a-ddos-attack/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "4Ra0qmFJ1uewk2MYscW8KI",
								"displayText": "What is DNS Learning Center",
								"url": "/learning/dns/what-is-dns/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "Q67XLnKqKhfmDJR4q9hJT",
								"displayText": "Performance Learning Center",
								"url": "/learning/performance/why-site-speed-matters/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "1z3UC9tP1Kjk85BX5zSGPY",
								"displayText": "Serverless Learning Center",
								"url": "/learning/serverless/what-is-serverless/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "52V7iI9YriJ0En2SGmEXz5",
								"displayText": "SSL Learning Center",
								"url": "/learning/ssl/what-is-ssl/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7D22pOfjb98KXcnAJyJFCX",
								"displayText": "Bots Learning Center",
								"url": "/learning/bots/what-is-a-bot/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "7jgqDUFFzaLuKrsaBTLdV0",
								"displayText": "Cloud Learning Center",
								"url": "/learning/cloud/what-is-the-cloud/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6PdBQjiFs98K6RQuG5TYNd",
								"displayText": "Access Management Learning Center",
								"url": "/learning/access-management/what-is-identity-and-access-management/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "3jjEMuuLrCwhRidjG5kglM",
								"displayText": "Network Layer Learning Center",
								"url": "/learning/network-layer/what-is-the-network-layer/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "6RvS0l0m86G1VISDrEvlJb",
								"displayText": "Privacy Learning Center",
								"url": "/learning/privacy/what-is-data-privacy/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "MytksT5WU5mh863BQYEkj",
								"displayText": "Video Streaming Learning Center",
								"url": "/learning/video/what-is-streaming/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "5ysNN6LRvlvlFj4ekk2xq4",
								"displayText": "Email Security Learning Center",
								"url": "/learning/email-security/what-is-email-security/"
							},
							{
								"contentTypeId": "learningCenterArticleLink",
								"contentfulId": "2hdSVoYA5asSIG0U2ae20c",
								"displayText": "Learning Center Home",
								"url": "/learning/"
							}
						]
					}
				},
				"header": "What is shadow AI?",
				"blurbSubHeader": "Shadow artificial intelligence (AI) is the nonsanctioned usage or integration of AI by employees and contractors at an organization. Shadow AI can expose organizations to unknown security risks.",
				"objectivesHeader": "Shadow AI",
				"objectivesList": [
					"Define shadow AI and compare with shadow IT",
					"Explain the main security risks associated with shadow AI",
					"Know how to detect shadow AI"
				],
				"relatedContentLinkText": "Related Content",
				"relatedContent": [
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "7HZD3CNwacCcZXLQxHtX8k",
						"displayText": "What is artificial intelligence (AI)?",
						"url": "/learning/ai/what-is-artificial-intelligence/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "28O79uvws5OhhzxUUPMr8z",
						"displayText": "AI data poisoning",
						"url": "/learning/ai/data-poisoning/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "qwHqeq4VedN29rZ0SP2dw",
						"displayText": "Security for AI",
						"url": "/learning/ai/what-is-ai-security/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "6EYLgrBEjKBwQRbu7qpAxu",
						"displayText": "How to secure AI training data",
						"url": "/learning/ai/how-to-secure-training-data-against-ai-data-leaks/"
					},
					{
						"contentTypeId": "learningCenterArticleLink",
						"contentfulId": "7lSEVfyAjPWCZDHNj1v27k",
						"displayText": "What is a large language model (LLM)?",
						"url": "/learning/ai/what-is-large-language-model/"
					}
				],
				"enablementBlade": null,
				"desktopMainContent": "<h2 class=\"learning-content-h2 learning-content-h2--margin-top-16px\" itemprop=\"headline\">What is shadow AI?</h2>\n\n<p>\"Shadow AI\" refers to the unauthorized and untracked use of <a href='/learning/ai/what-is-artificial-intelligence/'>artificial intelligence (AI)</a> by members of an organization. Shadow AI can be a security problem because it expands the organization's attack surface without security teams being aware, and because it increases the chances of a <a href='/learning/security/what-is-a-data-breach/'>data leak</a>, depending on what information those AI models can access.</p>\n\n<p>Shadow AI can also hinder an organization's overall strategic goals. The use of AI tools not optimized with internal data via <a href='/learning/ai/retrieval-augmented-generation-rag/'>retrieval-augmented generation (RAG)</a> may provide suboptimal responses for the business. For example, a report produced by an AI tool that lacks crucial context about a business's position in the market may provide unrealistic or unhelpful recommendations.</p>\n\n<p>Shadow AI is extremely common. Employees looking to boost their productivity adopt AI tools often without regard for their approval, or even knowing that they are exposing their organization to risks. Some studies have found dozens of unauthorized AI tools in live use even at heavily locked-down companies. Fortunately there are steps organizations can take to reduce risks while enabling employees to take advantage of these uniquely powerful tools.</p>\n\n<h4 class=\"learning-content-h4\">Two types of shadow AI</h4>\n\n<p>There are two main categories of shadow AI usage:</p>\n\n<ol class=\"learning-list\">\n  <li>Unsanctioned usage of AI apps</li>\n  <li>Unprotected AI endpoints integrated into public applications</li>\n</ol>\n\n<p>The former involves employees and contractors incorporating AI usage into their ordinary workflows. For instance, a member of the marketing department might upload a database of prospect information to an <a href='/learning/ai/what-is-large-language-model/'>LLM</a> like ChatGPT and ask for a report, unaware that doing so might constitute a security breach.</p>\n\n<p>The latter involves developers building AI models into public-facing applications without authorization or proper oversight, similar to when <a href='/learning/security/api/what-is-shadow-api/'>shadow API</a> endpoints are built into applications. Imagine a developer using ChatGPT to power an official company <a href='/learning/bots/what-is-a-chatbot/'>chatbot</a> without approval. While OpenAI itself embeds security and content guardrails in their models, the chatbot may still behave in ways the organization does not anticipate, such as by recommending the products of a competitor.</p>\n\n<h4 class=\"learning-content-h4\">Shadow AI vs. shadow IT</h4>\n\n<p><a href='/learning/access-management/what-is-shadow-it/'>Shadow IT</a> refers to unsanctioned or unmanaged technology use, especially of SaaS apps.  Shadow IT involves both the use of non-approved tools, and accessing approved tools in a non-approved manner (an example of the latter would be logging into an official work tool through a personal account).</p>\n\n<p>Many software tools are cheap or free, readily available over the Internet, and beneficial for productivity. Employees therefore may go around official channels if a tool can help them work faster, or if long legal approval processes prevent them from adopting the tools they think they need.</p>\n\n<p>Shadow AI is a type of shadow IT, but a fast-growing one, even more attractive to employees and contractors because of the quick productivity enhancements it promises.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What are the risks of unsanctioned AI usage?</h2>\n\n<p>There are two principal risks when employees and contractors use shadow AI tools:</p>\n\n<ul class=\"learning-list\">\n  <li>An enlarged attack surface</li>\n  <li>Exposure of sensitive data</li>\n</ul>\n\n<p>The totality of potential entry points available to an attacker is called an <a href='/learning/security/glossary/attack-vector/'>attack surface</a>. The attack surface cannot be defended if security teams do not know its full extent. AI tools, like any applications, have their security risks and vulnerabilities. Using them to process internal data, or integrating them into software stacks and business processes, therefore <a href='/learning/security/what-is-a-supply-chain-attack/'>exposes the organization to those vulnerabilities</a>.</p>\n\n<p>This is of less concern when security teams know what and where the risks are — however, if an AI tool is adopted without their knowledge, they cannot secure it. Imagine a bank vault with a back door that an employee has added, that connects straight from their office to the vault, added so the employee can streamline work processes. The security guards do not know about the second door. Because they do not know about the door, the security team cannot guard the door nor add any locks. Unauthorized use of any technologies, including AI tools, is like adding more unprotected doors to the company's vault of data, expanding the attack surface.</p>\n\n<p>Sensitive data exposure is the other big risk. Sensitive data can include intellectual property, customer data, or <a href='/learning/privacy/what-is-personal-information/'>personal employee data</a>. Employees may upload such data into AI tools for work tasks, and — especially if the tools are unmanaged — that data may be exposed to other users of the tools who are not part of the organization. Even if the data is not exposed directly to other users, it may live in that AI tool's database, which can expose the data if there is a data breach, expose it to external parties, or put an organization out of <a href='/learning/privacy/what-is-data-compliance/'>compliance</a> with data security and privacy regulations.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What are the risks of integrating shadow AI into apps?</h2>\n\n<p>AI models can be integrated into application infrastructure via API. In such a construction, the main application, when it runs, sends an API call to an AI tool, which responds with the requested service or data. If this API integration is not monitored or secured, the AI model is considered a shadow AI endpoint.</p>\n\n<p>The risks of shadow AI endpoints include:</p>\n\n<ul class=\"learning-list\">\n  <li><strong>Sensitive data exposure:</strong> Applications could include protected or confidential data in their <a href='/learning/security/api/what-is-api-call/'>API calls</a> to AI models.</li>\n  <li><strong>Model poisoning:</strong> The AI models could contain unknown security risks due to previous <a href='/learning/ai/data-poisoning/'>data poisoning</a> attacks.</li>\n  <li><strong><a href='/learning/ai/prompt-injection/'>Prompt injection</a> or jailbreaking:</strong> AI models might behave differently from expected due to malicious activity.</li>\n  <li><strong>Reputational risk:</strong> A shadow AI model may not have sufficient guardrails in place for protecting an organization's brand and reputation. For instance, a chatbot built with shadow AI integrations might accidentally offer a 100% discount on a product that it is not authorized to give to buyers for free.</li>\n  <li><strong>Lack of documentation:</strong> Because shadow AI integrations may not be properly documented, future updates to the application may not take them into account and could break the application.</li>\n</ul>\n\n<p>Many organizations may want to allow their developers to experiment with AI models during the development process. But discovering and securing shadow AI endpoints is essential for allowing such experiments to proceed safely.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">What is the 'shadow AI economy'?</h2>\n\n<p>The \"shadow AI economy\" is the idea that AI usage in business settings is underreported and undercounted since so many workers use it without permission. As a result, the return on investment (ROI) from corporate AI adoption might be higher than the \"official\" number.</p>\n\n<h2 class=\"learning-content-h2\" itemprop=\"headline\">How to detect shadow AI</h2>\n\n<p>Security teams can attempt to detect shadow AI tool usage with similar methods for detecting other unauthorized application use. They can monitor network traffic at the application layer with application awareness, an ability offered by <a href='/learning/security/what-is-next-generation-firewall-ngfw/'>next-generation firewalls (NGFWs)</a> and other security proxy tools. And they can monitor DNS queries using <a href='/learning/access-management/what-is-dns-filtering/'>DNS filtering</a> to see which apps employees are accessing. <a href='/learning/access-management/what-is-a-casb/'>Cloud access security broker (CASB)</a> and <a href='/learning/access-management/what-is-dlp/'>data loss prevention (DLP)</a> capabilities also help restrict where sensitive data can go. See <a href='/ai-security/'>AI Security Suite</a> to learn more.</p>\n\n<p>For unprotected AI endpoints, shadow AI detection is the most efficient option. Cloudflare's Firewall for AI detects all shadow AI endpoints added to apps without the security team's knowledge. Customers can get complete visibility of which LLMs are running, and where. Learn about <a href='/application-services/products/firewall-for-ai/'>Firewall for AI</a>.\n\n<p>&nbsp;</p>\n\n<h2>FAQs</h2>\n<h4>What does the term shadow AI mean in a business context?</h4>\n<p>Shadow AI refers to the use of artificial intelligence tools by employees or contractors without the official authorization or oversight of their organization's IT and security teams. This practice is increasingly common as workers adopt accessible AI tools to quickly improve their productivity or extend the capabilities of public-facing applications.</p>\n\n<h4>How does the unauthorized use of AI impact a company's security?</h4>\n<p>Using unsanctioned AI tools creates unprotected entry points to a company's private data, which expands the total area an attacker can target. Because security teams are unaware of these tools, they cannot implement necessary defenses to protect the information being processed.</p>\n\n<h4>In what ways can shadow AI lead to the exposure of sensitive information?</h4>\n<p>When employees upload intellectual property or customer data into unmanaged AI tools, that information may be stored in an external database or inadvertently shared with other users outside the organization. Such exposure can result in regulatory compliance violations or leave data vulnerable if the AI provider experiences a breach.</p>\n\n<h4>Beyond security vulnerabilities, how can unmanaged AI usage affect business goals?</h4>\n<p>AI tools that are not optimized with a company's internal data may produce suboptimal or unrealistic results because they lack specific context regarding the business's market position.</p>\n\n<h4>What risks are specifically associated with integrating shadow AI into application infrastructure?</h4>\n<p>Integrating AI via unmonitored APIs can lead to risks from model poisoning when the AI contains previously corrupted data, or prompt injection, where malicious activity causes the model to behave unexpectedly. There is also reputational risk; for example, an ungoverned chatbot might mistakenly offer customers unauthorized discounts.</p>\n\n<script type=\"application/ld+json\">\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"FAQPage\",\n  \"mainEntity\": [\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What does the term shadow AI mean in a business context?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Shadow AI refers to the use of artificial intelligence tools by employees or contractors without the official authorization or oversight of their organization's IT and security teams. This practice is increasingly common as workers adopt accessible AI tools to quickly improve their productivity or extend the capabilities of public-facing applications.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"How does the unauthorized use of AI impact a company's security?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Using unsanctioned AI tools creates unprotected entry points to a company's private data, which expands the total area an attacker can target. Because security teams are unaware of these tools, they cannot implement necessary defenses to protect the information being processed.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"In what ways can shadow AI lead to the exposure of sensitive information?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"When employees upload intellectual property or customer data into unmanaged AI tools, that information may be stored in an external database or inadvertently shared with other users outside the organization. Such exposure can result in regulatory compliance violations or leave data vulnerable if the AI provider experiences a breach.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"Beyond security vulnerabilities, how can unmanaged AI usage affect business goals?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"AI tools that are not optimized with a company's internal data may produce suboptimal or unrealistic results because they lack specific context regarding the business's market position.\"\n      }\n    },\n    {\n      \"@type\": \"Question\",\n      \"name\": \"What risks are specifically associated with integrating shadow AI into application infrastructure?\",\n      \"acceptedAnswer\": {\n        \"@type\": \"Answer\",\n        \"text\": \"Integrating AI via unmonitored APIs can lead to risks from model poisoning when the AI contains previously corrupted data, or prompt injection, where malicious activity causes the model to behave unexpectedly. There is also reputational risk; for example, an ungoverned chatbot might mistakenly offer customers unauthorized discounts.\"\n      }\n    }\n  ]\n}\n</script>",
				"availableLocales": null,
				"localized": null,
				"localeList": {
					"enUS": "English for Locale",
					"zhCN": "Translated for Locale",
					"zhTW": "Translated for Locale",
					"frFR": "Translated for Locale",
					"deDE": "Translated for Locale",
					"itIT": "Translated for Locale",
					"jaJP": "Translated for Locale",
					"koKR": "Translated for Locale",
					"ptBR": "Translated for Locale",
					"esES": "Translated for Locale",
					"esLA": "Translated for Locale",
					"enAU": "English for Locale",
					"enCA": "English for Locale",
					"enIN": "English for Locale",
					"enGB": "English for Locale",
					"nlNL": "English for Locale",
					"idID": "English for Locale",
					"thTH": "English for Locale",
					"ruRU": "English for Locale",
					"svSE": "English for Locale",
					"viVN": "English for Locale",
					"trTR": "English for Locale",
					"zhHansCN": "Translated for Locale",
					"plPL": "English for Locale"
				},
				"proactivePopup": null,
				"sidebarForm": null
			}
		},
		"pageContext": {
			"locale": "en-US",
			"contentfulId": "6PwAimyQPxSH1FIt89O7Ay",
			"pathname": "/learning/ai/what-is-shadow-ai/",
			"baseURL": "https://www.cloudflare.com",
			"allowedHrefLangs": [
				"en-US",
				"zh-CN",
				"zh-TW",
				"fr-FR",
				"de-DE",
				"it-IT",
				"ja-JP",
				"ko-KR",
				"pt-BR",
				"es-ES",
				"es-LA",
				"zh-Hans-CN"
			]
		}
	}
}