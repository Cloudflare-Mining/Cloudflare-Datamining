{
	"models": [
		{
			"id": "fe8904cf-e20e-4884-b829-ed7cec0a01cb",
			"source": 1,
			"name": "@cf/pipecat-ai/smart-turn-v2",
			"description": "An open source, community-driven, native audio turn detection model in 2nd version",
			"task": {
				"id": "ccb1ca5a-043d-41a7-8a3b-61017b2796fd",
				"name": "Dumb Pipe",
				"description": "Internal - Dumb Pipe models don't use tensors"
			},
			"created_at": "2025-08-04 10:08:04.219",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per audio minute",
							"price": 0.00034,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "realtime",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"properties": {
								"audio": {
									"type": "object",
									"description": "readable stream with audio data and content-type specified for that data",
									"properties": {
										"body": {
											"type": "object"
										},
										"contentType": {
											"type": "string"
										}
									},
									"required": [
										"body",
										"contentType"
									]
								},
								"dtype": {
									"type": "string",
									"description": "type of data PCM data that's sent to the inference server as raw array",
									"enum": [
										"uint8",
										"float32",
										"float64"
									]
								}
							},
							"required": [
								"audio"
							]
						},
						{
							"properties": {
								"audio": {
									"type": "string",
									"description": "base64 encoded audio data"
								},
								"dtype": {
									"type": "string",
									"description": "type of data PCM data that's sent to the inference server as raw array",
									"enum": [
										"uint8",
										"float32",
										"float64"
									]
								}
							},
							"required": [
								"audio"
							]
						}
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"is_complete": {
							"type": "boolean",
							"description": "if true, end-of-turn was detected"
						},
						"probability": {
							"type": "number",
							"description": "probability of the end-of-turn detection"
						}
					}
				}
			}
		},
		{
			"id": "f9f2250b-1048-4a52-9910-d0bf976616a1",
			"source": 1,
			"name": "@cf/openai/gpt-oss-120b",
			"description": "OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases – gpt-oss-120b is for production, general purpose, high reasoning use-cases.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-08-05 10:27:29.131",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "128000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.35,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.75,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"oneOf": [
						{
							"type": "object",
							"title": "GPT_OSS_120B_Responses",
							"properties": {
								"input": {
									"anyOf": [
										{
											"type": "string"
										},
										{
											"items": {},
											"type": "array"
										}
									],
									"description": "Responses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types"
								},
								"reasoning": {
									"type": "object",
									"properties": {
										"effort": {
											"type": "string",
											"description": "Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",
											"enum": [
												"low",
												"medium",
												"high"
											]
										},
										"summary": {
											"type": "string",
											"description": "A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.",
											"enum": [
												"auto",
												"concise",
												"detailed"
											]
										}
									}
								}
							},
							"required": [
								"input"
							]
						},
						{
							"type": "object",
							"title": "GPT_OSS_120B_Responses_Async",
							"properties": {
								"requests": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"input": {
												"anyOf": [
													{
														"type": "string"
													},
													{
														"items": {},
														"type": "array"
													}
												],
												"description": "Responses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types"
											},
											"reasoning": {
												"type": "object",
												"properties": {
													"effort": {
														"type": "string",
														"description": "Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",
														"enum": [
															"low",
															"medium",
															"high"
														]
													},
													"summary": {
														"type": "string",
														"description": "A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.",
														"enum": [
															"auto",
															"concise",
															"detailed"
														]
													}
												}
											}
										},
										"required": [
											"input"
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json"
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "f8703a00-ed54-4f98-bdc3-cd9a813286f3",
			"source": 1,
			"name": "@cf/qwen/qwen1.5-0.5b-chat",
			"description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:23:37.344",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "32000"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/qwen/qwen1.5-0.5b-chat"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "eed32bc1-8775-4985-89ce-dd1405508ad8",
			"source": 1,
			"name": "@cf/baai/bge-m3",
			"description": "Multi-Functionality, Multi-Linguality, and Multi-Granularity embeddings model.",
			"task": {
				"id": "0137cdcf-162a-4108-94f2-1ca59e8c65ee",
				"name": "Text Embeddings",
				"description": "Feature extraction models transform raw data into numerical features that can be processed while preserving the information in the original dataset. These models are ideal as part of building vector search applications or Retrieval Augmented Generation workflows with Large Language Models (LLM)."
			},
			"created_at": "2024-05-22 19:27:09.781",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "60000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.012,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "BGE M3 Input Query and Contexts",
							"properties": {
								"query": {
									"type": "string",
									"minLength": 1,
									"description": "A query you wish to perform against the provided contexts. If no query is provided the model with respond with embeddings for contexts"
								},
								"contexts": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"text": {
												"type": "string",
												"minLength": 1,
												"description": "One of the provided context content"
											}
										}
									},
									"description": "List of provided contexts. Note that the index in this array is important, as the response will refer to it."
								},
								"truncate_inputs": {
									"type": "boolean",
									"default": false,
									"description": "When provided with too long context should the model error out or truncate the context to fit?"
								}
							},
							"required": [
								"contexts"
							]
						},
						{
							"title": "BGE M3 Input Embedding",
							"properties": {
								"text": {
									"oneOf": [
										{
											"type": "string",
											"description": "The text to embed",
											"minLength": 1
										},
										{
											"type": "array",
											"description": "Batch of text values to embed",
											"items": {
												"type": "string",
												"description": "The text to embed",
												"minLength": 1
											},
											"maxItems": 100
										}
									]
								},
								"truncate_inputs": {
									"type": "boolean",
									"default": false,
									"description": "When provided with too long context should the model error out or truncate the context to fit?"
								}
							},
							"required": [
								"text"
							]
						},
						{
							"properties": {
								"requests": {
									"type": "array",
									"description": "Batch of the embeddings requests to run using async-queue",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"title": "BGE M3 Input Query and Contexts",
												"properties": {
													"query": {
														"type": "string",
														"minLength": 1,
														"description": "A query you wish to perform against the provided contexts. If no query is provided the model with respond with embeddings for contexts"
													},
													"contexts": {
														"type": "array",
														"items": {
															"type": "object",
															"properties": {
																"text": {
																	"type": "string",
																	"minLength": 1,
																	"description": "One of the provided context content"
																}
															}
														},
														"description": "List of provided contexts. Note that the index in this array is important, as the response will refer to it."
													},
													"truncate_inputs": {
														"type": "boolean",
														"default": false,
														"description": "When provided with too long context should the model error out or truncate the context to fit?"
													}
												},
												"required": [
													"contexts"
												]
											},
											{
												"title": "BGE M3 Input Embedding",
												"properties": {
													"text": {
														"oneOf": [
															{
																"type": "string",
																"description": "The text to embed",
																"minLength": 1
															},
															{
																"type": "array",
																"description": "Batch of text values to embed",
																"items": {
																	"type": "string",
																	"description": "The text to embed",
																	"minLength": 1
																},
																"maxItems": 100
															}
														]
													},
													"truncate_inputs": {
														"type": "boolean",
														"default": false,
														"description": "When provided with too long context should the model error out or truncate the context to fit?"
													}
												},
												"required": [
													"text"
												]
											}
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"oneOf": [
						{
							"title": "BGE M3 Ouput Query",
							"properties": {
								"response": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"id": {
												"type": "integer",
												"description": "Index of the context in the request"
											},
											"score": {
												"type": "number",
												"description": "Score of the context under the index."
											}
										}
									}
								}
							}
						},
						{
							"title": "BGE M3 Output Embedding for Contexts",
							"properties": {
								"response": {
									"type": "array",
									"items": {
										"type": "array",
										"items": {
											"type": "number"
										}
									}
								},
								"shape": {
									"type": "array",
									"items": {
										"type": "number"
									}
								},
								"pooling": {
									"type": "string",
									"enum": [
										"mean",
										"cls"
									],
									"description": "The pooling method used in the embedding process."
								}
							}
						},
						{
							"title": "BGE M3 Ouput Embedding",
							"properties": {
								"shape": {
									"type": "array",
									"items": {
										"type": "number"
									}
								},
								"data": {
									"type": "array",
									"description": "Embeddings of the requested text values",
									"items": {
										"type": "array",
										"description": "Floating point embedding representation shaped by the embedding model",
										"items": {
											"type": "number"
										}
									}
								},
								"pooling": {
									"type": "string",
									"enum": [
										"mean",
										"cls"
									],
									"description": "The pooling method used in the embedding process."
								}
							}
						},
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Async response",
							"properties": {
								"request_id": {
									"type": "string",
									"description": "The async request id that can be used to obtain the results."
								}
							}
						}
					]
				}
			}
		},
		{
			"id": "eaf31752-a074-441f-8b70-d593255d2811",
			"source": 1,
			"name": "@cf/huggingface/distilbert-sst-2-int8",
			"description": "Distilled BERT model that was finetuned on SST-2 for sentiment classification",
			"task": {
				"id": "19606750-23ed-4371-aab2-c20349b53a60",
				"name": "Text Classification",
				"description": "Sentiment analysis or text classification is a common NLP task that classifies a text input into labels or classes."
			},
			"created_at": "2023-09-25 19:21:11.898",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.026,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/Intel/distilbert-base-uncased-finetuned-sst-2-english-int8-static"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"text": {
							"type": "string",
							"minLength": 1,
							"description": "The text that you want to classify"
						}
					},
					"required": [
						"text"
					]
				},
				"output": {
					"type": "array",
					"contentType": "application/json",
					"description": "An array of classification results for the input text",
					"items": {
						"type": "object",
						"properties": {
							"score": {
								"type": "number",
								"description": "Confidence score indicating the likelihood that the text belongs to the specified label"
							},
							"label": {
								"type": "string",
								"description": "The classification label assigned to the text (e.g., 'POSITIVE' or 'NEGATIVE')"
							}
						}
					}
				}
			}
		},
		{
			"id": "e8e8abe4-a372-4c13-815f-4688ba655c8e",
			"source": 1,
			"name": "@cf/google/gemma-2b-it-lora",
			"description": "This is a Gemma-2B base model that Cloudflare dedicates for inference with LoRA adapters. Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-02 00:19:34.669",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "8192"
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "e5ca943b-720f-4e66-aa8f-40e3d2770933",
			"source": 2,
			"name": "@hf/nexusflow/starling-lm-7b-beta",
			"description": "We introduce Starling-LM-7B-beta, an open large language model (LLM) trained by Reinforcement Learning from AI Feedback (RLAIF). Starling-LM-7B-beta is trained from Openchat-3.5-0106 with our new reward model Nexusflow/Starling-RM-34B and policy optimization method Fine-Tuning Language Models from Human Preferences (PPO).",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-01 23:49:31.797",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/Nexusflow/Starling-LM-7B-beta"
				},
				{
					"property_id": "max_batch_prefill_tokens",
					"value": "8192"
				},
				{
					"property_id": "max_input_length",
					"value": "3072"
				},
				{
					"property_id": "max_total_tokens",
					"value": "4096"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "e11d8f45-7b08-499a-9eeb-71d4d3c8cbf9",
			"source": 1,
			"name": "@cf/meta/llama-3-8b-instruct",
			"description": "Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-18 20:31:47.273",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.28,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.83,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "context_window",
					"value": "7968"
				},
				{
					"property_id": "info",
					"value": "https://llama.meta.com"
				},
				{
					"property_id": "terms",
					"value": "https://llama.meta.com/llama3/license/#"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "d9dc8363-66f4-4bb0-8641-464ee7bfc131",
			"source": 1,
			"name": "@cf/meta/llama-3.2-3b-instruct",
			"description": "The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-09-25 20:05:43.986",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.051,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.34,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "context_window",
					"value": "128000"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "d9b7a55c-cefa-4208-8ab3-11497a2b046c",
			"source": 2,
			"name": "@hf/thebloke/llamaguard-7b-awq",
			"description": "Llama Guard is a model for classifying the safety of LLM prompts and responses, using a taxonomy of safety risks.\n",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-06 18:13:59.060",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "d2ba5c6b-bbb7-49d6-b466-900654870cd6",
			"source": 2,
			"name": "@hf/thebloke/neural-chat-7b-v3-1-awq",
			"description": "This model is a fine-tuned 7B parameter LLM on the Intel Gaudi 2 processor from the mistralai/Mistral-7B-v0.1 on the open source dataset Open-Orca/SlimOrca.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-06 18:12:30.722",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "cc80437b-9a8d-4f1a-9c77-9aaf0d226922",
			"source": 1,
			"name": "@cf/meta/llama-guard-3-8b",
			"description": "Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM – it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-01-22 23:26:23.495",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.48,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.03,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"messages": {
							"type": "array",
							"description": "An array of message objects representing the conversation history.",
							"items": {
								"type": "object",
								"properties": {
									"role": {
										"enum": [
											"user",
											"assistant"
										],
										"description": "The role of the message sender must alternate between 'user' and 'assistant'."
									},
									"content": {
										"type": "string",
										"description": "The content of the message as a string."
									}
								},
								"required": [
									"role",
									"content"
								]
							}
						},
						"max_tokens": {
							"type": "integer",
							"default": 256,
							"description": "The maximum number of tokens to generate in the response."
						},
						"temperature": {
							"type": "number",
							"default": 0.6,
							"minimum": 0,
							"maximum": 5,
							"description": "Controls the randomness of the output; higher values produce more random results."
						},
						"response_format": {
							"type": "object",
							"description": "Dictate the output format of the generated response.",
							"properties": {
								"type": {
									"type": "string",
									"description": "Set to json_object to process and output generated text as JSON."
								}
							}
						}
					},
					"required": [
						"messages"
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"response": {
							"oneOf": [
								{
									"type": "string",
									"description": "The generated text response from the model."
								},
								{
									"type": "object",
									"description": "The json response parsed from the generated text response from the model.",
									"properties": {
										"safe": {
											"type": "boolean",
											"description": "Whether the conversation is safe or not."
										},
										"categories": {
											"type": "array",
											"description": "A list of what hazard categories predicted for the conversation, if the conversation is deemed unsafe.",
											"items": {
												"type": "string",
												"description": "Hazard category classname, from S1 to S14."
											}
										}
									}
								}
							]
						},
						"usage": {
							"type": "object",
							"description": "Usage statistics for the inference request",
							"properties": {
								"prompt_tokens": {
									"type": "number",
									"description": "Total number of tokens in input",
									"default": 0
								},
								"completion_tokens": {
									"type": "number",
									"description": "Total number of tokens in output",
									"default": 0
								},
								"total_tokens": {
									"type": "number",
									"description": "Total number of input and output tokens",
									"default": 0
								}
							}
						}
					}
				}
			}
		},
		{
			"id": "ca54bcd6-0d98-4739-9b3b-5c8b4402193d",
			"source": 1,
			"name": "@cf/meta/llama-2-7b-chat-fp16",
			"description": "Full precision (fp16) generative text model with 7 billion parameters from Meta",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2023-11-07 11:54:20.229",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.56,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 6.67,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "info",
					"value": "https://ai.meta.com/llama/"
				},
				{
					"property_id": "terms",
					"value": "https://ai.meta.com/resources/models-and-libraries/llama-downloads/"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "c907d0f9-d69d-4e93-b501-4daeb4fd69eb",
			"source": 1,
			"name": "@cf/mistral/mistral-7b-instruct-v0.1",
			"description": "Instruct fine-tuned version of the Mistral-7b generative text model with 7 billion parameters",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2023-11-07 11:54:20.229",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.11,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.19,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "context_window",
					"value": "2824"
				},
				{
					"property_id": "info",
					"value": "https://mistral.ai/news/announcing-mistral-7b/"
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "c837b2ac-4d9b-4d37-8811-34de60f0c44f",
			"source": 1,
			"name": "@cf/myshell-ai/melotts",
			"description": "MeloTTS is a high-quality multi-lingual text-to-speech library by MyShell.ai.",
			"task": {
				"id": "b52660a1-9a95-4ab2-8b1d-f232be34604a",
				"name": "Text-to-Speech",
				"description": "Text-to-Speech (TTS) is the task of generating natural sounding speech given text input. TTS models can be extended to have a single model that generates speech for multiple speakers and multiple languages."
			},
			"created_at": "2024-07-19 15:51:04.819",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per audio minute",
							"price": 0.0002,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"description": "A text description of the audio you want to generate"
						},
						"lang": {
							"type": "string",
							"default": "en",
							"description": "The speech language (e.g., 'en' for English, 'fr' for French). Defaults to 'en' if not specified"
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"audio": {
									"type": "string",
									"description": "The generated audio in MP3 format, base64-encoded"
								}
							}
						},
						{
							"type": "string",
							"contentType": "audio/mpeg",
							"format": "binary",
							"description": "The generated audio in MP3 format"
						}
					]
				}
			}
		},
		{
			"id": "c58c317b-0c15-4bda-abb6-93e275f282d9",
			"source": 1,
			"name": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
			"description": "The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.2.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-01 22:14:40.529",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "15000"
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "c1c12ce4-c36a-4aa6-8da4-f63ba4b8984d",
			"source": 1,
			"name": "@cf/openai/whisper",
			"description": "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.",
			"task": {
				"id": "dfce1c48-2a81-462e-a7fd-de97ce985207",
				"name": "Automatic Speech Recognition",
				"description": "Automatic speech recognition (ASR) models convert a speech signal, typically an audio input, to text."
			},
			"created_at": "2023-09-25 19:21:11.898",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per audio minute",
							"price": 0.00045,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://openai.com/research/whisper"
				}
			],
			"schema": {
				"input": {
					"oneOf": [
						{
							"type": "string",
							"format": "binary"
						},
						{
							"type": "object",
							"properties": {
								"audio": {
									"type": "array",
									"description": "An array of integers that represent the audio data constrained to 8-bit unsigned integer values",
									"items": {
										"type": "number",
										"description": "A value between 0 and 255"
									}
								}
							},
							"required": [
								"audio"
							]
						}
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"text": {
							"type": "string",
							"description": "The transcription"
						},
						"word_count": {
							"type": "number"
						},
						"words": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"word": {
										"type": "string"
									},
									"start": {
										"type": "number",
										"description": "The second this word begins in the recording"
									},
									"end": {
										"type": "number",
										"description": "The ending second when the word completes"
									}
								}
							}
						},
						"vtt": {
							"type": "string"
						}
					},
					"required": [
						"text"
					]
				}
			}
		},
		{
			"id": "bf6ddd21-6477-4681-bbbe-24c3d5423e78",
			"source": 1,
			"name": "@cf/tinyllama/tinyllama-1.1b-chat-v1.0",
			"description": "The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens. This is the chat model finetuned on top of TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:25:37.524",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "2048"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "bc2b61f6-7eb3-4cdf-94f5-ffc128bd6aa4",
			"source": 1,
			"name": "@cf/pfnet/plamo-embedding-1b",
			"description": "PLaMo-Embedding-1B is a Japanese text embedding model developed by Preferred Networks, Inc.\n\nIt can convert Japanese text input into numerical vectors and can be used for a wide range of applications, including information retrieval, text classification, and clustering.",
			"task": {
				"id": "0137cdcf-162a-4108-94f2-1ca59e8c65ee",
				"name": "Text Embeddings",
				"description": "Feature extraction models transform raw data into numerical features that can be processed while preserving the information in the original dataset. These models are ideal as part of building vector search applications or Retrieval Augmented Generation workflows with Large Language Models (LLM)."
			},
			"created_at": "2025-09-24 18:42:05.576",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.019,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"text": {
							"oneOf": [
								{
									"type": "string"
								},
								{
									"type": "array",
									"items": {
										"type": "string"
									}
								}
							],
							"description": "Input text to embed. Can be a single string or a list of strings."
						}
					},
					"required": [
						"text"
					]
				},
				"output": {
					"type": "object",
					"properties": {
						"data": {
							"type": "array",
							"items": {
								"type": "array",
								"items": {
									"type": "number"
								}
							},
							"description": "Embedding vectors, where each vector is a list of floats."
						},
						"shape": {
							"type": "array",
							"items": {
								"type": "integer"
							},
							"minItems": 2,
							"maxItems": 2,
							"description": "Shape of the embedding data as [number_of_embeddings, embedding_dimension]."
						}
					},
					"required": [
						"data",
						"shape"
					]
				}
			}
		},
		{
			"id": "b97d7069-48d9-461c-80dd-445d20a632eb",
			"source": 2,
			"name": "@hf/mistral/mistral-7b-instruct-v0.2",
			"description": "The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.2. Mistral-7B-v0.2 has the following changes compared to Mistral-7B-v0.1: 32k context window (vs 8k context in v0.1), rope-theta = 1e6, and no Sliding-Window Attention.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-02 13:00:59.244",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "3072"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"
				},
				{
					"property_id": "lora",
					"value": "true"
				},
				{
					"property_id": "max_batch_prefill_tokens",
					"value": "8192"
				},
				{
					"property_id": "max_input_length",
					"value": "3072"
				},
				{
					"property_id": "max_total_tokens",
					"value": "4096"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "b7fe7ad2-aeaf-47d2-8bfa-7a5ae22a2ab4",
			"source": 1,
			"name": "@cf/fblgit/una-cybertron-7b-v2-bf16",
			"description": "Cybertron 7B v2 is a 7B MistralAI based model, best on it's series. It was trained with SFT, DPO and UNA (Unified Neural Alignment) on multiple datasets.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-24 14:37:19.494",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "15000"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "af274959-cb47-4ba8-9d8e-5a0a58b6b402",
			"source": 1,
			"name": "@cf/llava-hf/llava-1.5-7b-hf",
			"description": "LLaVA is an open-source chatbot trained by fine-tuning LLaMA/Vicuna on GPT-generated multimodal instruction-following data. It is an auto-regressive language model, based on the transformer architecture.",
			"task": {
				"id": "882a91d1-c331-4eec-bdad-834c919942a8",
				"name": "Image-to-Text",
				"description": "Image to text models output a text from a given image. Image captioning or optical character recognition can be considered as the most common applications of image to text."
			},
			"created_at": "2024-05-01 18:00:39.971",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"oneOf": [
						{
							"type": "string",
							"format": "binary",
							"description": "Binary string representing the image contents."
						},
						{
							"type": "object",
							"properties": {
								"image": {
									"oneOf": [
										{
											"type": "array",
											"description": "An array of integers that represent the image data constrained to 8-bit unsigned integer values",
											"items": {
												"type": "number",
												"description": "A value between 0 and 255"
											}
										},
										{
											"type": "string",
											"format": "binary",
											"description": "Binary string representing the image contents."
										}
									]
								},
								"temperature": {
									"type": "number",
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"prompt": {
									"type": "string",
									"description": "The input text prompt for the model to generate a response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"top_p": {
									"type": "number",
									"description": "Controls the creativity of the AI's responses by adjusting how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "number",
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "number",
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"description": "Increases the likelihood of the model introducing new topics."
								},
								"max_tokens": {
									"type": "integer",
									"default": 512,
									"description": "The maximum number of tokens to generate in the response."
								}
							},
							"required": [
								"image"
							]
						}
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"description": {
							"type": "string"
						}
					}
				}
			}
		},
		{
			"id": "ad01ab83-baf8-4e7b-8fed-a0a219d4eb45",
			"source": 1,
			"name": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
			"description": "DeepSeek-R1-Distill-Qwen-32B is a model distilled from DeepSeek-R1 based on Qwen2.5. It outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-01-22 19:48:55.776",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "80000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.5,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 4.88,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "terms",
					"value": "https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "a9abaef0-3031-47ad-8790-d311d8684c6c",
			"source": 1,
			"name": "@cf/runwayml/stable-diffusion-v1-5-inpainting",
			"description": "Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask.",
			"task": {
				"id": "3d6e1f35-341b-4915-a6c8-9a7142a9033a",
				"name": "Text-to-Image",
				"description": "Generates images from input text. These models can be used to generate and modify images based on text prompts."
			},
			"created_at": "2024-02-27 17:23:57.528",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per step",
							"price": 0,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/runwayml/stable-diffusion-inpainting"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/runwayml/stable-diffusion/blob/main/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"description": "A text description of the image you want to generate"
						},
						"negative_prompt": {
							"type": "string",
							"description": "Text describing elements to avoid in the generated image"
						},
						"height": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The height of the generated image in pixels"
						},
						"width": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The width of the generated image in pixels"
						},
						"image": {
							"type": "array",
							"description": "For use with img2img tasks. An array of integers that represent the image data constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"image_b64": {
							"type": "string",
							"description": "For use with img2img tasks. A base64-encoded string of the input image"
						},
						"mask": {
							"type": "array",
							"description": "An array representing An array of integers that represent mask image data for inpainting constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"num_steps": {
							"type": "integer",
							"default": 20,
							"maximum": 20,
							"description": "The number of diffusion steps; higher values can improve quality but take longer"
						},
						"strength": {
							"type": "number",
							"default": 1,
							"description": "A value between 0 and 1 indicating how strongly to apply the transformation during img2img tasks; lower values make the output closer to the input image"
						},
						"guidance": {
							"type": "number",
							"default": 7.5,
							"description": "Controls how closely the generated image should adhere to the prompt; higher values make the image more aligned with the prompt"
						},
						"seed": {
							"type": "integer",
							"description": "Random seed for reproducibility of the image generation"
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"type": "string",
					"contentType": "image/png",
					"format": "binary",
					"description": "The generated image in PNG format"
				}
			}
		},
		{
			"id": "a2a2afba-b609-4325-8c41-5791ce962239",
			"source": 1,
			"name": "@cf/deepgram/flux",
			"description": "Flux is the first conversational speech recognition model built specifically for voice agents.",
			"task": {
				"id": "dfce1c48-2a81-462e-a7fd-de97ce985207",
				"name": "Automatic Speech Recognition",
				"description": "Automatic speech recognition (ASR) models convert a speech signal, typically an audio input, to text."
			},
			"created_at": "2025-09-29 21:07:55.114",
			"tags": [],
			"properties": [
				{
					"property_id": "partner",
					"value": "true"
				},
				{
					"property_id": "realtime",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"encoding": {
							"type": "string",
							"description": "Encoding of the audio stream. Currently only supports raw signed little-endian 16-bit PCM.",
							"enum": [
								"linear16"
							]
						},
						"sample_rate": {
							"type": "string",
							"description": "Sample rate of the audio stream in Hz.",
							"pattern": "^[0-9]+$"
						},
						"eager_eot_threshold": {
							"type": "string",
							"description": "End-of-turn confidence required to fire an eager end-of-turn event. When set, enables EagerEndOfTurn and TurnResumed events. Valid Values 0.3 - 0.9."
						},
						"eot_threshold": {
							"type": "string",
							"description": "End-of-turn confidence required to finish a turn. Valid Values 0.5 - 0.9.",
							"default": "0.7"
						},
						"eot_timeout_ms": {
							"type": "string",
							"description": "A turn will be finished when this much time has passed after speech, regardless of EOT confidence.",
							"default": "5000",
							"pattern": "^[0-9]+$"
						},
						"keyterm": {
							"type": "string",
							"description": "Keyterm prompting can improve recognition of specialized terminology. Pass multiple keyterm query parameters to boost multiple keyterms."
						},
						"mip_opt_out": {
							"type": "string",
							"description": "Opts out requests from the Deepgram Model Improvement Program. Refer to Deepgram Docs for pricing impacts before setting this to true. https://dpgr.am/deepgram-mip",
							"enum": [
								"true",
								"false"
							],
							"default": "false"
						},
						"tag": {
							"type": "string",
							"description": "Label your requests for the purpose of identification during usage reporting"
						}
					},
					"required": [
						"sample_rate",
						"encoding"
					]
				},
				"output": {
					"type": "object",
					"description": "Output will be returned as websocket messages.",
					"properties": {
						"request_id": {
							"type": "string",
							"description": "The unique identifier of the request (uuid)"
						},
						"sequence_id": {
							"type": "integer",
							"description": "Starts at 0 and increments for each message the server sends to the client.",
							"minimum": 0
						},
						"event": {
							"type": "string",
							"description": "The type of event being reported.",
							"enum": [
								"Update",
								"StartOfTurn",
								"EagerEndOfTurn",
								"TurnResumed",
								"EndOfTurn"
							]
						},
						"turn_index": {
							"type": "integer",
							"description": "The index of the current turn",
							"minimum": 0
						},
						"audio_window_start": {
							"type": "number",
							"description": "Start time in seconds of the audio range that was transcribed"
						},
						"audio_window_end": {
							"type": "number",
							"description": "End time in seconds of the audio range that was transcribed"
						},
						"transcript": {
							"type": "string",
							"description": "Text that was said over the course of the current turn"
						},
						"words": {
							"type": "array",
							"description": "The words in the transcript",
							"items": {
								"type": "object",
								"required": [
									"word",
									"confidence"
								],
								"properties": {
									"word": {
										"type": "string",
										"description": "The individual punctuated, properly-cased word from the transcript"
									},
									"confidence": {
										"type": "number",
										"description": "Confidence that this word was transcribed correctly"
									}
								}
							}
						},
						"end_of_turn_confidence": {
							"type": "number",
							"description": "Confidence that no more speech is coming in this turn"
						}
					}
				}
			}
		},
		{
			"id": "a226909f-eef8-4265-a3a0-90db0422762e",
			"source": 1,
			"name": "@cf/deepgram/nova-3",
			"description": "Transcribe audio using Deepgram’s speech-to-text model",
			"task": {
				"id": "dfce1c48-2a81-462e-a7fd-de97ce985207",
				"name": "Automatic Speech Recognition",
				"description": "Automatic speech recognition (ASR) models convert a speech signal, typically an audio input, to text."
			},
			"created_at": "2025-06-05 16:05:15.199",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per audio minute",
							"price": 0.0052,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "partner",
					"value": "true"
				},
				{
					"property_id": "realtime",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"audio": {
							"type": "object",
							"properties": {
								"body": {
									"type": "object"
								},
								"contentType": {
									"type": "string"
								}
							},
							"required": [
								"body",
								"contentType"
							]
						},
						"custom_topic_mode": {
							"type": "string",
							"enum": [
								"extended",
								"strict"
							],
							"description": "Sets how the model will interpret strings submitted to the custom_topic param. When strict, the model will only return topics submitted using the custom_topic param. When extended, the model will return its own detected topics in addition to those submitted using the custom_topic param."
						},
						"custom_topic": {
							"type": "string",
							"description": "Custom topics you want the model to detect within your input audio or text if present Submit up to 100"
						},
						"custom_intent_mode": {
							"type": "string",
							"description": "Sets how the model will interpret intents submitted to the custom_intent param. When strict, the model will only return intents submitted using the custom_intent param. When extended, the model will return its own detected intents in addition those submitted using the custom_intents param",
							"enum": [
								"extended",
								"strict"
							]
						},
						"custom_intent": {
							"type": "string",
							"description": "Custom intents you want the model to detect within your input audio if present"
						},
						"detect_entities": {
							"type": "boolean",
							"description": "Identifies and extracts key entities from content in submitted audio"
						},
						"detect_language": {
							"type": "boolean",
							"description": "Identifies the dominant language spoken in submitted audio"
						},
						"diarize": {
							"type": "boolean",
							"description": "Recognize speaker changes. Each word in the transcript will be assigned a speaker number starting at 0"
						},
						"dictation": {
							"type": "boolean",
							"description": "Identify and extract key entities from content in submitted audio"
						},
						"encoding": {
							"type": "string",
							"description": "Specify the expected encoding of your submitted audio",
							"enum": [
								"linear16",
								"flac",
								"mulaw",
								"amr-nb",
								"amr-wb",
								"opus",
								"speex",
								"g729"
							]
						},
						"extra": {
							"type": "string",
							"description": "Arbitrary key-value pairs that are attached to the API response for usage in downstream processing"
						},
						"filler_words": {
							"type": "boolean",
							"description": "Filler Words can help transcribe interruptions in your audio, like 'uh' and 'um'"
						},
						"keyterm": {
							"type": "string",
							"description": "Key term prompting can boost or suppress specialized terminology and brands."
						},
						"keywords": {
							"type": "string",
							"description": "Keywords can boost or suppress specialized terminology and brands."
						},
						"language": {
							"type": "string",
							"description": "The BCP-47 language tag that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available."
						},
						"measurements": {
							"type": "boolean",
							"description": "Spoken measurements will be converted to their corresponding abbreviations."
						},
						"mip_opt_out": {
							"type": "boolean",
							"description": "Opts out requests from the Deepgram Model Improvement Program. Refer to our Docs for pricing impacts before setting this to true. https://dpgr.am/deepgram-mip."
						},
						"mode": {
							"type": "string",
							"description": "Mode of operation for the model representing broad area of topic that will be talked about in the supplied audio",
							"enum": [
								"general",
								"medical",
								"finance"
							]
						},
						"multichannel": {
							"type": "boolean",
							"description": "Transcribe each audio channel independently."
						},
						"numerals": {
							"type": "boolean",
							"description": "Numerals converts numbers from written format to numerical format."
						},
						"paragraphs": {
							"type": "boolean",
							"description": "Splits audio into paragraphs to improve transcript readability."
						},
						"profanity_filter": {
							"type": "boolean",
							"description": "Profanity Filter looks for recognized profanity and converts it to the nearest recognized non-profane word or removes it from the transcript completely."
						},
						"punctuate": {
							"type": "boolean",
							"description": "Add punctuation and capitalization to the transcript."
						},
						"redact": {
							"type": "string",
							"description": "Redaction removes sensitive information from your transcripts."
						},
						"replace": {
							"type": "string",
							"description": "Search for terms or phrases in submitted audio and replaces them."
						},
						"search": {
							"type": "string",
							"description": "Search for terms or phrases in submitted audio."
						},
						"sentiment": {
							"type": "boolean",
							"description": "Recognizes the sentiment throughout a transcript or text."
						},
						"smart_format": {
							"type": "boolean",
							"description": "Apply formatting to transcript output. When set to true, additional formatting will be applied to transcripts to improve readability."
						},
						"topics": {
							"type": "boolean",
							"description": "Detect topics throughout a transcript or text."
						},
						"utterances": {
							"type": "boolean",
							"description": "Segments speech into meaningful semantic units."
						},
						"utt_split": {
							"type": "number",
							"description": "Seconds to wait before detecting a pause between words in submitted audio."
						},
						"channels": {
							"type": "number",
							"description": "The number of channels in the submitted audio"
						},
						"interim_results": {
							"type": "boolean",
							"description": "Specifies whether the streaming endpoint should provide ongoing transcription updates as more audio is received. When set to true, the endpoint sends continuous updates, meaning transcription results may evolve over time. Note: Supported only for webosockets."
						},
						"endpointing": {
							"type": "string",
							"description": "Indicates how long model will wait to detect whether a speaker has finished speaking or pauses for a significant period of time. When set to a value, the streaming endpoint immediately finalizes the transcription for the processed time range and returns the transcript with a speech_final parameter set to true. Can also be set to false to disable endpointing"
						},
						"vad_events": {
							"type": "boolean",
							"description": "Indicates that speech has started. You'll begin receiving Speech Started messages upon speech starting. Note: Supported only for webosockets."
						},
						"utterance_end_ms": {
							"type": "boolean",
							"description": "Indicates how long model will wait to send an UtteranceEnd message after a word has been transcribed. Use with interim_results. Note: Supported only for webosockets."
						}
					},
					"required": [
						"audio"
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"results": {
							"type": "object",
							"properties": {
								"channels": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"alternatives": {
												"type": "array",
												"items": {
													"type": "object",
													"properties": {
														"confidence": {
															"type": "number"
														},
														"transcript": {
															"type": "string"
														},
														"words": {
															"type": "array",
															"items": {
																"type": "object",
																"properties": {
																	"confidence": {
																		"type": "number"
																	},
																	"end": {
																		"type": "number"
																	},
																	"start": {
																		"type": "number"
																	},
																	"word": {
																		"type": "string"
																	}
																}
															}
														}
													}
												}
											}
										}
									}
								},
								"summary": {
									"type": "object",
									"properties": {
										"result": {
											"type": "string"
										},
										"short": {
											"type": "string"
										}
									}
								},
								"sentiments": {
									"type": "object",
									"properties": {
										"segments": {
											"type": "array",
											"items": {
												"type": "object",
												"properties": {
													"text": {
														"type": "string"
													},
													"start_word": {
														"type": "number"
													},
													"end_word": {
														"type": "number"
													},
													"sentiment": {
														"type": "string"
													},
													"sentiment_score": {
														"type": "number"
													}
												}
											}
										},
										"average": {
											"type": "object",
											"properties": {
												"sentiment": {
													"type": "string"
												},
												"sentiment_score": {
													"type": "number"
												}
											}
										}
									}
								}
							}
						}
					}
				}
			}
		},
		{
			"id": "9e087485-23dc-47fa-997d-f5bfafc0c7cc",
			"source": 1,
			"name": "@cf/black-forest-labs/flux-1-schnell",
			"description": "FLUX.1 [schnell] is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions. ",
			"task": {
				"id": "3d6e1f35-341b-4915-a6c8-9a7142a9033a",
				"name": "Text-to-Image",
				"description": "Generates images from input text. These models can be used to generate and modify images based on text prompts."
			},
			"created_at": "2024-08-29 16:37:39.541",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per 512 by 512 tile",
							"price": 0.000053,
							"currency": "USD"
						},
						{
							"unit": "per step",
							"price": 0.00011,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"maxLength": 2048,
							"description": "A text description of the image you want to generate."
						},
						"steps": {
							"type": "integer",
							"default": 4,
							"maximum": 8,
							"description": "The number of diffusion steps; higher values can improve quality but take longer."
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"image": {
							"type": "string",
							"description": "The generated image in Base64 format."
						}
					}
				}
			}
		},
		{
			"id": "9d2ab560-065e-4d0d-a789-d4bc7468d33e",
			"source": 1,
			"name": "@cf/thebloke/discolm-german-7b-v1-awq",
			"description": "DiscoLM German 7b is a Mistral-based large language model with a focus on German-language applications. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:23:05.178",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/TheBloke/DiscoLM_German_7b_v1-AWQ"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "9c95c39d-45b3-4163-9631-22f0c0dc3b14",
			"source": 1,
			"name": "@cf/meta/llama-2-7b-chat-int8",
			"description": "Quantized (int8) generative text model with 7 billion parameters from Meta",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2023-09-25 19:21:11.898",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "8192"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "9b9c87c6-d4b7-494c-b177-87feab5904db",
			"source": 1,
			"name": "@cf/meta/llama-3.1-8b-instruct-fp8",
			"description": "Llama 3.1 8B quantized to FP8 precision",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-07-25 17:28:43.328",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.15,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.29,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "context_window",
					"value": "32000"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "980ec5e9-33c2-483a-a2d8-cd092fdf273f",
			"source": 2,
			"name": "@hf/thebloke/mistral-7b-instruct-v0.1-awq",
			"description": "Mistral 7B Instruct v0.1 AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Mistral variant.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2023-11-24 00:27:15.869",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-AWQ"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "90a20ae7-7cf4-4eb3-8672-8fc4ee580635",
			"source": 1,
			"name": "@cf/qwen/qwen1.5-7b-chat-awq",
			"description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:24:11.709",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "20000"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/qwen/qwen1.5-7b-chat-awq"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "906a57fd-b018-4d6c-a43e-a296d4cc5839",
			"source": 1,
			"name": "@cf/meta/llama-3.2-1b-instruct",
			"description": "The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-09-25 21:36:32.050",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.027,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.2,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "context_window",
					"value": "60000"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "85c5a3c6-24b0-45e7-b23a-023182578822",
			"source": 2,
			"name": "@hf/thebloke/llama-2-13b-chat-awq",
			"description": "Llama 2 13B Chat AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Llama 2 variant.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2023-11-24 00:27:15.869",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/TheBloke/Llama-2-13B-chat-AWQ"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "7f9a76e1-d120-48dd-a565-101d328bbb02",
			"source": 1,
			"name": "@cf/microsoft/resnet-50",
			"description": "50 layers deep image classification CNN trained on more than 1M images from ImageNet",
			"task": {
				"id": "00cd182b-bf30-4fc4-8481-84a3ab349657",
				"name": "Image Classification",
				"description": "Image classification models take an image input and assigns it labels or classes."
			},
			"created_at": "2023-09-25 19:21:11.898",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per inference request",
							"price": 0.0000025,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://www.microsoft.com/en-us/research/blog/microsoft-vision-model-resnet-50-combines-web-scale-data-and-multi-task-learning-to-achieve-state-of-the-art/"
				}
			],
			"schema": {
				"input": {
					"oneOf": [
						{
							"type": "string",
							"format": "binary",
							"description": "The image to classify"
						},
						{
							"type": "object",
							"properties": {
								"image": {
									"type": "array",
									"description": "An array of integers that represent the image data constrained to 8-bit unsigned integer values",
									"items": {
										"type": "number",
										"description": "A value between 0 and 255 (unsigned 8bit)"
									}
								}
							},
							"required": [
								"image"
							]
						}
					]
				},
				"output": {
					"type": "array",
					"contentType": "application/json",
					"items": {
						"type": "object",
						"properties": {
							"score": {
								"type": "number",
								"description": "A confidence value, between 0 and 1, indicating how certain the model is about the predicted label"
							},
							"label": {
								"type": "string",
								"description": "The predicted category or class for the input image based on analysis"
							}
						}
					}
				}
			}
		},
		{
			"id": "7f797b20-3eb0-44fd-b571-6cbbaa3c423b",
			"source": 1,
			"name": "@cf/bytedance/stable-diffusion-xl-lightning",
			"description": "SDXL-Lightning is a lightning-fast text-to-image generation model. It can generate high-quality 1024px images in a few steps.",
			"task": {
				"id": "3d6e1f35-341b-4915-a6c8-9a7142a9033a",
				"name": "Text-to-Image",
				"description": "Generates images from input text. These models can be used to generate and modify images based on text prompts."
			},
			"created_at": "2024-02-27 17:41:29.578",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per step",
							"price": 0,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/ByteDance/SDXL-Lightning"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"description": "A text description of the image you want to generate"
						},
						"negative_prompt": {
							"type": "string",
							"description": "Text describing elements to avoid in the generated image"
						},
						"height": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The height of the generated image in pixels"
						},
						"width": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The width of the generated image in pixels"
						},
						"image": {
							"type": "array",
							"description": "For use with img2img tasks. An array of integers that represent the image data constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"image_b64": {
							"type": "string",
							"description": "For use with img2img tasks. A base64-encoded string of the input image"
						},
						"mask": {
							"type": "array",
							"description": "An array representing An array of integers that represent mask image data for inpainting constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"num_steps": {
							"type": "integer",
							"default": 20,
							"maximum": 20,
							"description": "The number of diffusion steps; higher values can improve quality but take longer"
						},
						"strength": {
							"type": "number",
							"default": 1,
							"description": "A value between 0 and 1 indicating how strongly to apply the transformation during img2img tasks; lower values make the output closer to the input image"
						},
						"guidance": {
							"type": "number",
							"default": 7.5,
							"description": "Controls how closely the generated image should adhere to the prompt; higher values make the image more aligned with the prompt"
						},
						"seed": {
							"type": "integer",
							"description": "Random seed for reproducibility of the image generation"
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"type": "string",
					"contentType": "image/png",
					"format": "binary",
					"description": "The generated image in PNG format"
				}
			}
		},
		{
			"id": "7f180530-2e16-4116-9d26-f49fbed9d372",
			"source": 2,
			"name": "@hf/thebloke/deepseek-coder-6.7b-base-awq",
			"description": "Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-06 18:16:27.183",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				},
				{
					"property_id": "terms",
					"value": "https://huggingface.co/TheBloke/deepseek-coder-6.7B-base-AWQ"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "7ed8d8e8-6040-4680-843a-aef402d6b013",
			"source": 1,
			"name": "@cf/meta-llama/llama-2-7b-chat-hf-lora",
			"description": "This is a Llama2 base model that Cloudflare dedicated for inference with LoRA adapters. Llama 2 is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. This is the repository for the 7B fine-tuned model, optimized for dialogue use cases and converted for the Hugging Face Transformers format. ",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-02 00:17:18.579",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "8192"
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "7a143886-c9bb-4a1c-be95-377b1973bc3b",
			"source": 1,
			"name": "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
			"description": "Llama 3.3 70B quantized to fp8 precision, optimized to be faster.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-12-06 17:09:18.338",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "24000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.29,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 2.25,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "function_calling",
					"value": "true"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Meta_Llama_3_3_70B_Instruct_Fp8_Fast_Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Meta_Llama_3_3_70B_Instruct_Fp8_Fast_Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						},
						{
							"title": "Async Batch",
							"type": "object",
							"properties": {
								"requests": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"external_reference": {
												"type": "string",
												"description": "User-supplied reference. This field will be present in the response as well it can be used to reference the request and response. It's NOT validated to be unique."
											},
											"prompt": {
												"type": "string",
												"minLength": 1,
												"description": "Prompt for the text generation model"
											},
											"stream": {
												"type": "boolean",
												"default": false,
												"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
											},
											"max_tokens": {
												"type": "integer",
												"default": 256,
												"description": "The maximum number of tokens to generate in the response."
											},
											"temperature": {
												"type": "number",
												"default": 0.6,
												"minimum": 0,
												"maximum": 5,
												"description": "Controls the randomness of the output; higher values produce more random results."
											},
											"top_p": {
												"type": "number",
												"minimum": 0,
												"maximum": 2,
												"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
											},
											"seed": {
												"type": "integer",
												"minimum": 1,
												"maximum": 9999999999,
												"description": "Random seed for reproducibility of the generation."
											},
											"repetition_penalty": {
												"type": "number",
												"minimum": 0,
												"maximum": 2,
												"description": "Penalty for repeated tokens; higher values discourage repetition."
											},
											"frequency_penalty": {
												"type": "number",
												"minimum": 0,
												"maximum": 2,
												"description": "Decreases the likelihood of the model repeating the same lines verbatim."
											},
											"presence_penalty": {
												"type": "number",
												"minimum": 0,
												"maximum": 2,
												"description": "Increases the likelihood of the model introducing new topics."
											},
											"response_format": {
												"title": "JSON Mode",
												"type": "object",
												"properties": {
													"type": {
														"type": "string",
														"enum": [
															"json_object",
															"json_schema"
														]
													},
													"json_schema": {}
												}
											}
										}
									}
								}
							}
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						},
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Async response",
							"properties": {
								"request_id": {
									"type": "string",
									"description": "The async request id that can be used to obtain the results."
								}
							}
						}
					]
				}
			}
		},
		{
			"id": "7952d0cc-cb00-4e10-be02-667565c2ee0f",
			"source": 1,
			"name": "@cf/ibm-granite/granite-4.0-h-micro",
			"description": "Granite 4.0 instruct models deliver strong performance across benchmarks, achieving industry-leading results in key agentic tasks like instruction following and function calling. These efficiencies make the models well-suited for a wide range of use cases like retrieval-augmented generation (RAG), multi-agent workflows, and edge deployments.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-10-07 18:46:29.436",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "131000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.017,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.11,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "7912c0ab-542e-44b9-b9ee-3113d226a8b5",
			"source": 1,
			"name": "@cf/lykon/dreamshaper-8-lcm",
			"description": "Stable Diffusion model that has been fine-tuned to be better at photorealism without sacrificing range.",
			"task": {
				"id": "3d6e1f35-341b-4915-a6c8-9a7142a9033a",
				"name": "Text-to-Image",
				"description": "Generates images from input text. These models can be used to generate and modify images based on text prompts."
			},
			"created_at": "2024-02-27 17:40:38.881",
			"tags": [],
			"properties": [
				{
					"property_id": "info",
					"value": "https://huggingface.co/Lykon/DreamShaper"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"description": "A text description of the image you want to generate"
						},
						"negative_prompt": {
							"type": "string",
							"description": "Text describing elements to avoid in the generated image"
						},
						"height": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The height of the generated image in pixels"
						},
						"width": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The width of the generated image in pixels"
						},
						"image": {
							"type": "array",
							"description": "For use with img2img tasks. An array of integers that represent the image data constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"image_b64": {
							"type": "string",
							"description": "For use with img2img tasks. A base64-encoded string of the input image"
						},
						"mask": {
							"type": "array",
							"description": "An array representing An array of integers that represent mask image data for inpainting constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"num_steps": {
							"type": "integer",
							"default": 20,
							"maximum": 20,
							"description": "The number of diffusion steps; higher values can improve quality but take longer"
						},
						"strength": {
							"type": "number",
							"default": 1,
							"description": "A value between 0 and 1 indicating how strongly to apply the transformation during img2img tasks; lower values make the output closer to the input image"
						},
						"guidance": {
							"type": "number",
							"default": 7.5,
							"description": "Controls how closely the generated image should adhere to the prompt; higher values make the image more aligned with the prompt"
						},
						"seed": {
							"type": "integer",
							"description": "Random seed for reproducibility of the image generation"
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"type": "string",
					"contentType": "image/png",
					"format": "binary",
					"description": "The generated image in PNG format"
				}
			}
		},
		{
			"id": "724608fa-983e-495d-b95c-340d6b7e78be",
			"source": 1,
			"name": "@cf/leonardo/phoenix-1.0",
			"description": "Phoenix 1.0 is a model by Leonardo.Ai that generates images with exceptional prompt adherence and coherent text.",
			"task": {
				"id": "3d6e1f35-341b-4915-a6c8-9a7142a9033a",
				"name": "Text-to-Image",
				"description": "Generates images from input text. These models can be used to generate and modify images based on text prompts."
			},
			"created_at": "2025-08-25 18:12:18.073",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per 512 by 512 tile",
							"price": 0.0058,
							"currency": "USD"
						},
						{
							"unit": "per step",
							"price": 0.00011,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "partner",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"description": "A text description of the image you want to generate."
						},
						"guidance": {
							"type": "number",
							"default": 2,
							"minimum": 2,
							"maximum": 10,
							"description": "Controls how closely the generated image should adhere to the prompt; higher values make the image more aligned with the prompt"
						},
						"seed": {
							"type": "integer",
							"minimum": 0,
							"description": "Random seed for reproducibility of the image generation"
						},
						"height": {
							"type": "integer",
							"minimum": 0,
							"maximum": 2048,
							"default": 1024,
							"description": "The height of the generated image in pixels"
						},
						"width": {
							"type": "integer",
							"minimum": 0,
							"maximum": 2048,
							"default": 1024,
							"description": "The width of the generated image in pixels"
						},
						"num_steps": {
							"type": "integer",
							"default": 25,
							"minimum": 1,
							"maximum": 50,
							"description": "The number of diffusion steps; higher values can improve quality but take longer"
						},
						"negative_prompt": {
							"type": "string",
							"minLength": 1,
							"description": "Specify what to exclude from the generated images"
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"type": "string",
					"contentType": "image/jpeg",
					"format": "binary",
					"description": "The generated image in JPEG format"
				}
			}
		},
		{
			"id": "6d52253a-b731-4a03-b203-cde2d4fae871",
			"source": 1,
			"name": "@cf/stabilityai/stable-diffusion-xl-base-1.0",
			"description": "Diffusion-based text-to-image generative model by Stability AI. Generates and modify images based on text prompts.",
			"task": {
				"id": "3d6e1f35-341b-4915-a6c8-9a7142a9033a",
				"name": "Text-to-Image",
				"description": "Generates images from input text. These models can be used to generate and modify images based on text prompts."
			},
			"created_at": "2023-11-10 10:54:43.694",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per step",
							"price": 0,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://stability.ai/stable-diffusion"
				},
				{
					"property_id": "terms",
					"value": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/LICENSE.md"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"description": "A text description of the image you want to generate"
						},
						"negative_prompt": {
							"type": "string",
							"description": "Text describing elements to avoid in the generated image"
						},
						"height": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The height of the generated image in pixels"
						},
						"width": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The width of the generated image in pixels"
						},
						"image": {
							"type": "array",
							"description": "For use with img2img tasks. An array of integers that represent the image data constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"image_b64": {
							"type": "string",
							"description": "For use with img2img tasks. A base64-encoded string of the input image"
						},
						"mask": {
							"type": "array",
							"description": "An array representing An array of integers that represent mask image data for inpainting constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"num_steps": {
							"type": "integer",
							"default": 20,
							"maximum": 20,
							"description": "The number of diffusion steps; higher values can improve quality but take longer"
						},
						"strength": {
							"type": "number",
							"default": 1,
							"description": "A value between 0 and 1 indicating how strongly to apply the transformation during img2img tasks; lower values make the output closer to the input image"
						},
						"guidance": {
							"type": "number",
							"default": 7.5,
							"description": "Controls how closely the generated image should adhere to the prompt; higher values make the image more aligned with the prompt"
						},
						"seed": {
							"type": "integer",
							"description": "Random seed for reproducibility of the image generation"
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"type": "string",
					"contentType": "image/png",
					"format": "binary",
					"description": "The generated image in PNG format"
				}
			}
		},
		{
			"id": "673c56cc-8553-49a1-b179-dd549ec9209a",
			"source": 2,
			"name": "@hf/thebloke/openhermes-2.5-mistral-7b-awq",
			"description": "OpenHermes 2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of OpenHermes 2 model, which trained on additional code datasets.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-06 18:04:22.846",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "617e7ec3-bf8d-4088-a863-4f89582d91b5",
			"source": 1,
			"name": "@cf/meta/m2m100-1.2b",
			"description": "Multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation",
			"task": {
				"id": "f57d07cb-9087-487a-bbbf-bc3e17fecc4b",
				"name": "Translation",
				"description": "Translation models convert a sequence of text from one language to another."
			},
			"created_at": "2023-09-25 19:21:11.898",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.34,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.34,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://github.com/facebookresearch/fairseq/tree/main/examples/m2m_100"
				},
				{
					"property_id": "languages",
					"value": "english, chinese, french, spanish, arabic, russian, german, japanese, portuguese, hindi"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/facebookresearch/fairseq/blob/main/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"properties": {
								"text": {
									"type": "string",
									"minLength": 1,
									"description": "The text to be translated"
								},
								"source_lang": {
									"type": "string",
									"default": "en",
									"description": "The language code of the source text (e.g., 'en' for English). Defaults to 'en' if not specified"
								},
								"target_lang": {
									"type": "string",
									"description": "The language code to translate the text into (e.g., 'es' for Spanish)"
								}
							},
							"required": [
								"text",
								"target_lang"
							]
						},
						{
							"properties": {
								"requests": {
									"type": "array",
									"description": "Batch of the embeddings requests to run using async-queue",
									"items": {
										"type": "object",
										"properties": {
											"text": {
												"type": "string",
												"minLength": 1,
												"description": "The text to be translated"
											},
											"source_lang": {
												"type": "string",
												"default": "en",
												"description": "The language code of the source text (e.g., 'en' for English). Defaults to 'en' if not specified"
											},
											"target_lang": {
												"type": "string",
												"description": "The language code to translate the text into (e.g., 'es' for Spanish)"
											}
										},
										"required": [
											"text",
											"target_lang"
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"oneOf": [
						{
							"properties": {
								"translated_text": {
									"type": "string",
									"description": "The translated text in the target language"
								}
							}
						},
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Async response",
							"properties": {
								"request_id": {
									"type": "string",
									"description": "The async request id that can be used to obtain the results."
								}
							}
						}
					]
				}
			}
		},
		{
			"id": "60920ed4-cf72-449a-a0f3-a38456b78262",
			"source": 1,
			"name": "@cf/ai4bharat/indictrans2-en-indic-1B",
			"description": "IndicTrans2 is the first open-source transformer-based multilingual NMT model that supports high-quality translations across all the 22 scheduled Indic languages",
			"task": {
				"id": "f57d07cb-9087-487a-bbbf-bc3e17fecc4b",
				"name": "Translation",
				"description": "Translation models convert a sequence of text from one language to another."
			},
			"created_at": "2025-09-23 18:19:17.382",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.34,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.34,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"text": {
							"oneOf": [
								{
									"type": "string"
								},
								{
									"type": "array",
									"items": {
										"type": "string"
									}
								}
							],
							"description": "Input text to translate. Can be a single string or a list of strings."
						},
						"target_language": {
							"type": "string",
							"enum": [
								"asm_Beng",
								"awa_Deva",
								"ben_Beng",
								"bho_Deva",
								"brx_Deva",
								"doi_Deva",
								"eng_Latn",
								"gom_Deva",
								"gon_Deva",
								"guj_Gujr",
								"hin_Deva",
								"hne_Deva",
								"kan_Knda",
								"kas_Arab",
								"kas_Deva",
								"kha_Latn",
								"lus_Latn",
								"mag_Deva",
								"mai_Deva",
								"mal_Mlym",
								"mar_Deva",
								"mni_Beng",
								"mni_Mtei",
								"npi_Deva",
								"ory_Orya",
								"pan_Guru",
								"san_Deva",
								"sat_Olck",
								"snd_Arab",
								"snd_Deva",
								"tam_Taml",
								"tel_Telu",
								"urd_Arab",
								"unr_Deva"
							],
							"default": "hin_Deva",
							"description": "Target langauge to translate to"
						}
					},
					"required": [
						"text",
						"target_language"
					]
				},
				"output": {
					"type": "object",
					"properties": {
						"translations": {
							"type": "array",
							"items": {
								"type": "string"
							},
							"description": "Translated texts"
						}
					},
					"required": [
						"translations"
					]
				}
			}
		},
		{
			"id": "60474554-f03b-4ff4-8ecc-c1b7c71d7b29",
			"source": 2,
			"name": "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
			"description": "Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-06 18:18:27.462",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				},
				{
					"property_id": "terms",
					"value": "https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-AWQ"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "57fbd08a-a4c4-411c-910d-b9459ff36c20",
			"source": 1,
			"name": "@cf/baai/bge-small-en-v1.5",
			"description": "BAAI general embedding (Small) model that transforms any given text into a 384-dimensional vector",
			"task": {
				"id": "0137cdcf-162a-4108-94f2-1ca59e8c65ee",
				"name": "Text Embeddings",
				"description": "Feature extraction models transform raw data into numerical features that can be processed while preserving the information in the original dataset. These models are ideal as part of building vector search applications or Retrieval Augmented Generation workflows with Large Language Models (LLM)."
			},
			"created_at": "2023-11-07 15:43:58.042",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.02,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/BAAI/bge-small-en-v1.5"
				},
				{
					"property_id": "max_input_tokens",
					"value": "512"
				},
				{
					"property_id": "output_dimensions",
					"value": "384"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"properties": {
								"text": {
									"oneOf": [
										{
											"type": "string",
											"description": "The text to embed",
											"minLength": 1
										},
										{
											"type": "array",
											"description": "Batch of text values to embed",
											"items": {
												"type": "string",
												"description": "The text to embed",
												"minLength": 1
											},
											"maxItems": 100
										}
									]
								},
								"pooling": {
									"type": "string",
									"enum": [
										"mean",
										"cls"
									],
									"default": "mean",
									"description": "The pooling method used in the embedding process. `cls` pooling will generate more accurate embeddings on larger inputs - however, embeddings created with cls pooling are not compatible with embeddings generated with mean pooling. The default pooling method is `mean` in order for this to not be a breaking change, but we highly suggest using the new `cls` pooling for better accuracy."
								}
							},
							"required": [
								"text"
							]
						},
						{
							"properties": {
								"requests": {
									"type": "array",
									"description": "Batch of the embeddings requests to run using async-queue",
									"items": {
										"properties": {
											"text": {
												"oneOf": [
													{
														"type": "string",
														"description": "The text to embed",
														"minLength": 1
													},
													{
														"type": "array",
														"description": "Batch of text values to embed",
														"items": {
															"type": "string",
															"description": "The text to embed",
															"minLength": 1
														},
														"maxItems": 100
													}
												]
											},
											"pooling": {
												"type": "string",
												"enum": [
													"mean",
													"cls"
												],
												"default": "mean",
												"description": "The pooling method used in the embedding process. `cls` pooling will generate more accurate embeddings on larger inputs - however, embeddings created with cls pooling are not compatible with embeddings generated with mean pooling. The default pooling method is `mean` in order for this to not be a breaking change, but we highly suggest using the new `cls` pooling for better accuracy."
											}
										},
										"required": [
											"text"
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"shape": {
									"type": "array",
									"items": {
										"type": "number"
									}
								},
								"data": {
									"type": "array",
									"description": "Embeddings of the requested text values",
									"items": {
										"type": "array",
										"description": "Floating point embedding representation shaped by the embedding model",
										"items": {
											"type": "number"
										}
									}
								},
								"pooling": {
									"type": "string",
									"enum": [
										"mean",
										"cls"
									],
									"description": "The pooling method used in the embedding process."
								}
							}
						},
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Async response",
							"properties": {
								"request_id": {
									"type": "string",
									"description": "The async request id that can be used to obtain the results."
								}
							}
						}
					]
				}
			}
		},
		{
			"id": "51b71d5b-8bc0-4489-a107-95e542b69914",
			"source": 1,
			"name": "@cf/qwen/qwen2.5-coder-32b-instruct",
			"description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). As of now, Qwen2.5-Coder has covered six mainstream model sizes, 0.5, 1.5, 3, 7, 14, 32 billion parameters, to meet the needs of different developers. Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-02-27 00:31:43.829",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "32768"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.66,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 1,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Qwen2_5_Coder_32B_Instruct_Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Qwen2_5_Coder_32B_Instruct_Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "4c3a544e-da47-4336-9cea-c7cbfab33f16",
			"source": 1,
			"name": "@cf/deepseek-ai/deepseek-math-7b-instruct",
			"description": "DeepSeekMath-Instruct 7B is a mathematically instructed tuning model derived from DeepSeekMath-Base 7B. DeepSeekMath is initialized with DeepSeek-Coder-v1.5 7B and continues pre-training on math-related tokens sourced from Common Crawl, together with natural language and code data for 500B tokens.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 17:54:17.459",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/deepseek-ai/deepseek-math-7b-instruct"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/deepseek-ai/DeepSeek-Math/blob/main/LICENSE-MODEL"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "48dd2443-0c61-43b2-8894-22abddf1b081",
			"source": 1,
			"name": "@cf/tiiuae/falcon-7b-instruct",
			"description": "Falcon-7B-Instruct is a 7B parameters causal decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:21:15.796",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/tiiuae/falcon-7b-instruct"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "44774b85-08c8-4bb8-8d2a-b06ebc538a79",
			"source": 2,
			"name": "@hf/nousresearch/hermes-2-pro-mistral-7b",
			"description": "Hermes 2 Pro on Mistral 7B is the new flagship 7B Hermes! Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-01 23:45:53.800",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "24000"
				},
				{
					"property_id": "function_calling",
					"value": "true"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "429b9e8b-d99e-44de-91ad-706cf8183658",
			"source": 1,
			"name": "@cf/baai/bge-base-en-v1.5",
			"description": "BAAI general embedding (Base) model that transforms any given text into a 768-dimensional vector",
			"task": {
				"id": "0137cdcf-162a-4108-94f2-1ca59e8c65ee",
				"name": "Text Embeddings",
				"description": "Feature extraction models transform raw data into numerical features that can be processed while preserving the information in the original dataset. These models are ideal as part of building vector search applications or Retrieval Augmented Generation workflows with Large Language Models (LLM)."
			},
			"created_at": "2023-09-25 19:21:11.898",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.067,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/BAAI/bge-base-en-v1.5"
				},
				{
					"property_id": "max_input_tokens",
					"value": "512"
				},
				{
					"property_id": "output_dimensions",
					"value": "768"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"properties": {
								"text": {
									"oneOf": [
										{
											"type": "string",
											"description": "The text to embed",
											"minLength": 1
										},
										{
											"type": "array",
											"description": "Batch of text values to embed",
											"items": {
												"type": "string",
												"description": "The text to embed",
												"minLength": 1
											},
											"maxItems": 100
										}
									]
								},
								"pooling": {
									"type": "string",
									"enum": [
										"mean",
										"cls"
									],
									"default": "mean",
									"description": "The pooling method used in the embedding process. `cls` pooling will generate more accurate embeddings on larger inputs - however, embeddings created with cls pooling are not compatible with embeddings generated with mean pooling. The default pooling method is `mean` in order for this to not be a breaking change, but we highly suggest using the new `cls` pooling for better accuracy."
								}
							},
							"required": [
								"text"
							]
						},
						{
							"properties": {
								"requests": {
									"type": "array",
									"description": "Batch of the embeddings requests to run using async-queue",
									"items": {
										"properties": {
											"text": {
												"oneOf": [
													{
														"type": "string",
														"description": "The text to embed",
														"minLength": 1
													},
													{
														"type": "array",
														"description": "Batch of text values to embed",
														"items": {
															"type": "string",
															"description": "The text to embed",
															"minLength": 1
														},
														"maxItems": 100
													}
												]
											},
											"pooling": {
												"type": "string",
												"enum": [
													"mean",
													"cls"
												],
												"default": "mean",
												"description": "The pooling method used in the embedding process. `cls` pooling will generate more accurate embeddings on larger inputs - however, embeddings created with cls pooling are not compatible with embeddings generated with mean pooling. The default pooling method is `mean` in order for this to not be a breaking change, but we highly suggest using the new `cls` pooling for better accuracy."
											}
										},
										"required": [
											"text"
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"shape": {
									"type": "array",
									"items": {
										"type": "number"
									}
								},
								"data": {
									"type": "array",
									"description": "Embeddings of the requested text values",
									"items": {
										"type": "array",
										"description": "Floating point embedding representation shaped by the embedding model",
										"items": {
											"type": "number"
										}
									}
								},
								"pooling": {
									"type": "string",
									"enum": [
										"mean",
										"cls"
									],
									"description": "The pooling method used in the embedding process."
								}
							}
						},
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Async response",
							"properties": {
								"request_id": {
									"type": "string",
									"description": "The async request id that can be used to obtain the results."
								}
							}
						}
					]
				}
			}
		},
		{
			"id": "41ca173f-72d5-4420-8915-49e835d2676e",
			"source": 1,
			"name": "@cf/aisingapore/gemma-sea-lion-v4-27b-it",
			"description": "SEA-LION stands for Southeast Asian Languages In One Network, which is a collection of Large Language Models (LLMs) which have been pretrained and instruct-tuned for the Southeast Asia (SEA) region.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-09-23 19:27:30.468",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "128000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.35,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.56,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 2000,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 2000,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						},
						{
							"title": "Async Batch",
							"type": "object",
							"properties": {
								"requests": {
									"type": "array",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"title": "Prompt",
												"properties": {
													"prompt": {
														"type": "string",
														"minLength": 1,
														"description": "The input text prompt for the model to generate a response."
													},
													"lora": {
														"type": "string",
														"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
													},
													"response_format": {
														"title": "JSON Mode",
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"enum": [
																	"json_object",
																	"json_schema"
																]
															},
															"json_schema": {}
														}
													},
													"raw": {
														"type": "boolean",
														"default": false,
														"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
													},
													"stream": {
														"type": "boolean",
														"default": false,
														"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
													},
													"max_tokens": {
														"type": "integer",
														"default": 256,
														"description": "The maximum number of tokens to generate in the response."
													},
													"temperature": {
														"type": "number",
														"default": 0.6,
														"minimum": 0,
														"maximum": 5,
														"description": "Controls the randomness of the output; higher values produce more random results."
													},
													"top_p": {
														"type": "number",
														"minimum": 0.001,
														"maximum": 1,
														"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
													},
													"top_k": {
														"type": "integer",
														"minimum": 1,
														"maximum": 50,
														"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
													},
													"seed": {
														"type": "integer",
														"minimum": 1,
														"maximum": 9999999999,
														"description": "Random seed for reproducibility of the generation."
													},
													"repetition_penalty": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Penalty for repeated tokens; higher values discourage repetition."
													},
													"frequency_penalty": {
														"type": "number",
														"minimum": -2,
														"maximum": 2,
														"description": "Decreases the likelihood of the model repeating the same lines verbatim."
													},
													"presence_penalty": {
														"type": "number",
														"minimum": -2,
														"maximum": 2,
														"description": "Increases the likelihood of the model introducing new topics."
													}
												},
												"required": [
													"prompt"
												]
											},
											{
												"title": "Messages",
												"properties": {
													"messages": {
														"type": "array",
														"description": "An array of message objects representing the conversation history.",
														"items": {
															"type": "object",
															"properties": {
																"role": {
																	"type": "string",
																	"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
																},
																"content": {
																	"type": "string",
																	"description": "The content of the message as a string."
																}
															},
															"required": [
																"role",
																"content"
															]
														}
													},
													"functions": {
														"type": "array",
														"items": {
															"type": "object",
															"properties": {
																"name": {
																	"type": "string"
																},
																"code": {
																	"type": "string"
																}
															},
															"required": [
																"name",
																"code"
															]
														}
													},
													"tools": {
														"type": "array",
														"description": "A list of tools available for the assistant to use.",
														"items": {
															"type": "object",
															"oneOf": [
																{
																	"properties": {
																		"name": {
																			"type": "string",
																			"description": "The name of the tool. More descriptive the better."
																		},
																		"description": {
																			"type": "string",
																			"description": "A brief description of what the tool does."
																		},
																		"parameters": {
																			"type": "object",
																			"description": "Schema defining the parameters accepted by the tool.",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The type of the parameters object (usually 'object')."
																				},
																				"required": {
																					"type": "array",
																					"description": "List of required parameter names.",
																					"items": {
																						"type": "string"
																					}
																				},
																				"properties": {
																					"type": "object",
																					"description": "Definitions of each parameter.",
																					"additionalProperties": {
																						"type": "object",
																						"properties": {
																							"type": {
																								"type": "string",
																								"description": "The data type of the parameter."
																							},
																							"description": {
																								"type": "string",
																								"description": "A description of the expected parameter."
																							}
																						},
																						"required": [
																							"type",
																							"description"
																						]
																					}
																				}
																			},
																			"required": [
																				"type",
																				"properties"
																			]
																		}
																	},
																	"required": [
																		"name",
																		"description",
																		"parameters"
																	]
																},
																{
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "Specifies the type of tool (e.g., 'function')."
																		},
																		"function": {
																			"type": "object",
																			"description": "Details of the function tool.",
																			"properties": {
																				"name": {
																					"type": "string",
																					"description": "The name of the function."
																				},
																				"description": {
																					"type": "string",
																					"description": "A brief description of what the function does."
																				},
																				"parameters": {
																					"type": "object",
																					"description": "Schema defining the parameters accepted by the function.",
																					"properties": {
																						"type": {
																							"type": "string",
																							"description": "The type of the parameters object (usually 'object')."
																						},
																						"required": {
																							"type": "array",
																							"description": "List of required parameter names.",
																							"items": {
																								"type": "string"
																							}
																						},
																						"properties": {
																							"type": "object",
																							"description": "Definitions of each parameter.",
																							"additionalProperties": {
																								"type": "object",
																								"properties": {
																									"type": {
																										"type": "string",
																										"description": "The data type of the parameter."
																									},
																									"description": {
																										"type": "string",
																										"description": "A description of the expected parameter."
																									}
																								},
																								"required": [
																									"type",
																									"description"
																								]
																							}
																						}
																					},
																					"required": [
																						"type",
																						"properties"
																					]
																				}
																			},
																			"required": [
																				"name",
																				"description",
																				"parameters"
																			]
																		}
																	},
																	"required": [
																		"type",
																		"function"
																	]
																}
															]
														}
													},
													"response_format": {
														"title": "JSON Mode",
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"enum": [
																	"json_object",
																	"json_schema"
																]
															},
															"json_schema": {}
														}
													},
													"raw": {
														"type": "boolean",
														"default": false,
														"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
													},
													"stream": {
														"type": "boolean",
														"default": false,
														"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
													},
													"max_tokens": {
														"type": "integer",
														"default": 256,
														"description": "The maximum number of tokens to generate in the response."
													},
													"temperature": {
														"type": "number",
														"default": 0.6,
														"minimum": 0,
														"maximum": 5,
														"description": "Controls the randomness of the output; higher values produce more random results."
													},
													"top_p": {
														"type": "number",
														"minimum": 0.001,
														"maximum": 1,
														"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
													},
													"top_k": {
														"type": "integer",
														"minimum": 1,
														"maximum": 50,
														"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
													},
													"seed": {
														"type": "integer",
														"minimum": 1,
														"maximum": 9999999999,
														"description": "Random seed for reproducibility of the generation."
													},
													"repetition_penalty": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Penalty for repeated tokens; higher values discourage repetition."
													},
													"frequency_penalty": {
														"type": "number",
														"minimum": -2,
														"maximum": 2,
														"description": "Decreases the likelihood of the model repeating the same lines verbatim."
													},
													"presence_penalty": {
														"type": "number",
														"minimum": -2,
														"maximum": 2,
														"description": "Increases the likelihood of the model introducing new topics."
													}
												},
												"required": [
													"messages"
												]
											}
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Chat Completion Response",
							"properties": {
								"id": {
									"type": "string",
									"description": "Unique identifier for the completion"
								},
								"object": {
									"type": "string",
									"enum": [
										"chat.completion"
									],
									"description": "Object type identifier"
								},
								"created": {
									"type": "number",
									"description": "Unix timestamp of when the completion was created"
								},
								"model": {
									"type": "string",
									"description": "Model used for the completion"
								},
								"choices": {
									"type": "array",
									"description": "List of completion choices",
									"items": {
										"type": "object",
										"properties": {
											"index": {
												"type": "number",
												"description": "Index of the choice in the list"
											},
											"message": {
												"type": "object",
												"description": "The message generated by the model",
												"properties": {
													"role": {
														"type": "string",
														"description": "Role of the message author"
													},
													"content": {
														"type": "string",
														"description": "The content of the message"
													},
													"reasoning_content": {
														"type": "string",
														"description": "Internal reasoning content (if available)"
													},
													"tool_calls": {
														"type": "array",
														"description": "Tool calls made by the assistant",
														"items": {
															"type": "object",
															"properties": {
																"id": {
																	"type": "string",
																	"description": "Unique identifier for the tool call"
																},
																"type": {
																	"type": "string",
																	"enum": [
																		"function"
																	],
																	"description": "Type of tool call"
																},
																"function": {
																	"type": "object",
																	"properties": {
																		"name": {
																			"type": "string",
																			"description": "Name of the function to call"
																		},
																		"arguments": {
																			"type": "string",
																			"description": "JSON string of arguments for the function"
																		}
																	},
																	"required": [
																		"name",
																		"arguments"
																	]
																}
															},
															"required": [
																"id",
																"type",
																"function"
															]
														}
													}
												},
												"required": [
													"role",
													"content"
												]
											},
											"finish_reason": {
												"type": "string",
												"description": "Reason why the model stopped generating"
											},
											"stop_reason": {
												"type": [
													"string",
													"null"
												],
												"description": "Stop reason (may be null)"
											},
											"logprobs": {
												"type": [
													"object",
													"null"
												],
												"description": "Log probabilities (if requested)"
											}
										}
									}
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"prompt_logprobs": {
									"type": [
										"object",
										"null"
									],
									"description": "Log probabilities for the prompt (if requested)"
								}
							}
						},
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Text Completion Response",
							"properties": {
								"id": {
									"type": "string",
									"description": "Unique identifier for the completion"
								},
								"object": {
									"type": "string",
									"enum": [
										"text_completion"
									],
									"description": "Object type identifier"
								},
								"created": {
									"type": "number",
									"description": "Unix timestamp of when the completion was created"
								},
								"model": {
									"type": "string",
									"description": "Model used for the completion"
								},
								"choices": {
									"type": "array",
									"description": "List of completion choices",
									"items": {
										"type": "object",
										"properties": {
											"index": {
												"type": "number",
												"description": "Index of the choice in the list"
											},
											"text": {
												"type": "string",
												"description": "The generated text completion"
											},
											"finish_reason": {
												"type": "string",
												"description": "Reason why the model stopped generating"
											},
											"stop_reason": {
												"type": [
													"string",
													"null"
												],
												"description": "Stop reason (may be null)"
											},
											"logprobs": {
												"type": [
													"object",
													"null"
												],
												"description": "Log probabilities (if requested)"
											},
											"prompt_logprobs": {
												"type": [
													"object",
													"null"
												],
												"description": "Log probabilities for the prompt (if requested)"
											}
										},
										"required": [
											"index",
											"text",
											"finish_reason"
										]
									}
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								}
							}
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						},
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Async response",
							"properties": {
								"request_id": {
									"type": "string",
									"description": "The async request id that can be used to obtain the results."
								}
							}
						}
					]
				}
			}
		},
		{
			"id": "3dcb4f2d-26a8-412b-b6e3-2a368beff66b",
			"source": 1,
			"name": "@cf/meta/llama-3.1-8b-instruct-awq",
			"description": "Quantized (int4) generative text model with 8 billion parameters from Meta.\n",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-07-25 17:46:04.304",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.12,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.27,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "context_window",
					"value": "8192"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "3dca5889-db3e-4973-aa0c-3a4a6bd22d29",
			"source": 1,
			"name": "@cf/unum/uform-gen2-qwen-500m",
			"description": "UForm-Gen is a small generative vision-language model primarily designed for Image Captioning and Visual Question Answering. The model was pre-trained on the internal image captioning dataset and fine-tuned on public instructions datasets: SVIT, LVIS, VQAs datasets.",
			"task": {
				"id": "882a91d1-c331-4eec-bdad-834c919942a8",
				"name": "Image-to-Text",
				"description": "Image to text models output a text from a given image. Image captioning or optical character recognition can be considered as the most common applications of image to text."
			},
			"created_at": "2024-02-27 18:28:52.485",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "info",
					"value": "https://www.unum.cloud/"
				}
			],
			"schema": {
				"input": {
					"oneOf": [
						{
							"type": "string",
							"format": "binary",
							"description": "Binary string representing the image contents."
						},
						{
							"type": "object",
							"properties": {
								"prompt": {
									"type": "string",
									"description": "The input text prompt for the model to generate a response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"top_p": {
									"type": "number",
									"description": "Controls the creativity of the AI's responses by adjusting how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "number",
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "number",
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"description": "Increases the likelihood of the model introducing new topics."
								},
								"image": {
									"oneOf": [
										{
											"type": "array",
											"description": "An array of integers that represent the image data constrained to 8-bit unsigned integer values",
											"items": {
												"type": "number",
												"description": "A value between 0 and 255"
											}
										},
										{
											"type": "string",
											"format": "binary",
											"description": "Binary string representing the image contents."
										}
									]
								},
								"max_tokens": {
									"type": "integer",
									"default": 512,
									"description": "The maximum number of tokens to generate in the response."
								}
							},
							"required": [
								"image"
							]
						}
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"description": {
							"type": "string"
						}
					}
				}
			}
		},
		{
			"id": "3976bab8-3810-4ad8-8580-ab1e22de7823",
			"source": 2,
			"name": "@hf/thebloke/zephyr-7b-beta-awq",
			"description": "Zephyr 7B Beta AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Zephyr model variant.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2023-11-24 00:27:15.869",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "4096"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/TheBloke/zephyr-7B-beta-AWQ"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "337170b7-bd2f-4631-9a57-688b579cf6d3",
			"source": 1,
			"name": "@cf/google/gemma-7b-it-lora",
			"description": "  This is a Gemma-7B base model that Cloudflare dedicates for inference with LoRA adapters. Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-02 00:20:19.633",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "3500"
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "3222ddb3-e211-4fd9-9a6d-79a80e47b3a6",
			"source": 1,
			"name": "@cf/qwen/qwen1.5-1.8b-chat",
			"description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:30:31.723",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "32000"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/qwen/qwen1.5-1.8b-chat"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "31690291-ebdc-4f98-bcfc-a44844e215b7",
			"source": 1,
			"name": "@cf/mistralai/mistral-small-3.1-24b-instruct",
			"description": "Building upon Mistral Small 3 (2501), Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance. With 24 billion parameters, this model achieves top-tier capabilities in both text and vision tasks.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-03-18 03:28:37.890",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "128000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.35,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.56,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "function_calling",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Mistral_Small_3_1_24B_Instruct_Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"guided_json": {
									"type": "object",
									"description": "JSON schema that should be fulfilled for the response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.15,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Mistral_Small_3_1_24B_Instruct_Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"tool_call_id": {
												"type": "string",
												"description": "The tool call id. Must be supplied for tool calls for Mistral-3. If you don't know what to put here you can fall back to 000000001",
												"pattern": "[a-zA-Z0-9]{9}"
											},
											"content": {
												"oneOf": [
													{
														"type": "string",
														"description": "The content of the message as a string."
													},
													{
														"type": "array",
														"items": {
															"type": "object",
															"properties": {
																"type": {
																	"type": "string",
																	"description": "Type of the content provided"
																},
																"text": {
																	"type": "string"
																},
																"image_url": {
																	"type": "object",
																	"properties": {
																		"url": {
																			"type": "string",
																			"pattern": "^data:*",
																			"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																		}
																	}
																}
															}
														}
													},
													{
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"description": "Type of the content provided"
															},
															"text": {
																"type": "string"
															},
															"image_url": {
																"type": "object",
																"properties": {
																	"url": {
																		"type": "string",
																		"pattern": "^data:*",
																		"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																	}
																}
															}
														}
													}
												]
											}
										}
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"guided_json": {
									"type": "object",
									"description": "JSON schema that should be fufilled for the response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.15,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "31097538-a3ff-4e6e-bb56-ad0e1f428b61",
			"source": 1,
			"name": "@cf/meta/llama-3-8b-instruct-awq",
			"description": "Quantized (int4) generative text model with 8 billion parameters from Meta.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-05-09 23:32:47.584",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.12,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.27,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "context_window",
					"value": "8192"
				},
				{
					"property_id": "info",
					"value": "https://llama.meta.com"
				},
				{
					"property_id": "terms",
					"value": "https://llama.meta.com/llama3/license/#"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "2cbc033b-ded8-4e02-bbb2-47cf05d5cfe5",
			"source": 1,
			"name": "@cf/meta/llama-3.2-11b-vision-instruct",
			"description": " The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-09-25 05:36:04.547",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "128000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.049,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.68,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "lora",
					"value": "true"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"maxLength": 131072,
									"description": "The input text prompt for the model to generate a response."
								},
								"image": {
									"oneOf": [
										{
											"type": "array",
											"description": "An array of integers that represent the image data constrained to 8-bit unsigned integer values.  Deprecated, use image as a part of messages now.",
											"items": {
												"type": "number",
												"description": "A value between 0 and 255"
											}
										},
										{
											"type": "string",
											"format": "binary",
											"description": "Binary string representing the image contents.  Deprecated, use image as a part of messages now."
										}
									]
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"tool_call_id": {
												"type": "string",
												"description": "The tool call id. Must be supplied for tool calls for Mistral-3. If you don't know what to put here you can fall back to 000000001",
												"pattern": "[a-zA-Z0-9]{9}"
											},
											"content": {
												"oneOf": [
													{
														"type": "string",
														"description": "The content of the message as a string."
													},
													{
														"type": "array",
														"items": {
															"type": "object",
															"properties": {
																"type": {
																	"type": "string",
																	"description": "Type of the content provided"
																},
																"text": {
																	"type": "string"
																},
																"image_url": {
																	"type": "object",
																	"properties": {
																		"url": {
																			"type": "string",
																			"pattern": "^data:*",
																			"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																		}
																	}
																}
															}
														}
													},
													{
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"description": "Type of the content provided"
															},
															"text": {
																"type": "string"
															},
															"image_url": {
																"type": "object",
																"properties": {
																	"url": {
																		"type": "string",
																		"pattern": "^data:*",
																		"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																	}
																}
															}
														}
													}
												]
											}
										}
									}
								},
								"image": {
									"oneOf": [
										{
											"type": "array",
											"description": "An array of integers that represent the image data constrained to 8-bit unsigned integer values. Deprecated, use image as a part of messages now.",
											"items": {
												"type": "number",
												"description": "A value between 0 and 255"
											}
										},
										{
											"type": "string",
											"format": "binary",
											"description": "Binary string representing the image contents. Deprecated, use image as a part of messages now."
										}
									]
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Controls the creativity of the AI's responses by adjusting how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							}
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "2169496d-9c0e-4e49-8399-c44ee66bff7d",
			"source": 1,
			"name": "@cf/openai/whisper-tiny-en",
			"description": "Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. This is the English-only version of the Whisper Tiny model which was trained on the task of speech recognition.",
			"task": {
				"id": "dfce1c48-2a81-462e-a7fd-de97ce985207",
				"name": "Automatic Speech Recognition",
				"description": "Automatic speech recognition (ASR) models convert a speech signal, typically an audio input, to text."
			},
			"created_at": "2024-04-22 20:59:02.731",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"oneOf": [
						{
							"type": "string",
							"format": "binary"
						},
						{
							"type": "object",
							"properties": {
								"audio": {
									"type": "array",
									"description": "An array of integers that represent the audio data constrained to 8-bit unsigned integer values",
									"items": {
										"type": "number",
										"description": "A value between 0 and 255"
									}
								}
							},
							"required": [
								"audio"
							]
						}
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"text": {
							"type": "string",
							"description": "The transcription"
						},
						"word_count": {
							"type": "number"
						},
						"words": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"word": {
										"type": "string"
									},
									"start": {
										"type": "number",
										"description": "The second this word begins in the recording"
									},
									"end": {
										"type": "number",
										"description": "The ending second when the word completes"
									}
								}
							}
						},
						"vtt": {
							"type": "string"
						}
					},
					"required": [
						"text"
					]
				}
			}
		},
		{
			"id": "200f0812-148c-48c1-915d-fb3277a94a08",
			"source": 1,
			"name": "@cf/openai/whisper-large-v3-turbo",
			"description": "Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. ",
			"task": {
				"id": "dfce1c48-2a81-462e-a7fd-de97ce985207",
				"name": "Automatic Speech Recognition",
				"description": "Automatic speech recognition (ASR) models convert a speech signal, typically an audio input, to text."
			},
			"created_at": "2024-05-22 00:02:18.656",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per audio minute",
							"price": 0.00051,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"audio": {
							"type": "string",
							"description": "Base64 encoded value of the audio data."
						},
						"task": {
							"type": "string",
							"default": "transcribe",
							"description": "Supported tasks are 'translate' or 'transcribe'."
						},
						"language": {
							"type": "string",
							"description": "The language of the audio being transcribed or translated."
						},
						"vad_filter": {
							"type": "boolean",
							"default": false,
							"description": "Preprocess the audio with a voice activity detection model."
						},
						"initial_prompt": {
							"type": "string",
							"description": "A text prompt to help provide context to the model on the contents of the audio."
						},
						"prefix": {
							"type": "string",
							"description": "The prefix it appended the the beginning of the output of the transcription and can guide the transcription result."
						}
					},
					"required": [
						"audio"
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"transcription_info": {
							"type": "object",
							"properties": {
								"language": {
									"type": "string",
									"description": "The language of the audio being transcribed or translated."
								},
								"language_probability": {
									"type": "number",
									"description": "The confidence level or probability of the detected language being accurate, represented as a decimal between 0 and 1."
								},
								"duration": {
									"type": "number",
									"description": "The total duration of the original audio file, in seconds."
								},
								"duration_after_vad": {
									"type": "number",
									"description": "The duration of the audio after applying Voice Activity Detection (VAD) to remove silent or irrelevant sections, in seconds."
								}
							}
						},
						"text": {
							"type": "string",
							"description": "The complete transcription of the audio."
						},
						"word_count": {
							"type": "number",
							"description": "The total number of words in the transcription."
						},
						"segments": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"start": {
										"type": "number",
										"description": "The starting time of the segment within the audio, in seconds."
									},
									"end": {
										"type": "number",
										"description": "The ending time of the segment within the audio, in seconds."
									},
									"text": {
										"type": "string",
										"description": "The transcription of the segment."
									},
									"temperature": {
										"type": "number",
										"description": "The temperature used in the decoding process, controlling randomness in predictions. Lower values result in more deterministic outputs."
									},
									"avg_logprob": {
										"type": "number",
										"description": "The average log probability of the predictions for the words in this segment, indicating overall confidence."
									},
									"compression_ratio": {
										"type": "number",
										"description": "The compression ratio of the input to the output, measuring how much the text was compressed during the transcription process."
									},
									"no_speech_prob": {
										"type": "number",
										"description": "The probability that the segment contains no speech, represented as a decimal between 0 and 1."
									},
									"words": {
										"type": "array",
										"items": {
											"type": "object",
											"properties": {
												"word": {
													"type": "string",
													"description": "The individual word transcribed from the audio."
												},
												"start": {
													"type": "number",
													"description": "The starting time of the word within the audio, in seconds."
												},
												"end": {
													"type": "number",
													"description": "The ending time of the word within the audio, in seconds."
												}
											}
										}
									}
								}
							}
						},
						"vtt": {
							"type": "string",
							"description": "The transcription in WebVTT format, which includes timing and text information for use in subtitles."
						}
					},
					"required": [
						"text"
					]
				}
			}
		},
		{
			"id": "1f55679f-009e-4456-aa4f-049a62b4b6a0",
			"source": 1,
			"name": "@cf/deepgram/aura-1",
			"description": "Aura is a context-aware text-to-speech (TTS) model that applies natural pacing, expressiveness, and fillers based on the context of the provided text. The quality of your text input directly impacts the naturalness of the audio output.",
			"task": {
				"id": "b52660a1-9a95-4ab2-8b1d-f232be34604a",
				"name": "Text-to-Speech",
				"description": "Text-to-Speech (TTS) is the task of generating natural sounding speech given text input. TTS models can be extended to have a single model that generates speech for multiple speakers and multiple languages."
			},
			"created_at": "2025-08-27 01:18:18.880",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per audio minute",
							"price": 0,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "partner",
					"value": "true"
				},
				{
					"property_id": "realtime",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"speaker": {
							"type": "string",
							"enum": [
								"angus",
								"asteria",
								"arcas",
								"orion",
								"orpheus",
								"athena",
								"luna",
								"zeus",
								"perseus",
								"helios",
								"hera",
								"stella"
							],
							"default": "angus",
							"description": "Speaker used to produce the audio."
						},
						"encoding": {
							"type": "string",
							"enum": [
								"linear16",
								"flac",
								"mulaw",
								"alaw",
								"mp3",
								"opus",
								"aac"
							],
							"description": "Encoding of the output audio."
						},
						"container": {
							"type": "string",
							"enum": [
								"none",
								"wav",
								"ogg"
							],
							"description": "Container specifies the file format wrapper for the output audio. The available options depend on the encoding type.."
						},
						"text": {
							"type": "string",
							"description": "The text content to be converted to speech"
						},
						"sample_rate": {
							"type": "number",
							"description": "Sample Rate specifies the sample rate for the output audio. Based on the encoding, different sample rates are supported. For some encodings, the sample rate is not configurable"
						},
						"bit_rate": {
							"type": "number",
							"description": "The bitrate of the audio in bits per second. Choose from predefined ranges or specific values based on the encoding type."
						}
					},
					"required": [
						"text"
					]
				},
				"output": {
					"type": "string",
					"contentType": "audio/mpeg",
					"format": "binary",
					"description": "The generated audio in MP3 format"
				}
			}
		},
		{
			"id": "1dc9e589-df6b-4e66-ac9f-ceff42d64983",
			"source": 1,
			"name": "@cf/defog/sqlcoder-7b-2",
			"description": "This model is intended to be used by non-technical users to understand data inside their SQL databases. ",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:18:46.095",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "10000"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/defog/sqlcoder-7b-2"
				},
				{
					"property_id": "terms",
					"value": "https://creativecommons.org/licenses/by-sa/4.0/deed.en"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "1d933df3-680f-4280-940d-da87435edb07",
			"source": 1,
			"name": "@cf/microsoft/phi-2",
			"description": "Phi-2 is a Transformer-based model with a next-word prediction objective, trained on 1.4T tokens from multiple passes on a mixture of Synthetic and Web datasets for NLP and coding.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:26:21.126",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "2048"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/microsoft/phi-2"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "19bd38eb-bcda-4e53-bec2-704b4689b43a",
			"source": 1,
			"name": "@cf/facebook/bart-large-cnn",
			"description": "BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. You can use this model for text summarization.",
			"task": {
				"id": "6f4e65d8-da0f-40d2-9aa4-db582a5a04fd",
				"name": "Summarization",
				"description": "Summarization is the task of producing a shorter version of a document while preserving its important information. Some models can extract text from the original input, while other models can generate entirely new text."
			},
			"created_at": "2024-02-27 18:28:11.833",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"input_text": {
							"type": "string",
							"minLength": 1,
							"description": "The text that you want the model to summarize"
						},
						"max_length": {
							"type": "integer",
							"default": 1024,
							"description": "The maximum length of the generated summary in tokens"
						}
					},
					"required": [
						"input_text"
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"summary": {
							"type": "string",
							"description": "The summarized version of the input text"
						}
					}
				}
			}
		},
		{
			"id": "19547f04-7a6a-4f87-bf2c-f5e32fb12dc5",
			"source": 1,
			"name": "@cf/runwayml/stable-diffusion-v1-5-img2img",
			"description": "Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images. Img2img generate a new image from an input image with Stable Diffusion. ",
			"task": {
				"id": "3d6e1f35-341b-4915-a6c8-9a7142a9033a",
				"name": "Text-to-Image",
				"description": "Generates images from input text. These models can be used to generate and modify images based on text prompts."
			},
			"created_at": "2024-02-27 17:32:28.581",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per step",
							"price": 0,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/runwayml/stable-diffusion-v1-5"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/runwayml/stable-diffusion/blob/main/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"description": "A text description of the image you want to generate"
						},
						"negative_prompt": {
							"type": "string",
							"description": "Text describing elements to avoid in the generated image"
						},
						"height": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The height of the generated image in pixels"
						},
						"width": {
							"type": "integer",
							"minimum": 256,
							"maximum": 2048,
							"description": "The width of the generated image in pixels"
						},
						"image": {
							"type": "array",
							"description": "For use with img2img tasks. An array of integers that represent the image data constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"image_b64": {
							"type": "string",
							"description": "For use with img2img tasks. A base64-encoded string of the input image"
						},
						"mask": {
							"type": "array",
							"description": "An array representing An array of integers that represent mask image data for inpainting constrained to 8-bit unsigned integer values",
							"items": {
								"type": "number",
								"description": "A value between 0 and 255"
							}
						},
						"num_steps": {
							"type": "integer",
							"default": 20,
							"maximum": 20,
							"description": "The number of diffusion steps; higher values can improve quality but take longer"
						},
						"strength": {
							"type": "number",
							"default": 1,
							"description": "A value between 0 and 1 indicating how strongly to apply the transformation during img2img tasks; lower values make the output closer to the input image"
						},
						"guidance": {
							"type": "number",
							"default": 7.5,
							"description": "Controls how closely the generated image should adhere to the prompt; higher values make the image more aligned with the prompt"
						},
						"seed": {
							"type": "integer",
							"description": "Random seed for reproducibility of the image generation"
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"type": "string",
					"contentType": "image/png",
					"format": "binary",
					"description": "The generated image in PNG format"
				}
			}
		},
		{
			"id": "188a4e1e-253e-46d0-9616-0bf8c149763f",
			"source": 1,
			"name": "@cf/openai/gpt-oss-20b",
			"description": "OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases – gpt-oss-20b is for lower latency, and local or specialized use-cases.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-08-05 10:49:53.265",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "128000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.2,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.3,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"oneOf": [
						{
							"type": "object",
							"title": "GPT_OSS_20B_Responses",
							"properties": {
								"input": {
									"anyOf": [
										{
											"type": "string"
										},
										{
											"items": {},
											"type": "array"
										}
									],
									"description": "Responses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types"
								},
								"reasoning": {
									"type": "object",
									"properties": {
										"effort": {
											"type": "string",
											"description": "Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",
											"enum": [
												"low",
												"medium",
												"high"
											]
										},
										"summary": {
											"type": "string",
											"description": "A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.",
											"enum": [
												"auto",
												"concise",
												"detailed"
											]
										}
									}
								}
							},
							"required": [
								"input"
							]
						},
						{
							"type": "object",
							"title": "GPT_OSS_20B_Responses_Async",
							"properties": {
								"requests": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"input": {
												"anyOf": [
													{
														"type": "string"
													},
													{
														"items": {},
														"type": "array"
													}
												],
												"description": "Responses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types"
											},
											"reasoning": {
												"type": "object",
												"properties": {
													"effort": {
														"type": "string",
														"description": "Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",
														"enum": [
															"low",
															"medium",
															"high"
														]
													},
													"summary": {
														"type": "string",
														"description": "A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.",
														"enum": [
															"auto",
															"concise",
															"detailed"
														]
													}
												}
											}
										},
										"required": [
											"input"
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json"
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "15631501-2742-4346-a469-22fe202188a2",
			"source": 1,
			"name": "@cf/google/embeddinggemma-300m",
			"description": "EmbeddingGemma is a 300M parameter, state-of-the-art for its size, open embedding model from Google, built from Gemma 3 (with T5Gemma initialization) and the same research and technology used to create Gemini models. EmbeddingGemma produces vector representations of text, making it well-suited for search and retrieval tasks, including classification, clustering, and semantic similarity search. This model was trained with data in 100+ spoken languages.",
			"task": {
				"id": "0137cdcf-162a-4108-94f2-1ca59e8c65ee",
				"name": "Text Embeddings",
				"description": "Feature extraction models transform raw data into numerical features that can be processed while preserving the information in the original dataset. These models are ideal as part of building vector search applications or Retrieval Augmented Generation workflows with Large Language Models (LLM)."
			},
			"created_at": "2025-09-04 16:38:44.980",
			"tags": [],
			"properties": [],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"text": {
							"oneOf": [
								{
									"type": "string",
									"description": "The text to embed",
									"minLength": 1
								},
								{
									"type": "array",
									"description": "Batch of text values to embed",
									"items": {
										"type": "string",
										"description": "The text to embed",
										"minLength": 1
									},
									"maxItems": 100
								}
							]
						}
					},
					"required": [
						"text"
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"shape": {
							"type": "array",
							"items": {
								"type": "number"
							}
						},
						"data": {
							"type": "array",
							"description": "Embeddings of the requested text values",
							"items": {
								"type": "array",
								"description": "Floating point embedding representation shaped by the embedding model",
								"items": {
									"type": "number"
								}
							}
						}
					}
				}
			}
		},
		{
			"id": "145337e7-cec3-4ebb-8e78-16ddfc75e580",
			"source": 1,
			"name": "@cf/baai/bge-reranker-base",
			"description": "Different from embedding model, reranker uses question and document as input and directly output similarity instead of embedding. You can get a relevance score by inputting query and passage to the reranker. And the score can be mapped to a float value in [0,1] by sigmoid function.\n\n",
			"task": {
				"id": "19606750-23ed-4371-aab2-c20349b53a60",
				"name": "Text Classification",
				"description": "Sentiment analysis or text classification is a common NLP task that classifies a text input into labels or classes."
			},
			"created_at": "2025-02-14 12:28:19.009",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.0031,
							"currency": "USD"
						}
					]
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"query": {
							"type": "string",
							"minLength": 1,
							"description": "A query you wish to perform against the provided contexts."
						},
						"top_k": {
							"type": "integer",
							"minimum": 1,
							"description": "Number of returned results starting with the best score."
						},
						"contexts": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"text": {
										"type": "string",
										"minLength": 1,
										"description": "One of the provided context content"
									}
								}
							},
							"description": "List of provided contexts. Note that the index in this array is important, as the response will refer to it."
						}
					},
					"required": [
						"query",
						"contexts"
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"response": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"id": {
										"type": "integer",
										"description": "Index of the context in the request"
									},
									"score": {
										"type": "number",
										"description": "Score of the context under the index."
									}
								}
							}
						}
					}
				}
			}
		},
		{
			"id": "0f002249-7d86-4698-aabf-8529ed86cefb",
			"source": 2,
			"name": "@hf/google/gemma-7b-it",
			"description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-04-01 23:51:35.866",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "8192"
				},
				{
					"property_id": "info",
					"value": "https://ai.google.dev/gemma/docs"
				},
				{
					"property_id": "lora",
					"value": "true"
				},
				{
					"property_id": "terms",
					"value": "https://ai.google.dev/gemma/terms"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "0e372c11-8720-46c9-a02d-666188a22dae",
			"source": 1,
			"name": "@cf/leonardo/lucid-origin",
			"description": "Lucid Origin from Leonardo.AI is their most adaptable and prompt-responsive model to date. Whether you're generating images with sharp graphic design, stunning full-HD renders, or highly specific creative direction, it adheres closely to your prompts, renders text with accuracy, and supports a wide array of visual styles and aesthetics – from stylized concept art to crisp product mockups.\n",
			"task": {
				"id": "3d6e1f35-341b-4915-a6c8-9a7142a9033a",
				"name": "Text-to-Image",
				"description": "Generates images from input text. These models can be used to generate and modify images based on text prompts."
			},
			"created_at": "2025-08-25 19:21:28.770",
			"tags": [],
			"properties": [
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per 512 by 512 tile",
							"price": 0.007,
							"currency": "USD"
						},
						{
							"unit": "per step",
							"price": 0.00013,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "partner",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"properties": {
						"prompt": {
							"type": "string",
							"minLength": 1,
							"description": "A text description of the image you want to generate."
						},
						"guidance": {
							"type": "number",
							"default": 4.5,
							"minimum": 0,
							"maximum": 10,
							"description": "Controls how closely the generated image should adhere to the prompt; higher values make the image more aligned with the prompt"
						},
						"seed": {
							"type": "integer",
							"minimum": 0,
							"description": "Random seed for reproducibility of the image generation"
						},
						"height": {
							"type": "integer",
							"minimum": 0,
							"maximum": 2500,
							"default": 1120,
							"description": "The height of the generated image in pixels"
						},
						"width": {
							"type": "integer",
							"minimum": 0,
							"maximum": 2500,
							"default": 1120,
							"description": "The width of the generated image in pixels"
						},
						"num_steps": {
							"type": "integer",
							"minimum": 1,
							"maximum": 40,
							"description": "The number of diffusion steps; higher values can improve quality but take longer"
						},
						"steps": {
							"type": "integer",
							"minimum": 1,
							"maximum": 40,
							"description": "The number of diffusion steps; higher values can improve quality but take longer"
						}
					},
					"required": [
						"prompt"
					]
				},
				"output": {
					"type": "object",
					"contentType": "application/json",
					"properties": {
						"image": {
							"type": "string",
							"description": "The generated image in Base64 format."
						}
					}
				}
			}
		},
		{
			"id": "09d113a9-03c4-420e-b6f2-52ad4b3bed45",
			"source": 1,
			"name": "@cf/qwen/qwen1.5-14b-chat-awq",
			"description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:24:45.316",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "7500"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/qwen/qwen1.5-14b-chat-awq"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "081054cd-a254-4349-855e-6dc0996277fa",
			"source": 1,
			"name": "@cf/openchat/openchat-3.5-0106",
			"description": "OpenChat is an innovative library of open-source language models, fine-tuned with C-RLFT - a strategy inspired by offline reinforcement learning.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2024-02-27 18:20:39.169",
			"tags": [],
			"properties": [
				{
					"property_id": "beta",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "8192"
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/openchat/openchat-3.5-0106"
				},
				{
					"property_id": "planned_deprecation_date",
					"value": "2025-10-01"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"lora": {
									"type": "string",
									"description": "Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"type": "string",
												"description": "The content of the message as a string."
											}
										},
										"required": [
											"role",
											"content"
										]
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0.001,
									"maximum": 1,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": -2,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "06455e78-19f7-487b-93cd-c05a3dd07813",
			"source": 1,
			"name": "@cf/meta/llama-4-scout-17b-16e-instruct",
			"description": "Meta's Llama 4 Scout is a 17 billion parameter model with 16 experts that is natively multimodal. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-04-05 20:25:56.137",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "context_window",
					"value": "131000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.27,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.85,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "function_calling",
					"value": "true"
				},
				{
					"property_id": "terms",
					"value": "https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Ai_Cf_Meta_Llama_4_Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"guided_json": {
									"type": "object",
									"description": "JSON schema that should be fulfilled for the response."
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.15,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Ai_Cf_Meta_Llama_4_Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"tool_call_id": {
												"type": "string",
												"description": "The tool call id. If you don't know what to put here you can fall back to 000000001",
												"pattern": "[a-zA-Z0-9]{9}"
											},
											"content": {
												"oneOf": [
													{
														"type": "string",
														"description": "The content of the message as a string."
													},
													{
														"type": "array",
														"items": {
															"type": "object",
															"properties": {
																"type": {
																	"type": "string",
																	"description": "Type of the content provided"
																},
																"text": {
																	"type": "string"
																},
																"image_url": {
																	"type": "object",
																	"properties": {
																		"url": {
																			"type": "string",
																			"pattern": "^data:*",
																			"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																		}
																	}
																}
															}
														}
													},
													{
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"description": "Type of the content provided"
															},
															"text": {
																"type": "string"
															},
															"image_url": {
																"type": "object",
																"properties": {
																	"url": {
																		"type": "string",
																		"pattern": "^data:*",
																		"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																	}
																}
															}
														}
													}
												]
											}
										}
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"response_format": {
									"title": "JSON Mode",
									"type": "object",
									"properties": {
										"type": {
											"type": "string",
											"enum": [
												"json_object",
												"json_schema"
											]
										},
										"json_schema": {}
									}
								},
								"guided_json": {
									"type": "object",
									"description": "JSON schema that should be fufilled for the response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.15,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						},
						{
							"title": "Ai_Cf_Meta_Llama_4_Async_Batch",
							"type": "object",
							"properties": {
								"requests": {
									"type": "array",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"title": "Ai_Cf_Meta_Llama_4_Prompt_Inner",
												"properties": {
													"prompt": {
														"type": "string",
														"minLength": 1,
														"description": "The input text prompt for the model to generate a response."
													},
													"guided_json": {
														"type": "object",
														"description": "JSON schema that should be fulfilled for the response."
													},
													"response_format": {
														"title": "JSON Mode",
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"enum": [
																	"json_object",
																	"json_schema"
																]
															},
															"json_schema": {}
														}
													},
													"raw": {
														"type": "boolean",
														"default": false,
														"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
													},
													"stream": {
														"type": "boolean",
														"default": false,
														"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
													},
													"max_tokens": {
														"type": "integer",
														"default": 256,
														"description": "The maximum number of tokens to generate in the response."
													},
													"temperature": {
														"type": "number",
														"default": 0.15,
														"minimum": 0,
														"maximum": 5,
														"description": "Controls the randomness of the output; higher values produce more random results."
													},
													"top_p": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
													},
													"top_k": {
														"type": "integer",
														"minimum": 1,
														"maximum": 50,
														"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
													},
													"seed": {
														"type": "integer",
														"minimum": 1,
														"maximum": 9999999999,
														"description": "Random seed for reproducibility of the generation."
													},
													"repetition_penalty": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Penalty for repeated tokens; higher values discourage repetition."
													},
													"frequency_penalty": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Decreases the likelihood of the model repeating the same lines verbatim."
													},
													"presence_penalty": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Increases the likelihood of the model introducing new topics."
													}
												},
												"required": [
													"prompt"
												]
											},
											{
												"title": "Ai_Cf_Meta_Llama_4_Messages_Inner",
												"properties": {
													"messages": {
														"type": "array",
														"description": "An array of message objects representing the conversation history.",
														"items": {
															"type": "object",
															"properties": {
																"role": {
																	"type": "string",
																	"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
																},
																"tool_call_id": {
																	"type": "string",
																	"description": "The tool call id. If you don't know what to put here you can fall back to 000000001",
																	"pattern": "[a-zA-Z0-9]{9}"
																},
																"content": {
																	"oneOf": [
																		{
																			"type": "string",
																			"description": "The content of the message as a string."
																		},
																		{
																			"type": "array",
																			"items": {
																				"type": "object",
																				"properties": {
																					"type": {
																						"type": "string",
																						"description": "Type of the content provided"
																					},
																					"text": {
																						"type": "string"
																					},
																					"image_url": {
																						"type": "object",
																						"properties": {
																							"url": {
																								"type": "string",
																								"pattern": "^data:*",
																								"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																							}
																						}
																					}
																				}
																			}
																		},
																		{
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "Type of the content provided"
																				},
																				"text": {
																					"type": "string"
																				},
																				"image_url": {
																					"type": "object",
																					"properties": {
																						"url": {
																							"type": "string",
																							"pattern": "^data:*",
																							"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																						}
																					}
																				}
																			}
																		}
																	]
																}
															}
														}
													},
													"functions": {
														"type": "array",
														"items": {
															"type": "object",
															"properties": {
																"name": {
																	"type": "string"
																},
																"code": {
																	"type": "string"
																}
															},
															"required": [
																"name",
																"code"
															]
														}
													},
													"tools": {
														"type": "array",
														"description": "A list of tools available for the assistant to use.",
														"items": {
															"type": "object",
															"oneOf": [
																{
																	"properties": {
																		"name": {
																			"type": "string",
																			"description": "The name of the tool. More descriptive the better."
																		},
																		"description": {
																			"type": "string",
																			"description": "A brief description of what the tool does."
																		},
																		"parameters": {
																			"type": "object",
																			"description": "Schema defining the parameters accepted by the tool.",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The type of the parameters object (usually 'object')."
																				},
																				"required": {
																					"type": "array",
																					"description": "List of required parameter names.",
																					"items": {
																						"type": "string"
																					}
																				},
																				"properties": {
																					"type": "object",
																					"description": "Definitions of each parameter.",
																					"additionalProperties": {
																						"type": "object",
																						"properties": {
																							"type": {
																								"type": "string",
																								"description": "The data type of the parameter."
																							},
																							"description": {
																								"type": "string",
																								"description": "A description of the expected parameter."
																							}
																						},
																						"required": [
																							"type",
																							"description"
																						]
																					}
																				}
																			},
																			"required": [
																				"type",
																				"properties"
																			]
																		}
																	},
																	"required": [
																		"name",
																		"description",
																		"parameters"
																	]
																},
																{
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "Specifies the type of tool (e.g., 'function')."
																		},
																		"function": {
																			"type": "object",
																			"description": "Details of the function tool.",
																			"properties": {
																				"name": {
																					"type": "string",
																					"description": "The name of the function."
																				},
																				"description": {
																					"type": "string",
																					"description": "A brief description of what the function does."
																				},
																				"parameters": {
																					"type": "object",
																					"description": "Schema defining the parameters accepted by the function.",
																					"properties": {
																						"type": {
																							"type": "string",
																							"description": "The type of the parameters object (usually 'object')."
																						},
																						"required": {
																							"type": "array",
																							"description": "List of required parameter names.",
																							"items": {
																								"type": "string"
																							}
																						},
																						"properties": {
																							"type": "object",
																							"description": "Definitions of each parameter.",
																							"additionalProperties": {
																								"type": "object",
																								"properties": {
																									"type": {
																										"type": "string",
																										"description": "The data type of the parameter."
																									},
																									"description": {
																										"type": "string",
																										"description": "A description of the expected parameter."
																									}
																								},
																								"required": [
																									"type",
																									"description"
																								]
																							}
																						}
																					},
																					"required": [
																						"type",
																						"properties"
																					]
																				}
																			},
																			"required": [
																				"name",
																				"description",
																				"parameters"
																			]
																		}
																	},
																	"required": [
																		"type",
																		"function"
																	]
																}
															]
														}
													},
													"response_format": {
														"title": "JSON Mode",
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"enum": [
																	"json_object",
																	"json_schema"
																]
															},
															"json_schema": {}
														}
													},
													"guided_json": {
														"type": "object",
														"description": "JSON schema that should be fufilled for the response."
													},
													"raw": {
														"type": "boolean",
														"default": false,
														"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
													},
													"stream": {
														"type": "boolean",
														"default": false,
														"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
													},
													"max_tokens": {
														"type": "integer",
														"default": 256,
														"description": "The maximum number of tokens to generate in the response."
													},
													"temperature": {
														"type": "number",
														"default": 0.15,
														"minimum": 0,
														"maximum": 5,
														"description": "Controls the randomness of the output; higher values produce more random results."
													},
													"top_p": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
													},
													"top_k": {
														"type": "integer",
														"minimum": 1,
														"maximum": 50,
														"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
													},
													"seed": {
														"type": "integer",
														"minimum": 1,
														"maximum": 9999999999,
														"description": "Random seed for reproducibility of the generation."
													},
													"repetition_penalty": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Penalty for repeated tokens; higher values discourage repetition."
													},
													"frequency_penalty": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Decreases the likelihood of the model repeating the same lines verbatim."
													},
													"presence_penalty": {
														"type": "number",
														"minimum": 0,
														"maximum": 2,
														"description": "Increases the likelihood of the model introducing new topics."
													}
												},
												"required": [
													"messages"
												]
											}
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"id": {
												"type": "string",
												"description": "The tool call id."
											},
											"type": {
												"type": "string",
												"description": "Specifies the type of tool (e.g., 'function')."
											},
											"function": {
												"type": "object",
												"description": "Details of the function tool.",
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool to be called"
													},
													"arguments": {
														"type": "object",
														"description": "The arguments passed to be passed to the tool call request"
													}
												}
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "053d5ac0-861b-4d3b-8501-e58d00417ef8",
			"source": 1,
			"name": "@cf/google/gemma-3-12b-it",
			"description": "Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Gemma 3 models are multimodal, handling text and image input and generating text output, with a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-03-18 03:58:02.423",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "80000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.35,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 0.56,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Google_Gemma_3_12B_It_Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"guided_json": {
									"type": "object",
									"description": "JSON schema that should be fufilled for the response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Google_Gemma_3_12B_It_Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"content": {
												"oneOf": [
													{
														"type": "string",
														"description": "The content of the message as a string."
													},
													{
														"type": "array",
														"items": {
															"type": "object",
															"properties": {
																"type": {
																	"type": "string",
																	"description": "Type of the content provided"
																},
																"text": {
																	"type": "string"
																},
																"image_url": {
																	"type": "object",
																	"properties": {
																		"url": {
																			"type": "string",
																			"pattern": "^data:*",
																			"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																		}
																	}
																}
															}
														}
													},
													{
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"description": "Type of the content provided"
															},
															"text": {
																"type": "string"
															},
															"image_url": {
																"type": "object",
																"properties": {
																	"url": {
																		"type": "string",
																		"pattern": "^data:*",
																		"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																	}
																}
															}
														}
													}
												]
											}
										}
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"guided_json": {
									"type": "object",
									"description": "JSON schema that should be fufilled for the response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.6,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "02c16efa-29f5-4304-8e6c-3d188889f875",
			"source": 1,
			"name": "@cf/qwen/qwq-32b",
			"description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.",
			"task": {
				"id": "c329a1f9-323d-4e91-b2aa-582dd4188d34",
				"name": "Text Generation",
				"description": "Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."
			},
			"created_at": "2025-03-05 21:52:40.974",
			"tags": [],
			"properties": [
				{
					"property_id": "context_window",
					"value": "24000"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.66,
							"currency": "USD"
						},
						{
							"unit": "per M output tokens",
							"price": 1,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "lora",
					"value": "true"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"title": "Qwen_Qwq_32B_Prompt",
							"properties": {
								"prompt": {
									"type": "string",
									"minLength": 1,
									"description": "The input text prompt for the model to generate a response."
								},
								"guided_json": {
									"type": "object",
									"description": "JSON schema that should be fulfilled for the response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.15,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"prompt"
							]
						},
						{
							"title": "Qwen_Qwq_32B_Messages",
							"properties": {
								"messages": {
									"type": "array",
									"description": "An array of message objects representing the conversation history.",
									"items": {
										"type": "object",
										"properties": {
											"role": {
												"type": "string",
												"description": "The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool')."
											},
											"tool_call_id": {
												"type": "string",
												"description": "The tool call id. Must be supplied for tool calls for Mistral-3. If you don't know what to put here you can fall back to 000000001",
												"pattern": "[a-zA-Z0-9]{9}"
											},
											"content": {
												"oneOf": [
													{
														"type": "string",
														"description": "The content of the message as a string."
													},
													{
														"type": "array",
														"items": {
															"type": "object",
															"properties": {
																"type": {
																	"type": "string",
																	"description": "Type of the content provided"
																},
																"text": {
																	"type": "string"
																},
																"image_url": {
																	"type": "object",
																	"properties": {
																		"url": {
																			"type": "string",
																			"pattern": "^data:*",
																			"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																		}
																	}
																}
															}
														}
													},
													{
														"type": "object",
														"properties": {
															"type": {
																"type": "string",
																"description": "Type of the content provided"
															},
															"text": {
																"type": "string"
															},
															"image_url": {
																"type": "object",
																"properties": {
																	"url": {
																		"type": "string",
																		"pattern": "^data:*",
																		"description": "image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted"
																	}
																}
															}
														}
													}
												]
											}
										}
									}
								},
								"functions": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"name": {
												"type": "string"
											},
											"code": {
												"type": "string"
											}
										},
										"required": [
											"name",
											"code"
										]
									}
								},
								"tools": {
									"type": "array",
									"description": "A list of tools available for the assistant to use.",
									"items": {
										"type": "object",
										"oneOf": [
											{
												"properties": {
													"name": {
														"type": "string",
														"description": "The name of the tool. More descriptive the better."
													},
													"description": {
														"type": "string",
														"description": "A brief description of what the tool does."
													},
													"parameters": {
														"type": "object",
														"description": "Schema defining the parameters accepted by the tool.",
														"properties": {
															"type": {
																"type": "string",
																"description": "The type of the parameters object (usually 'object')."
															},
															"required": {
																"type": "array",
																"description": "List of required parameter names.",
																"items": {
																	"type": "string"
																}
															},
															"properties": {
																"type": "object",
																"description": "Definitions of each parameter.",
																"additionalProperties": {
																	"type": "object",
																	"properties": {
																		"type": {
																			"type": "string",
																			"description": "The data type of the parameter."
																		},
																		"description": {
																			"type": "string",
																			"description": "A description of the expected parameter."
																		}
																	},
																	"required": [
																		"type",
																		"description"
																	]
																}
															}
														},
														"required": [
															"type",
															"properties"
														]
													}
												},
												"required": [
													"name",
													"description",
													"parameters"
												]
											},
											{
												"properties": {
													"type": {
														"type": "string",
														"description": "Specifies the type of tool (e.g., 'function')."
													},
													"function": {
														"type": "object",
														"description": "Details of the function tool.",
														"properties": {
															"name": {
																"type": "string",
																"description": "The name of the function."
															},
															"description": {
																"type": "string",
																"description": "A brief description of what the function does."
															},
															"parameters": {
																"type": "object",
																"description": "Schema defining the parameters accepted by the function.",
																"properties": {
																	"type": {
																		"type": "string",
																		"description": "The type of the parameters object (usually 'object')."
																	},
																	"required": {
																		"type": "array",
																		"description": "List of required parameter names.",
																		"items": {
																			"type": "string"
																		}
																	},
																	"properties": {
																		"type": "object",
																		"description": "Definitions of each parameter.",
																		"additionalProperties": {
																			"type": "object",
																			"properties": {
																				"type": {
																					"type": "string",
																					"description": "The data type of the parameter."
																				},
																				"description": {
																					"type": "string",
																					"description": "A description of the expected parameter."
																				}
																			},
																			"required": [
																				"type",
																				"description"
																			]
																		}
																	}
																},
																"required": [
																	"type",
																	"properties"
																]
															}
														},
														"required": [
															"name",
															"description",
															"parameters"
														]
													}
												},
												"required": [
													"type",
													"function"
												]
											}
										]
									}
								},
								"guided_json": {
									"type": "object",
									"description": "JSON schema that should be fufilled for the response."
								},
								"raw": {
									"type": "boolean",
									"default": false,
									"description": "If true, a chat template is not applied and you must adhere to the specific model's expected formatting."
								},
								"stream": {
									"type": "boolean",
									"default": false,
									"description": "If true, the response will be streamed back incrementally using SSE, Server Sent Events."
								},
								"max_tokens": {
									"type": "integer",
									"default": 256,
									"description": "The maximum number of tokens to generate in the response."
								},
								"temperature": {
									"type": "number",
									"default": 0.15,
									"minimum": 0,
									"maximum": 5,
									"description": "Controls the randomness of the output; higher values produce more random results."
								},
								"top_p": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses."
								},
								"top_k": {
									"type": "integer",
									"minimum": 1,
									"maximum": 50,
									"description": "Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises."
								},
								"seed": {
									"type": "integer",
									"minimum": 1,
									"maximum": 9999999999,
									"description": "Random seed for reproducibility of the generation."
								},
								"repetition_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Penalty for repeated tokens; higher values discourage repetition."
								},
								"frequency_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Decreases the likelihood of the model repeating the same lines verbatim."
								},
								"presence_penalty": {
									"type": "number",
									"minimum": 0,
									"maximum": 2,
									"description": "Increases the likelihood of the model introducing new topics."
								}
							},
							"required": [
								"messages"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"response": {
									"type": "string",
									"description": "The generated text response from the model"
								},
								"usage": {
									"type": "object",
									"description": "Usage statistics for the inference request",
									"properties": {
										"prompt_tokens": {
											"type": "number",
											"description": "Total number of tokens in input",
											"default": 0
										},
										"completion_tokens": {
											"type": "number",
											"description": "Total number of tokens in output",
											"default": 0
										},
										"total_tokens": {
											"type": "number",
											"description": "Total number of input and output tokens",
											"default": 0
										}
									}
								},
								"tool_calls": {
									"type": "array",
									"description": "An array of tool calls requests made during the response generation",
									"items": {
										"type": "object",
										"properties": {
											"arguments": {
												"type": "object",
												"description": "The arguments passed to be passed to the tool call request"
											},
											"name": {
												"type": "string",
												"description": "The name of the tool to be called"
											}
										}
									}
								}
							},
							"required": [
								"response"
							]
						},
						{
							"type": "string",
							"contentType": "text/event-stream",
							"format": "binary"
						}
					]
				}
			}
		},
		{
			"id": "01bc2fb0-4bca-4598-b985-d2584a3f46c0",
			"source": 1,
			"name": "@cf/baai/bge-large-en-v1.5",
			"description": "BAAI general embedding (Large) model that transforms any given text into a 1024-dimensional vector",
			"task": {
				"id": "0137cdcf-162a-4108-94f2-1ca59e8c65ee",
				"name": "Text Embeddings",
				"description": "Feature extraction models transform raw data into numerical features that can be processed while preserving the information in the original dataset. These models are ideal as part of building vector search applications or Retrieval Augmented Generation workflows with Large Language Models (LLM)."
			},
			"created_at": "2023-11-07 15:43:58.042",
			"tags": [],
			"properties": [
				{
					"property_id": "async_queue",
					"value": "true"
				},
				{
					"property_id": "price",
					"value": [
						{
							"unit": "per M input tokens",
							"price": 0.2,
							"currency": "USD"
						}
					]
				},
				{
					"property_id": "info",
					"value": "https://huggingface.co/BAAI/bge-large-en-v1.5"
				},
				{
					"property_id": "max_input_tokens",
					"value": "512"
				},
				{
					"property_id": "output_dimensions",
					"value": "1024"
				}
			],
			"schema": {
				"input": {
					"type": "object",
					"oneOf": [
						{
							"properties": {
								"text": {
									"oneOf": [
										{
											"type": "string",
											"description": "The text to embed",
											"minLength": 1
										},
										{
											"type": "array",
											"description": "Batch of text values to embed",
											"items": {
												"type": "string",
												"description": "The text to embed",
												"minLength": 1
											},
											"maxItems": 100
										}
									]
								},
								"pooling": {
									"type": "string",
									"enum": [
										"mean",
										"cls"
									],
									"default": "mean",
									"description": "The pooling method used in the embedding process. `cls` pooling will generate more accurate embeddings on larger inputs - however, embeddings created with cls pooling are not compatible with embeddings generated with mean pooling. The default pooling method is `mean` in order for this to not be a breaking change, but we highly suggest using the new `cls` pooling for better accuracy."
								}
							},
							"required": [
								"text"
							]
						},
						{
							"properties": {
								"requests": {
									"type": "array",
									"description": "Batch of the embeddings requests to run using async-queue",
									"items": {
										"properties": {
											"text": {
												"oneOf": [
													{
														"type": "string",
														"description": "The text to embed",
														"minLength": 1
													},
													{
														"type": "array",
														"description": "Batch of text values to embed",
														"items": {
															"type": "string",
															"description": "The text to embed",
															"minLength": 1
														},
														"maxItems": 100
													}
												]
											},
											"pooling": {
												"type": "string",
												"enum": [
													"mean",
													"cls"
												],
												"default": "mean",
												"description": "The pooling method used in the embedding process. `cls` pooling will generate more accurate embeddings on larger inputs - however, embeddings created with cls pooling are not compatible with embeddings generated with mean pooling. The default pooling method is `mean` in order for this to not be a breaking change, but we highly suggest using the new `cls` pooling for better accuracy."
											}
										},
										"required": [
											"text"
										]
									}
								}
							},
							"required": [
								"requests"
							]
						}
					]
				},
				"output": {
					"oneOf": [
						{
							"type": "object",
							"contentType": "application/json",
							"properties": {
								"shape": {
									"type": "array",
									"items": {
										"type": "number"
									}
								},
								"data": {
									"type": "array",
									"description": "Embeddings of the requested text values",
									"items": {
										"type": "array",
										"description": "Floating point embedding representation shaped by the embedding model",
										"items": {
											"type": "number"
										}
									}
								},
								"pooling": {
									"type": "string",
									"enum": [
										"mean",
										"cls"
									],
									"description": "The pooling method used in the embedding process."
								}
							}
						},
						{
							"type": "object",
							"contentType": "application/json",
							"title": "Async response",
							"properties": {
								"request_id": {
									"type": "string",
									"description": "The async request id that can be used to obtain the results."
								}
							}
						}
					]
				}
			}
		}
	]
}
